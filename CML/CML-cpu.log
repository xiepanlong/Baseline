10403 features over tag_occurence_thres (5)
79527/25186/31555 train/valid/test samples

Recall on (sampled) validation set: 0.0

Training loss 49241.8203125

Recall on (sampled) validation set: 0.2270547653093025

Training loss 49012.64453125

Recall on (sampled) validation set: 0.2408867593050896

Training loss 48994.0390625

Recall on (sampled) validation set: 0.21594895393307367

Training loss 48985.41015625

Recall on (sampled) validation set: 0.2182173546021096

Training loss 48980.49609375

Recall on (sampled) validation set: 0.22329053389307474

Training loss 48976.078125

Recall on (sampled) validation set: 0.21735219841662673

Training loss 48971.87109375

Recall on (sampled) validation set: 0.22618288952091128

Training loss 48968.48828125

Recall on (sampled) validation set: 0.23697425076100212

Training loss 48965.60546875

Recall on (sampled) validation set: 0.21396063718159908

Training loss 48962.74609375

Recall on (sampled) validation set: 0.21768153032354487

Training loss 48960.59375

Recall on (sampled) validation set: 0.22298904343958792

Training loss 48958.83984375

Recall on (sampled) validation set: 0.21288214741163924

Training loss 48956.85546875

Recall on (sampled) validation set: 0.2090806589726735

Training loss 48955.03515625

Recall on (sampled) validation set: 0.2317222951143096

Training loss 48953.73046875

Recall on (sampled) validation set: 0.21986776764272226

Training loss 48952.05859375

Recall on (sampled) validation set: 0.22885628779367437

Training loss 48950.76953125

Recall on (sampled) validation set: 0.22817446039542227

Training loss 48949.2265625

Recall on (sampled) validation set: 0.23155982607162276

Training loss 48948.12109375

Recall on (sampled) validation set: 0.24248632007570298

Training loss 48946.5703125

Recall on (sampled) validation set: 0.22573693791252775

Training loss 48945.21875

Recall on (sampled) validation set: 0.23374486656383206

Training loss 48944.3359375

Recall on (sampled) validation set: 0.22953840927842742

Training loss 48942.703125

Recall on (sampled) validation set: 0.23142902597167567

Training loss 48942.23828125

Recall on (sampled) validation set: 0.23480543857903205

Training loss 48940.8359375

Recall on (sampled) validation set: 0.23393007466419447

Training loss 48940.50390625

Recall on (sampled) validation set: 0.2321996018869885

Training loss 48939.4609375

Recall on (sampled) validation set: 0.22298094919465158

Training loss 48938.87109375

Recall on (sampled) validation set: 0.21694842470160072

Training loss 48938.3046875

Recall on (sampled) validation set: 0.21754928290772213

Training loss 48937.78125

Recall on (sampled) validation set: 0.22391858761323372

Training loss 48937.31640625

Recall on (sampled) validation set: 0.2187773570114768

Training loss 48936.19140625

Recall on (sampled) validation set: 0.222432832560328

Training loss 48936.0703125

Recall on (sampled) validation set: 0.22251419518842389

Training loss 48935.17578125

Recall on (sampled) validation set: 0.22784545895389816

Training loss 48934.68359375

Recall on (sampled) validation set: 0.22381595730007708

Training loss 48933.58984375

Recall on (sampled) validation set: 0.22696196626187554

Training loss 48933.61328125

Recall on (sampled) validation set: 0.23191358381149668

Training loss 48933.21875

Recall on (sampled) validation set: 0.22890853330644623

Training loss 48932.05859375

Recall on (sampled) validation set: 0.22291612805088307

Training loss 48932.16015625

Recall on (sampled) validation set: 0.2182586320381239

Training loss 48931.33984375

Recall on (sampled) validation set: 0.2148030423062183

Training loss 48931.06640625

Recall on (sampled) validation set: 0.22100889785417915

Training loss 48930.71875

Recall on (sampled) validation set: 0.2198597789754777

Training loss 48930.18359375

Recall on (sampled) validation set: 0.22441659006450293

Training loss 48930.390625

Recall on (sampled) validation set: 0.21609581490298369

Training loss 48930.046875

Recall on (sampled) validation set: 0.22025403721773956

Training loss 48929.8515625

Recall on (sampled) validation set: 0.2263128648423567

Training loss 48930.13671875

Recall on (sampled) validation set: 0.22759046012131307

Training loss 48928.87890625

Recall on (sampled) validation set: 0.218415758570931

Training loss 48928.765625

Recall on (sampled) validation set: 0.23078337584644298

Training loss 48928.66015625

Recall on (sampled) validation set: 0.2245090307622068

Training loss 48928.42578125

Recall on (sampled) validation set: 0.21769981859909265

Training loss 48927.69140625

Recall on (sampled) validation set: 0.227550900719231

Training loss 48927.65625

Recall on (sampled) validation set: 0.21510899658585686

Training loss 48927.015625

Recall on (sampled) validation set: 0.21470963087796116

Training loss 48927.00390625

Recall on (sampled) validation set: 0.21347515820201846

Training loss 48926.8203125

Recall on (sampled) validation set: 0.22196026530100937

Training loss 48926.53125

Recall on (sampled) validation set: 0.22579107818309269

Training loss 48926.375

Recall on (sampled) validation set: 0.2317669838563668

Training loss 48926.24609375

Recall on (sampled) validation set: 0.23598843394623795

Training loss 48925.484375

Recall on (sampled) validation set: 0.2403703736439671

Training loss 48925.50390625

Recall on (sampled) validation set: 0.2236374009300507

Training loss 48925.23828125

Recall on (sampled) validation set: 0.23045296889035546

Training loss 48925.11328125

Recall on (sampled) validation set: 0.22064485010855245

Training loss 48924.796875

Recall on (sampled) validation set: 0.2146864376632979

Training loss 48924.98828125

Recall on (sampled) validation set: 0.2180584195162235

Training loss 48924.65625

Recall on (sampled) validation set: 0.22445752573701758

Training loss 48924.37109375

Recall on (sampled) validation set: 0.2312180761028311

Training loss 48923.1953125

Recall on (sampled) validation set: 0.22673765155661707

Training loss 48923.01171875

Recall on (sampled) validation set: 0.22023321255943762

Training loss 48922.9765625

Recall on (sampled) validation set: 0.2328389523026546

Training loss 48922.875

Recall on (sampled) validation set: 0.22429726108401246

Training loss 48922.3359375

Recall on (sampled) validation set: 0.2306794057088975

Training loss 48922.34375

Recall on (sampled) validation set: 0.22300063856960406

Training loss 48921.921875

Recall on (sampled) validation set: 0.22197555692610138

Training loss 48922.046875

Recall on (sampled) validation set: 0.226734302667152

Training loss 48921.48046875

Recall on (sampled) validation set: 0.22471523200198334

Training loss 48921.83984375

Recall on (sampled) validation set: 0.23079034795277992

Training loss 48921.17578125

Recall on (sampled) validation set: 0.22557470631472445

Training loss 48921.0859375

Recall on (sampled) validation set: 0.23267168247159173

Training loss 48921.1953125

Recall on (sampled) validation set: 0.2201542462041555

Training loss 48920.4765625

Recall on (sampled) validation set: 0.22275084742507606

Training loss 48920.671875

Recall on (sampled) validation set: 0.22644259966356153

Training loss 48920.25

Recall on (sampled) validation set: 0.21349936356243074

Training loss 48920.05078125

Recall on (sampled) validation set: 0.22349191678456648

Training loss 48919.4609375

Recall on (sampled) validation set: 0.22436858014943312

Training loss 48919.609375

Recall on (sampled) validation set: 0.22146406698766047

Training loss 48919.6796875

Recall on (sampled) validation set: 0.2196073779013888

Training loss 48919.34375

Recall on (sampled) validation set: 0.2196239645613511

Training loss 48918.921875

Recall on (sampled) validation set: 0.2203971490464231

Training loss 48919.1484375

Recall on (sampled) validation set: 0.21099012617751275

Training loss 48918.75

Recall on (sampled) validation set: 0.23276489137333053

Training loss 48918.85546875

Recall on (sampled) validation set: 0.2325566917118641

Training loss 48918.515625

Recall on (sampled) validation set: 0.22311490935628867

Training loss 48918.5390625

Recall on (sampled) validation set: 0.231487040048746

Training loss 48918.84375

Recall on (sampled) validation set: 0.2219239886113752

Training loss 48918.0859375

Recall on (sampled) validation set: 0.23082592212855368

Training loss 48918.44921875

Recall on (sampled) validation set: 0.23397640413293772

Training loss 48918.0546875

Recall on (sampled) validation set: 0.2299099763078892

Training loss 48918.3359375

Recall on (sampled) validation set: 0.22669857659648945

Training loss 48917.859375

Recall on (sampled) validation set: 0.22541502681293973

Training loss 48917.625

Recall on (sampled) validation set: 0.2231435035690934

Training loss 48917.48046875

Recall on (sampled) validation set: 0.21811704701495988

Training loss 48917.21484375

Recall on (sampled) validation set: 0.2150843974705136

Training loss 48917.4765625

Recall on (sampled) validation set: 0.2067277594019881

Training loss 48916.90625

Recall on (sampled) validation set: 0.21347125083694957

Training loss 48916.82421875

Recall on (sampled) validation set: 0.22588447695344246

Training loss 48917.12109375

Recall on (sampled) validation set: 0.2277672330861986

Training loss 48916.82421875

Recall on (sampled) validation set: 0.21782387089283642

Training loss 48916.76953125

Recall on (sampled) validation set: 0.22976400139149683

Training loss 48916.7109375

Recall on (sampled) validation set: 0.21560704486748042

Training loss 48916.4453125

Recall on (sampled) validation set: 0.2191146356836012

Training loss 48915.86328125

Recall on (sampled) validation set: 0.22209665512614696

Training loss 48916.51171875

Recall on (sampled) validation set: 0.22426114223210414

Training loss 48915.96875

Recall on (sampled) validation set: 0.22614044275614148

Training loss 48915.94140625

Recall on (sampled) validation set: 0.23395776623725809

Training loss 48916.37890625

Recall on (sampled) validation set: 0.2189501754211373

Training loss 48915.859375

Recall on (sampled) validation set: 0.2117315377873454

Training loss 48915.82421875

Recall on (sampled) validation set: 0.22166104742874254

Training loss 48915.9296875

Recall on (sampled) validation set: 0.21736231928654792

Training loss 48915.71875

Recall on (sampled) validation set: 0.22104548553550368

Training loss 48915.80859375

Recall on (sampled) validation set: 0.21770463340517787

Training loss 48915.3359375

Recall on (sampled) validation set: 0.2181385440700323

Training loss 48915.17578125

Recall on (sampled) validation set: 0.2274109826115271

Training loss 48915.4609375

Recall on (sampled) validation set: 0.22068855153383282

Training loss 48915.25390625

Recall on (sampled) validation set: 0.22106208790873041

Training loss 48915.26953125

Recall on (sampled) validation set: 0.21977174803082244

Training loss 48915.2109375

Recall on (sampled) validation set: 0.21654727422876238

Training loss 48915.046875

Recall on (sampled) validation set: 0.21051158133054684

Training loss 48914.71484375

Recall on (sampled) validation set: 0.2182030107923937

Training loss 48915.01171875

Recall on (sampled) validation set: 0.21812168373738244

Training loss 48914.66015625

Recall on (sampled) validation set: 0.21841514466242234

Training loss 48914.23828125

Recall on (sampled) validation set: 0.20703138222602832

Training loss 48914.171875

Recall on (sampled) validation set: 0.2124547322677994

Training loss 48914.24609375

Recall on (sampled) validation set: 0.1999692002559516

Training loss 48913.984375

Recall on (sampled) validation set: 0.20792725435148304

Training loss 48914.23828125

Recall on (sampled) validation set: 0.21759625640206404

Training loss 48913.4765625

Recall on (sampled) validation set: 0.2163458956517033

Training loss 48913.7890625

Recall on (sampled) validation set: 0.21075177385295352

Training loss 48913.5390625

Recall on (sampled) validation set: 0.21245448151028912

Training loss 48913.671875

Recall on (sampled) validation set: 0.21097745081093539

Training loss 48913.78125

Recall on (sampled) validation set: 0.21774320549048318

Training loss 48913.55859375

Recall on (sampled) validation set: 0.21695649411756487

Training loss 48913.609375

Recall on (sampled) validation set: 0.22353074644317839

Training loss 48913.51953125

Recall on (sampled) validation set: 0.21899663818402473

Training loss 48913.3359375

Recall on (sampled) validation set: 0.21589112819693582

Training loss 48912.91015625

Recall on (sampled) validation set: 0.2029278147408819

Training loss 48912.88671875

Recall on (sampled) validation set: 0.21391117832224907

Training loss 48913.13671875

Recall on (sampled) validation set: 0.21727569833876548

Training loss 48912.5

Recall on (sampled) validation set: 0.21255385738144358

Training loss 48912.49609375

Recall on (sampled) validation set: 0.21380198488410826

Training loss 48912.46484375

Recall on (sampled) validation set: 0.2145558163017328

Training loss 48912.64453125

Recall on (sampled) validation set: 0.21159692678431335

Training loss 48912.78125

Recall on (sampled) validation set: 0.20873401633655717

Training loss 48912.32421875

Recall on (sampled) validation set: 0.2072784471191912

Training loss 48912.43359375

Recall on (sampled) validation set: 0.2131496821555805

Training loss 48912.375

Recall on (sampled) validation set: 0.2179933286280836

Training loss 48912.15625

Recall on (sampled) validation set: 0.21474596780177543

Training loss 48912.59375

Recall on (sampled) validation set: 0.2082708595766672

Training loss 48912.03125

Recall on (sampled) validation set: 0.21295771320499088

Training loss 48912.32421875

Recall on (sampled) validation set: 0.20555938064422638

Training loss 48911.71484375

Recall on (sampled) validation set: 0.22102651766127265

Training loss 48911.8515625

Recall on (sampled) validation set: 0.21286778030062964

Training loss 48911.9765625

Recall on (sampled) validation set: 0.20414907784962233

Training loss 48911.89453125

Recall on (sampled) validation set: 0.21472337736539188

Training loss 48911.75390625

Recall on (sampled) validation set: 0.2159255003583497

Training loss 48911.8203125

Recall on (sampled) validation set: 0.22170947505475633

Training loss 48911.609375

Recall on (sampled) validation set: 0.21545633982203857

Training loss 48911.73828125

Recall on (sampled) validation set: 0.21372772928489808

Training loss 48911.58984375

Recall on (sampled) validation set: 0.22488069529448837

Training loss 48911.875

Recall on (sampled) validation set: 0.2264991575944389

Training loss 48911.3359375

Recall on (sampled) validation set: 0.22625502453451635

Training loss 48911.62109375

Recall on (sampled) validation set: 0.20857079502133946

Training loss 48911.1796875

Recall on (sampled) validation set: 0.21666555844505025

Training loss 48911.39453125

Recall on (sampled) validation set: 0.20395425366795603

Training loss 48911.1953125

Recall on (sampled) validation set: 0.22362105717096645

Training loss 48910.890625

Recall on (sampled) validation set: 0.21876394115731682

Training loss 48910.81640625

Recall on (sampled) validation set: 0.21831367494842993

Training loss 48910.7109375

Recall on (sampled) validation set: 0.21611950417667297

Training loss 48911.12109375

Recall on (sampled) validation set: 0.21111663323233198

Training loss 48910.48046875

Recall on (sampled) validation set: 0.20986862292443054

Training loss 48910.890625

Recall on (sampled) validation set: 0.21941498883921753

Training loss 48910.9453125

Recall on (sampled) validation set: 0.21202776839346713

Training loss 48910.8046875

Recall on (sampled) validation set: 0.2191205045374737

Training loss 48910.578125

Recall on (sampled) validation set: 0.22086594048889874

Training loss 48910.08984375

Recall on (sampled) validation set: 0.20977042680717817

Training loss 48910.109375

Recall on (sampled) validation set: 0.21374511732134238

Training loss 48910.63671875

Recall on (sampled) validation set: 0.209578940384748

Training loss 48910.43359375

Recall on (sampled) validation set: 0.21491808369757553

Training loss 48910.3359375

Recall on (sampled) validation set: 0.21317895596706848

Training loss 48910.3359375

Recall on (sampled) validation set: 0.20846086109561607

Training loss 48910.39453125

Recall on (sampled) validation set: 0.21645801306645227

Training loss 48910.21484375

Recall on (sampled) validation set: 0.21920508908984407

Training loss 48910.4765625

Recall on (sampled) validation set: 0.21714514756937622

Training loss 48910.05078125

Recall on (sampled) validation set: 0.21983906431002617

Training loss 48910.2265625

Recall on (sampled) validation set: 0.22605805483754665

Training loss 48909.88671875

Recall on (sampled) validation set: 0.22551370545835156

Training loss 48909.98828125

Recall on (sampled) validation set: 0.22643169007506578

Training loss 48909.83984375

Recall on (sampled) validation set: 0.22209999681369919

Training loss 48909.94140625

Recall on (sampled) validation set: 0.2190351907284757

Training loss 48909.48828125

Recall on (sampled) validation set: 0.23006522794272344

Training loss 48909.75

Recall on (sampled) validation set: 0.2225396415106034

Training loss 48909.83984375

Recall on (sampled) validation set: 0.22114932467881648

Training loss 48909.74609375

Recall on (sampled) validation set: 0.22343113072650278

Training loss 48909.28515625

Recall on (sampled) validation set: 0.22526461289936792

Training loss 48909.328125

Recall on (sampled) validation set: 0.22616569528139402

Training loss 48909.06640625

Recall on (sampled) validation set: 0.22036220143706534

Training loss 48908.8984375

Recall on (sampled) validation set: 0.22096110792481027

Training loss 48909.12890625

Recall on (sampled) validation set: 0.22513426809797044

Training loss 48909.44921875

Recall on (sampled) validation set: 0.2179995111428868

Training loss 48908.90625

Recall on (sampled) validation set: 0.22815954746671627

Training loss 48908.875

Recall on (sampled) validation set: 0.22872659727514535

Training loss 48909.05078125

Recall on (sampled) validation set: 0.22060650930705378

Training loss 48908.93359375

Recall on (sampled) validation set: 0.2177587839330126

Training loss 48909.296875

Recall on (sampled) validation set: 0.22674299079290003

Training loss 48908.74609375

Recall on (sampled) validation set: 0.2343855908492932

Training loss 48908.7265625

Recall on (sampled) validation set: 0.231921900056655

Training loss 48909.35546875

Recall on (sampled) validation set: 0.22618107071056254

Training loss 48908.50390625

Recall on (sampled) validation set: 0.23268272256747755

Training loss 48909.11328125

Recall on (sampled) validation set: 0.2343908264216794

Training loss 48908.51171875

Recall on (sampled) validation set: 0.23547324052904814

Training loss 48908.7734375

Recall on (sampled) validation set: 0.23453172006121187

Training loss 48908.765625

Recall on (sampled) validation set: 0.23178350875447062

Training loss 48908.56640625

Recall on (sampled) validation set: 0.22815578021158786

Training loss 48908.34375

Recall on (sampled) validation set: 0.22961517708613896

Training loss 48908.56640625

Recall on (sampled) validation set: 0.22879541351637536

Training loss 48908.44140625

Recall on (sampled) validation set: 0.23127873192210763

Training loss 48908.23046875

Recall on (sampled) validation set: 0.23478798572537224

Training loss 48908.859375

Recall on (sampled) validation set: 0.2255035245724901

Training loss 48908.44921875

Recall on (sampled) validation set: 0.23205455732678962

Training loss 48908.5390625

Recall on (sampled) validation set: 0.23066569719518906

Training loss 48907.85546875

Recall on (sampled) validation set: 0.22909500518302697

Training loss 48908.1015625

Recall on (sampled) validation set: 0.226181359441795

Training loss 48908.19140625

Recall on (sampled) validation set: 0.22664591882876817

Training loss 48908.0546875

Recall on (sampled) validation set: 0.23157012327928844

Training loss 48908.46875

Recall on (sampled) validation set: 0.233379635303864

Training loss 48908.18359375

Recall on (sampled) validation set: 0.2301973044767963

Training loss 48907.6796875

Recall on (sampled) validation set: 0.22723794612996065

Training loss 48907.875

Recall on (sampled) validation set: 0.23359860155640558

Training loss 48907.66015625

Recall on (sampled) validation set: 0.23595094073769207

Training loss 48907.48046875

Recall on (sampled) validation set: 0.23000924354599492

Training loss 48907.62109375

Recall on (sampled) validation set: 0.23547275271277088

Training loss 48908.03125

Recall on (sampled) validation set: 0.23471147451728214

Training loss 48907.6015625

Recall on (sampled) validation set: 0.2412800170858247

Training loss 48907.2734375

Recall on (sampled) validation set: 0.23612529516930603

Training loss 48907.58984375

Recall on (sampled) validation set: 0.22587370410056432

Training loss 48907.53515625

Recall on (sampled) validation set: 0.22490064454265904

Training loss 48907.23046875

Recall on (sampled) validation set: 0.2277554631461165

Training loss 48907.44921875

Recall on (sampled) validation set: 0.22717306802560888

Training loss 48907.41015625

Recall on (sampled) validation set: 0.23115955330882737

Training loss 48907.2890625

Recall on (sampled) validation set: 0.22346659512766592

Training loss 48906.953125

Recall on (sampled) validation set: 0.22611731675933128

Training loss 48907.18359375

Recall on (sampled) validation set: 0.2276923167744402

Training loss 48907.0859375

Recall on (sampled) validation set: 0.22821995580207927

Training loss 48907.578125

Recall on (sampled) validation set: 0.226585530739342

Training loss 48907.4765625

Recall on (sampled) validation set: 0.22935964798124506

Training loss 48906.96484375

Recall on (sampled) validation set: 0.22181231575106347

Training loss 48906.86328125

Recall on (sampled) validation set: 0.22730094060674824

Training loss 48907.109375

Recall on (sampled) validation set: 0.23011164552997584

Training loss 48907.0390625

Recall on (sampled) validation set: 0.22281698259057606

Training loss 48907.234375

Recall on (sampled) validation set: 0.21945169437002468

Training loss 48906.80859375

Recall on (sampled) validation set: 0.2247678635809307

Training loss 48906.9765625

Recall on (sampled) validation set: 0.2179371654929731

Training loss 48906.7734375

Recall on (sampled) validation set: 0.2309900209859375

Training loss 48906.88671875

Recall on (sampled) validation set: 0.22577523048303447

Training loss 48906.96484375

Recall on (sampled) validation set: 0.23048513023240788

Training loss 48906.6796875

Recall on (sampled) validation set: 0.22895566262399294

Training loss 48906.53515625

Recall on (sampled) validation set: 0.22654828838903246

Training loss 48906.984375

Recall on (sampled) validation set: 0.22534349937888956

Training loss 48906.71484375

Recall on (sampled) validation set: 0.23292848456913792

Training loss 48906.69140625

Recall on (sampled) validation set: 0.21826660259146644

Training loss 48906.76171875

Recall on (sampled) validation set: 0.23198485655972045

Training loss 48906.828125

Recall on (sampled) validation set: 0.22237150892731658

Training loss 48906.6640625

Recall on (sampled) validation set: 0.2268990248173551

Training loss 48906.24609375

Recall on (sampled) validation set: 0.22358663006349033

Training loss 48906.73046875

Recall on (sampled) validation set: 0.22007375304335378

Training loss 48906.734375

Recall on (sampled) validation set: 0.22563540338131985

Training loss 48906.3203125

Recall on (sampled) validation set: 0.21684277787816805

Training loss 48906.28125

Recall on (sampled) validation set: 0.22509179056139128

Training loss 48906.63671875

Recall on (sampled) validation set: 0.2263537221667893

Training loss 48906.6015625

Recall on (sampled) validation set: 0.22262479758260156

Training loss 48906.4765625

Recall on (sampled) validation set: 0.22929969669035002

Training loss 48906.3046875

Recall on (sampled) validation set: 0.22423778446464473

Training loss 48906.203125

Recall on (sampled) validation set: 0.22786072831853232

Training loss 48906.2265625

Recall on (sampled) validation set: 0.21855740928426953

Training loss 48906.30078125

Recall on (sampled) validation set: 0.21905921303607329

Training loss 48906.328125

Recall on (sampled) validation set: 0.2288892275970316

Training loss 48906.16015625

Recall on (sampled) validation set: 0.23365833230760633

Training loss 48906.21875

Recall on (sampled) validation set: 0.23047595172186822

Training loss 48906.40625

Recall on (sampled) validation set: 0.22667159626687758

Training loss 48905.90625

Recall on (sampled) validation set: 0.22803735915895623

Training loss 48906.359375

Recall on (sampled) validation set: 0.22647892545714682

Training loss 48906.0

Recall on (sampled) validation set: 0.22998497048088698

Training loss 48905.96875

Recall on (sampled) validation set: 0.23859566388105408

Training loss 48905.8203125

Recall on (sampled) validation set: 0.2344408869177472

Training loss 48905.8359375

Recall on (sampled) validation set: 0.22831492087934918

Training loss 48906.078125

Recall on (sampled) validation set: 0.22076507644066623

Training loss 48906.39453125

Recall on (sampled) validation set: 0.22511962922806844

Training loss 48905.96484375

Recall on (sampled) validation set: 0.22786579781044392

Training loss 48905.80078125

Recall on (sampled) validation set: 0.22607973783291385

Training loss 48905.80859375

Recall on (sampled) validation set: 0.22703598424832544

Training loss 48905.6953125

Recall on (sampled) validation set: 0.22845980175971103

Training loss 48906.015625

Recall on (sampled) validation set: 0.23489754384218992

Training loss 48906.0390625

Recall on (sampled) validation set: 0.22897924037715328

Training loss 48905.984375

Recall on (sampled) validation set: 0.23002213955299255

Training loss 48905.33984375

Recall on (sampled) validation set: 0.22289891482450466

Training loss 48905.24609375

Recall on (sampled) validation set: 0.22055331597890582

Training loss 48905.68359375

Recall on (sampled) validation set: 0.2295724658651156

Training loss 48905.71484375

Recall on (sampled) validation set: 0.22838429494146373

Training loss 48905.73828125

Recall on (sampled) validation set: 0.22793105172370143

Training loss 48905.453125

Recall on (sampled) validation set: 0.22275960036803952

Training loss 48905.4609375

Recall on (sampled) validation set: 0.23192455821720795

Training loss 48905.23046875

Recall on (sampled) validation set: 0.22877218472862756

Training loss 48905.26953125

Recall on (sampled) validation set: 0.22862297091562064

Training loss 48905.37890625

Recall on (sampled) validation set: 0.2288974070058462

Training loss 48905.21484375

Recall on (sampled) validation set: 0.21270633109244722

Training loss 48905.328125

Recall on (sampled) validation set: 0.2121760280621442

Training loss 48905.26953125

Recall on (sampled) validation set: 0.21943610222875198

Training loss 48905.046875

Recall on (sampled) validation set: 0.2220962753889251

Training loss 48904.921875

Recall on (sampled) validation set: 0.2218754961681459

Training loss 48905.53125

Recall on (sampled) validation set: 0.22463216448470533

Training loss 48904.96484375

Recall on (sampled) validation set: 0.22468498784605861

Training loss 48904.890625

Recall on (sampled) validation set: 0.2236822708111274

Training loss 48905.25

Recall on (sampled) validation set: 0.22219439948704917

Training loss 48905.15625

Recall on (sampled) validation set: 0.23325211954476927

Training loss 48905.078125

Recall on (sampled) validation set: 0.2219102099923334

Training loss 48905.109375

Recall on (sampled) validation set: 0.22724802623940557

Training loss 48904.81640625

Recall on (sampled) validation set: 0.22786394102637297

Training loss 48904.515625

Recall on (sampled) validation set: 0.2298759708396732

Training loss 48904.78125

Recall on (sampled) validation set: 0.23075311270365717

Training loss 48904.453125

Recall on (sampled) validation set: 0.2301833871076158

Training loss 48905.28515625

Recall on (sampled) validation set: 0.21649161195395314

Training loss 48904.81640625

Recall on (sampled) validation set: 0.22668236967374894

Training loss 48904.91015625

Recall on (sampled) validation set: 0.2281879099088718

Training loss 48904.37890625

Recall on (sampled) validation set: 0.22691580200064773

Training loss 48904.7265625

Recall on (sampled) validation set: 0.2285915895625515

Training loss 48904.51171875

Recall on (sampled) validation set: 0.22863091135187322

Training loss 48904.5859375

Recall on (sampled) validation set: 0.2261650457998008

Training loss 48904.67578125

Recall on (sampled) validation set: 0.22655249168724667

Training loss 48904.7734375

Recall on (sampled) validation set: 0.22999249320619555

Training loss 48904.55859375

Recall on (sampled) validation set: 0.22571445354067857

Training loss 48904.37890625

Recall on (sampled) validation set: 0.22084542098017598

Training loss 48904.484375

Recall on (sampled) validation set: 0.2262431466161049

Training loss 48904.25

Recall on (sampled) validation set: 0.22674174879029688

Training loss 48904.58984375

Recall on (sampled) validation set: 0.22906836470311967

Training loss 48904.4453125

Recall on (sampled) validation set: 0.23301343571398017

Training loss 48904.5546875

Recall on (sampled) validation set: 0.21775814230805157

Training loss 48904.49609375

Recall on (sampled) validation set: 0.21940953961008408

Training loss 48904.24609375

Recall on (sampled) validation set: 0.22191725220400352

Training loss 48904.3359375

Recall on (sampled) validation set: 0.21967600514696703

Training loss 48904.3515625

Recall on (sampled) validation set: 0.22392814673395434

Training loss 48904.2265625

Recall on (sampled) validation set: 0.2239624828354411

Training loss 48904.28515625

Recall on (sampled) validation set: 0.2248354338912415

Training loss 48904.015625

Recall on (sampled) validation set: 0.22819656006089764

Training loss 48904.2734375

Recall on (sampled) validation set: 0.23080845748994572

Training loss 48903.80859375

Recall on (sampled) validation set: 0.24190022491792

Training loss 48904.5234375

Recall on (sampled) validation set: 0.2403036878594955

Training loss 48903.98046875

Recall on (sampled) validation set: 0.23128327698382145

Training loss 48904.4296875

Recall on (sampled) validation set: 0.23315802458951276

Training loss 48904.21875

Recall on (sampled) validation set: 0.22279389063917193

Training loss 48903.99609375

Recall on (sampled) validation set: 0.2213709393214838

Training loss 48903.85546875

Recall on (sampled) validation set: 0.23161402810404624

Training loss 48904.13671875

Recall on (sampled) validation set: 0.23378466302468118

Training loss 48904.05078125

Recall on (sampled) validation set: 0.2260743305058187

Training loss 48904.01953125

Recall on (sampled) validation set: 0.22035449669977802

Training loss 48903.85546875

Recall on (sampled) validation set: 0.22481155234830372

Training loss 48903.46484375

Recall on (sampled) validation set: 0.22958522503576947

Training loss 48903.92578125

Recall on (sampled) validation set: 0.2208438260838442

Training loss 48903.875

Recall on (sampled) validation set: 0.22485088919617047

Training loss 48903.68359375

Recall on (sampled) validation set: 0.22241293825821956

Training loss 48903.80078125

Recall on (sampled) validation set: 0.2272873899307656

Training loss 48903.60546875

Recall on (sampled) validation set: 0.22415767889769705

Training loss 48903.34375

Recall on (sampled) validation set: 0.21782707967236098

Training loss 48903.8203125

Recall on (sampled) validation set: 0.22561054237823744

Training loss 48903.51171875

Recall on (sampled) validation set: 0.23083235409142844

Training loss 48903.421875

Recall on (sampled) validation set: 0.22347117096118913

Training loss 48903.515625

Recall on (sampled) validation set: 0.22322956315379183

Training loss 48903.25

Recall on (sampled) validation set: 0.22749929443078262

Training loss 48903.55078125

Recall on (sampled) validation set: 0.230042671551746

Training loss 48903.0234375

Recall on (sampled) validation set: 0.22328117729887245

Training loss 48903.53515625

Recall on (sampled) validation set: 0.22248702891851707

Training loss 48903.63671875

Recall on (sampled) validation set: 0.22277718220141082

Training loss 48903.5703125

Recall on (sampled) validation set: 0.23253806167281663

Training loss 48903.4140625

Recall on (sampled) validation set: 0.23173292382820515

Training loss 48903.18359375

Recall on (sampled) validation set: 0.2331894818900263

Training loss 48903.36328125

Recall on (sampled) validation set: 0.22939622982045849

Training loss 48903.2265625

Recall on (sampled) validation set: 0.23212557997222244

Training loss 48903.14453125

Recall on (sampled) validation set: 0.23367470618378056

Training loss 48902.87890625

Recall on (sampled) validation set: 0.22814205271101826

Training loss 48903.11328125

Recall on (sampled) validation set: 0.2281911867792085

Training loss 48903.171875

Recall on (sampled) validation set: 0.23201555111219355

Training loss 48902.74609375

Recall on (sampled) validation set: 0.23069550072499254

Training loss 48903.00390625

Recall on (sampled) validation set: 0.2221307175549462

Training loss 48903.1015625

Recall on (sampled) validation set: 0.23553220979128417

Training loss 48903.26171875

Recall on (sampled) validation set: 0.227421691201183

Training loss 48903.01953125

Recall on (sampled) validation set: 0.23086928746456872

Training loss 48902.5703125

Recall on (sampled) validation set: 0.22238049364092916

Training loss 48902.75

Recall on (sampled) validation set: 0.2268540220282507

Training loss 48902.296875

Recall on (sampled) validation set: 0.2265365237370682

Training loss 48902.84375

Recall on (sampled) validation set: 0.2329405150371575

Training loss 48902.6796875

Recall on (sampled) validation set: 0.22744326420369979

Training loss 48902.4765625

Recall on (sampled) validation set: 0.23075112109776355

Training loss 48902.56640625

Recall on (sampled) validation set: 0.22733811103865548

Training loss 48902.546875

Recall on (sampled) validation set: 0.2309588635468853

Training loss 48902.7890625

Recall on (sampled) validation set: 0.2342934428111379

Training loss 48902.71484375

Recall on (sampled) validation set: 0.23436773054195925

Training loss 48902.4609375

Recall on (sampled) validation set: 0.22327522655471835

Training loss 48902.41015625

Recall on (sampled) validation set: 0.2244546334051779

Training loss 48902.53515625

Recall on (sampled) validation set: 0.22168844786993608

Training loss 48902.61328125

Recall on (sampled) validation set: 0.21060125627548493

Training loss 48902.76953125

Recall on (sampled) validation set: 0.2247077345924896

Training loss 48902.66015625

Recall on (sampled) validation set: 0.22203682071104935

Training loss 48902.50390625

Recall on (sampled) validation set: 0.21801992049088237

Training loss 48902.609375

Recall on (sampled) validation set: 0.21867598856074358

Training loss 48902.58984375

Recall on (sampled) validation set: 0.21664904620485384

Training loss 48902.30078125

Recall on (sampled) validation set: 0.21470766257336132

Training loss 48902.26171875

Recall on (sampled) validation set: 0.2204053766862297

Training loss 48902.48828125

Recall on (sampled) validation set: 0.22223902493956943

Training loss 48902.18359375

Recall on (sampled) validation set: 0.22365321371174365

Training loss 48902.33984375

Recall on (sampled) validation set: 0.21450164880155806

Training loss 48902.07421875

Recall on (sampled) validation set: 0.22667586831062328

Training loss 48902.26953125

Recall on (sampled) validation set: 0.22602006212850131

Training loss 48902.0703125

Recall on (sampled) validation set: 0.21754122134839013

Training loss 48901.9765625

Recall on (sampled) validation set: 0.21629971960552724

Training loss 48902.01953125

Recall on (sampled) validation set: 0.21047422391750886

Training loss 48902.19140625

Recall on (sampled) validation set: 0.21465989643212874

Training loss 48902.19921875

Recall on (sampled) validation set: 0.21315230561600798

Training loss 48902.0546875

Recall on (sampled) validation set: 0.21300728789930243

Training loss 48902.1015625

Recall on (sampled) validation set: 0.21870486517582705

Training loss 48902.36328125

Recall on (sampled) validation set: 0.21551744979830278

Training loss 48902.0234375

Recall on (sampled) validation set: 0.21361940531405138

Training loss 48901.921875

Recall on (sampled) validation set: 0.21629613501709688

Training loss 48901.98828125

Recall on (sampled) validation set: 0.20753806167281666

Training loss 48902.2734375

Recall on (sampled) validation set: 0.21957812787803713

Training loss 48901.53515625

Recall on (sampled) validation set: 0.21310366913452214

Training loss 48901.84375

Recall on (sampled) validation set: 0.21574697956140787

Training loss 48902.30859375

Recall on (sampled) validation set: 0.22466240029715526

Training loss 48902.41015625

Recall on (sampled) validation set: 0.21692505187559633

Training loss 48902.171875

Recall on (sampled) validation set: 0.2164533890019371

Training loss 48901.69921875

Recall on (sampled) validation set: 0.21016050161104607

Training loss 48902.12890625

Recall on (sampled) validation set: 0.21482298396635963

Training loss 48901.81640625

Recall on (sampled) validation set: 0.2174291087349164

Training loss 48902.37890625

Recall on (sampled) validation set: 0.2201231014230107

Training loss 48901.81640625

Recall on (sampled) validation set: 0.22004001099055542

Training loss 48901.87109375

Recall on (sampled) validation set: 0.21813851875421747

Training loss 48901.73828125

Recall on (sampled) validation set: 0.20847774587112156

Training loss 48901.4453125

Recall on (sampled) validation set: 0.21024007554588317

Training loss 48901.98046875

Recall on (sampled) validation set: 0.21013339623003868

Training loss 48902.0390625

Recall on (sampled) validation set: 0.2205617588031381

Training loss 48901.75390625

Recall on (sampled) validation set: 0.22073973771069963

Training loss 48901.62890625

Recall on (sampled) validation set: 0.22363299750595578

Training loss 48901.87109375

Recall on (sampled) validation set: 0.2237718911961199

Training loss 48901.76953125

Recall on (sampled) validation set: 0.22679496416066292

Training loss 48901.59375

Recall on (sampled) validation set: 0.22211215080543573

Training loss 48901.875

Recall on (sampled) validation set: 0.22747870634440506

Training loss 48901.37890625

Recall on (sampled) validation set: 0.21816276104751603

Training loss 48901.40625

Recall on (sampled) validation set: 0.2181949311191598

Training loss 48901.23046875

Recall on (sampled) validation set: 0.21601825204774386

Training loss 48900.953125

Recall on (sampled) validation set: 0.21531519935331184

Training loss 48901.7265625

Recall on (sampled) validation set: 0.21415198196641028

Training loss 48901.57421875

Recall on (sampled) validation set: 0.2210648774496324

Training loss 48901.78125

Recall on (sampled) validation set: 0.21540339812436002

Training loss 48901.359375

Recall on (sampled) validation set: 0.21558619489336364

Training loss 48901.4453125

Recall on (sampled) validation set: 0.22184617412566596

Training loss 48901.46875

Recall on (sampled) validation set: 0.21919553236976105

Training loss 48901.09375

Recall on (sampled) validation set: 0.21635041605232166

Training loss 48901.421875

Recall on (sampled) validation set: 0.21547740017930578

Training loss 48901.53125

Recall on (sampled) validation set: 0.21697453643687767

Training loss 48901.5234375

Recall on (sampled) validation set: 0.21491676727520645

Training loss 48901.51953125

Recall on (sampled) validation set: 0.21347076983646857

Training loss 48901.421875

Recall on (sampled) validation set: 0.2205342453137371

Training loss 48901.05859375

Recall on (sampled) validation set: 0.21533262536347839

Training loss 48901.1640625

Recall on (sampled) validation set: 0.22269046680616555

Training loss 48901.65625

Recall on (sampled) validation set: 0.21882542541480832

Training loss 48901.3984375

Recall on (sampled) validation set: 0.22674468935312855

Training loss 48901.0703125

Recall on (sampled) validation set: 0.2235725164967452

Training loss 48901.30859375

Recall on (sampled) validation set: 0.21578006820429688

Training loss 48901.06640625

Recall on (sampled) validation set: 0.21952030262874178

Training loss 48901.2734375

Recall on (sampled) validation set: 0.21614692120409

Training loss 48900.99609375

Recall on (sampled) validation set: 0.22248824407762702

Training loss 48901.75

Recall on (sampled) validation set: 0.2225822480268941

Training loss 48901.0546875

Recall on (sampled) validation set: 0.22423353140776006

Training loss 48901.23828125

Recall on (sampled) validation set: 0.22346021947065503

Training loss 48901.61328125

Recall on (sampled) validation set: 0.22427816711755005

Training loss 48901.43359375

Recall on (sampled) validation set: 0.21806938366466497

Training loss 48901.2109375

Recall on (sampled) validation set: 0.22373911354492113

Training loss 48901.1015625

Recall on (sampled) validation set: 0.21415934734083555

Training loss 48901.4765625

Recall on (sampled) validation set: 0.21193643373498186

Training loss 48901.17578125

Recall on (sampled) validation set: 0.21962551515500697

Training loss 48901.51953125

Recall on (sampled) validation set: 0.22204870217166042

Training loss 48900.921875

Recall on (sampled) validation set: 0.2099653206073351

Training loss 48901.15625

Recall on (sampled) validation set: 0.21726961822878338

Training loss 48901.16015625

Recall on (sampled) validation set: 0.21791206486260933

Training loss 48901.06640625

Recall on (sampled) validation set: 0.21043608324189086

Training loss 48900.67578125

Recall on (sampled) validation set: 0.2142719418277494

Training loss 48901.03125

Recall on (sampled) validation set: 0.2199743227801304

Training loss 48901.125

Recall on (sampled) validation set: 0.22592190005665505

Training loss 48901.0546875

Recall on (sampled) validation set: 0.2250098282103727

Training loss 48900.87109375

Recall on (sampled) validation set: 0.21801024592131674

Training loss 48901.12890625

Recall on (sampled) validation set: 0.2089348490959199

Training loss 48901.1484375

Recall on (sampled) validation set: 0.20358557072758524

Training loss 48900.78125

Recall on (sampled) validation set: 0.201304633274234

Training loss 48900.921875

Recall on (sampled) validation set: 0.2154993664499109

Training loss 48900.81640625

Recall on (sampled) validation set: 0.20579336293537748

Training loss 48900.6796875

Recall on (sampled) validation set: 0.20916603311657758

Training loss 48901.07421875

Recall on (sampled) validation set: 0.2163611041274381

Training loss 48900.8203125

Recall on (sampled) validation set: 0.2130988536737176

Training loss 48900.74609375

Recall on (sampled) validation set: 0.20431341306069076

Training loss 48900.890625

Recall on (sampled) validation set: 0.211026354636155

Training loss 48901.21484375

Recall on (sampled) validation set: 0.2091633179954414

Training loss 48900.7265625

Recall on (sampled) validation set: 0.2105146128993679

Training loss 48900.984375

Recall on (sampled) validation set: 0.21000916367023448

Training loss 48900.828125

Recall on (sampled) validation set: 0.21188846419427185

Training loss 48900.546875

Recall on (sampled) validation set: 0.20900291699293516

Training loss 48900.44140625

Recall on (sampled) validation set: 0.20151858115333615

Training loss 48900.5859375

Recall on (sampled) validation set: 0.20822658221660037

Training loss 48900.5

Recall on (sampled) validation set: 0.2049827378879103

Training loss 48901.03125

Recall on (sampled) validation set: 0.21261595363364874

Training loss 48900.5

Recall on (sampled) validation set: 0.2088424590298456

Training loss 48900.6640625

Recall on (sampled) validation set: 0.20990722321303082

Training loss 48900.8359375

Recall on (sampled) validation set: 0.20650010606453437

Training loss 48900.62109375

Recall on (sampled) validation set: 0.21068314027842158

Training loss 48900.48828125

Recall on (sampled) validation set: 0.20944001352213695

Training loss 48900.59375

Recall on (sampled) validation set: 0.2092369457691599

Training loss 48900.33984375

Recall on (sampled) validation set: 0.21307662398769478

Training loss 48900.578125

Recall on (sampled) validation set: 0.21166248257355336

Training loss 48900.78515625

Recall on (sampled) validation set: 0.214567590170131

Training loss 48900.43359375

Recall on (sampled) validation set: 0.20787300888934282

Training loss 48900.2265625

Recall on (sampled) validation set: 0.20841748790296885

Training loss 48900.26171875

Recall on (sampled) validation set: 0.21184523111156506

Training loss 48900.265625

Recall on (sampled) validation set: 0.2194313784286561

Training loss 48900.61328125

Recall on (sampled) validation set: 0.21695755738178604

Training loss 48900.33984375

Recall on (sampled) validation set: 0.2156310972921681

Training loss 48899.99609375

Recall on (sampled) validation set: 0.214094813400621

Training loss 48900.63671875

Recall on (sampled) validation set: 0.21520687778310285

Training loss 48900.60546875

Recall on (sampled) validation set: 0.20827928581467597

Training loss 48900.7734375

Recall on (sampled) validation set: 0.2107380882544222

Training loss 48900.30078125

Recall on (sampled) validation set: 0.2220158660322

Training loss 48900.328125

Recall on (sampled) validation set: 0.2256585143195851

Training loss 48900.4609375

Recall on (sampled) validation set: 0.2151380464833278

Training loss 48900.0234375

Recall on (sampled) validation set: 0.21263695637561336

Training loss 48900.40625

Recall on (sampled) validation set: 0.22673028858282943

Training loss 48900.62890625

Recall on (sampled) validation set: 0.2197213798166611

Training loss 48900.23828125

Recall on (sampled) validation set: 0.22145290952913455

Training loss 48900.01953125

Recall on (sampled) validation set: 0.22084228814809578

Training loss 48900.1015625

Recall on (sampled) validation set: 0.22237965429072507

Training loss 48900.1015625

Recall on (sampled) validation set: 0.21692873925496428

Training loss 48900.390625

Recall on (sampled) validation set: 0.21888313281462105

Training loss 48900.171875

Recall on (sampled) validation set: 0.22468832761981583

Training loss 48900.23828125

Recall on (sampled) validation set: 0.22039721713723529

Training loss 48900.42578125

Recall on (sampled) validation set: 0.21706896115244576

Training loss 48899.94921875

Recall on (sampled) validation set: 0.21990595502165378

Training loss 48899.85546875

Recall on (sampled) validation set: 0.2168201763115556

Training loss 48900.578125

Recall on (sampled) validation set: 0.21742871633978708

Training loss 48900.140625

Recall on (sampled) validation set: 0.217054603157144

Training loss 48899.9609375

Recall on (sampled) validation set: 0.21821919305403875

Training loss 48900.1484375

Recall on (sampled) validation set: 0.221114388854407

Training loss 48899.87890625

Recall on (sampled) validation set: 0.2179098663150387

Training loss 48899.96484375

Recall on (sampled) validation set: 0.22338474276949777

Training loss 48900.06640625

Recall on (sampled) validation set: 0.22124189348327283

Training loss 48900.19140625

Recall on (sampled) validation set: 0.21749927544392156

Training loss 48900.3515625

Recall on (sampled) validation set: 0.2185594186179485

Training loss 48900.36328125

Recall on (sampled) validation set: 0.21906676980678796

Training loss 48900.24609375

Recall on (sampled) validation set: 0.2227823846013501

Training loss 48900.2890625

Recall on (sampled) validation set: 0.22567955568999123

Training loss 48899.7734375

Recall on (sampled) validation set: 0.22337210144832648

Training loss 48900.10546875

Recall on (sampled) validation set: 0.2191785454580373

Training loss 48899.9453125

Recall on (sampled) validation set: 0.21666301813397998

Training loss 48899.80859375

Recall on (sampled) validation set: 0.21504567540411462

Training loss 48899.75390625

Recall on (sampled) validation set: 0.21781109906427512

Training loss 48899.75

Recall on (sampled) validation set: 0.21575742080733004

Training loss 48899.734375

Recall on (sampled) validation set: 0.21802841634738182

Training loss 48899.86328125

Recall on (sampled) validation set: 0.22069789699780623

Training loss 48899.81640625

Recall on (sampled) validation set: 0.22040027795018716

Training loss 48899.80859375

Recall on (sampled) validation set: 0.22140034276740267

Training loss 48899.53515625

Recall on (sampled) validation set: 0.22124393620763858

Training loss 48899.640625

Recall on (sampled) validation set: 0.22169886925603804

Training loss 48899.953125

Recall on (sampled) validation set: 0.21981736232779792

Training loss 48899.49609375

Recall on (sampled) validation set: 0.22196483567853803

Training loss 48899.640625

Recall on (sampled) validation set: 0.22094877039341648

Training loss 48899.703125

Recall on (sampled) validation set: 0.21606515592359515

Training loss 48899.671875

Recall on (sampled) validation set: 0.21819502605346525

Training loss 48899.87109375

Recall on (sampled) validation set: 0.21537606970229475

Training loss 48899.40625

Recall on (sampled) validation set: 0.2196730353400045

Training loss 48899.71875

Recall on (sampled) validation set: 0.215906634620337

Training loss 48899.53515625

Recall on (sampled) validation set: 0.21537502542493467

Training loss 48899.421875

Recall on (sampled) validation set: 0.2155973844835006

Training loss 48899.25

Recall on (sampled) validation set: 0.21557322926787534

Training loss 48899.2734375

Recall on (sampled) validation set: 0.21923996795367032

Training loss 48899.53125

Recall on (sampled) validation set: 0.2163287623010853

Training loss 48899.65625

Recall on (sampled) validation set: 0.22122409493779732

Training loss 48899.50390625

Recall on (sampled) validation set: 0.2174918214641445

Training loss 48899.62890625

Recall on (sampled) validation set: 0.21817250763621

Training loss 48899.80859375

Recall on (sampled) validation set: 0.2148829619328712

Training loss 48899.44921875

Recall on (sampled) validation set: 0.22096246384857995

Training loss 48899.2265625

Recall on (sampled) validation set: 0.21553916683907612

Training loss 48899.60546875

Recall on (sampled) validation set: 0.21787071147915066

Training loss 48899.51171875

Recall on (sampled) validation set: 0.21844631716001953

Training loss 48899.5546875

Recall on (sampled) validation set: 0.21783520604890838

Training loss 48899.109375

Recall on (sampled) validation set: 0.213156843475809

Training loss 48899.39453125

Recall on (sampled) validation set: 0.21436708891699813

Training loss 48899.05078125

Recall on (sampled) validation set: 0.22289089844080767

Training loss 48899.2265625

Recall on (sampled) validation set: 0.2156820239819332

Training loss 48899.3515625

Recall on (sampled) validation set: 0.21607754321365935

Training loss 48899.19140625

Recall on (sampled) validation set: 0.21393996048986974

Training loss 48899.3046875

Recall on (sampled) validation set: 0.21373097402362376

Training loss 48899.25

Recall on (sampled) validation set: 0.2089254453115615

Training loss 48899.38671875

Recall on (sampled) validation set: 0.22108158348675588

Training loss 48899.140625

Recall on (sampled) validation set: 0.21108384292322588

Training loss 48899.203125

Recall on (sampled) validation set: 0.21532740637731565

Training loss 48899.4453125

Recall on (sampled) validation set: 0.21977760776898705

Training loss 48899.37890625

Recall on (sampled) validation set: 0.2165840517786979

Training loss 48899.08984375

Recall on (sampled) validation set: 0.21754047300417534

Training loss 48899.296875

Recall on (sampled) validation set: 0.2160033025722681

Training loss 48899.30078125

Recall on (sampled) validation set: 0.21972574679471232

Training loss 48899.109375

Recall on (sampled) validation set: 0.22379782676152915

Training loss 48899.28515625

Recall on (sampled) validation set: 0.21710169248644745

Training loss 48899.1796875

Recall on (sampled) validation set: 0.21681309814068433

Training loss 48899.25

Recall on (sampled) validation set: 0.21585647717544268

Training loss 48899.01953125

Recall on (sampled) validation set: 0.224128388013143

Training loss 48899.375

Recall on (sampled) validation set: 0.2221334385181935

Training loss 48899.2734375

Recall on (sampled) validation set: 0.22172157552738317

Training loss 48899.375

Recall on (sampled) validation set: 0.21648733663661066

Training loss 48899.1015625

Recall on (sampled) validation set: 0.21159311042523385

Training loss 48899.05078125

Recall on (sampled) validation set: 0.2109711899480502

Training loss 48899.296875

Recall on (sampled) validation set: 0.21691732422313184

Training loss 48899.12890625

Recall on (sampled) validation set: 0.2112018501932295

Training loss 48899.21875

Recall on (sampled) validation set: 0.21904992846099924

Training loss 48898.9609375

Recall on (sampled) validation set: 0.21439709208583982

Training loss 48898.80859375

Recall on (sampled) validation set: 0.21737341154174183

Training loss 48899.3984375

Recall on (sampled) validation set: 0.2120799126429798

Training loss 48898.8046875

Recall on (sampled) validation set: 0.21825846901300622

Training loss 48898.94140625

Recall on (sampled) validation set: 0.21261463961191726

Training loss 48898.875

Recall on (sampled) validation set: 0.21073765548493317

Training loss 48898.64453125

Recall on (sampled) validation set: 0.20391692549904894

Training loss 48898.91015625

Recall on (sampled) validation set: 0.2072295821406529

Training loss 48898.7734375

Recall on (sampled) validation set: 0.21354293736780125

Training loss 48898.7265625

Recall on (sampled) validation set: 0.2152860909675792

Training loss 48898.7890625

Recall on (sampled) validation set: 0.20963140108194556

Training loss 48898.44140625

Recall on (sampled) validation set: 0.21242146335884993

Training loss 48899.05078125

Recall on (sampled) validation set: 0.21437325571853705

Training loss 48898.859375

Recall on (sampled) validation set: 0.21073168968223416

Training loss 48898.984375

Recall on (sampled) validation set: 0.20741261940989708

Training loss 48898.39453125

Recall on (sampled) validation set: 0.21128981239235323

Training loss 48898.55859375

Recall on (sampled) validation set: 0.20500820319695096

Training loss 48898.453125

Recall on (sampled) validation set: 0.20528461784904614

Training loss 48898.61328125

Recall on (sampled) validation set: 0.20487436481311255

Training loss 48898.625

Recall on (sampled) validation set: 0.2125555865456047

Training loss 48898.5390625

Recall on (sampled) validation set: 0.22598074426749562

Training loss 48898.484375

Recall on (sampled) validation set: 0.218970301493895

Training loss 48898.8984375

Recall on (sampled) validation set: 0.2135435567323045

Training loss 48898.765625

Recall on (sampled) validation set: 0.20949247421933448

Training loss 48898.41015625

Recall on (sampled) validation set: 0.2111951360463157

Training loss 48898.5546875

Recall on (sampled) validation set: 0.20736492834314976

Training loss 48898.5546875

Recall on (sampled) validation set: 0.20808050516398974

Training loss 48898.859375

Recall on (sampled) validation set: 0.206685658329034

Training loss 48898.43359375

Recall on (sampled) validation set: 0.2181439972274818

Training loss 48898.2734375

Recall on (sampled) validation set: 0.22159707676540705

Training loss 48898.59375

Recall on (sampled) validation set: 0.22192588729748436

Training loss 48898.7109375

Recall on (sampled) validation set: 0.21377091653725044

Training loss 48898.19140625

Recall on (sampled) validation set: 0.2151954476927254

Training loss 48898.0859375

Recall on (sampled) validation set: 0.21815541946122707

Training loss 48898.09375

Recall on (sampled) validation set: 0.22228685437033893

Training loss 48898.69140625

Recall on (sampled) validation set: 0.22031435847542924

Training loss 48898.2265625

Recall on (sampled) validation set: 0.2151276416834493

Training loss 48898.5859375

Recall on (sampled) validation set: 0.22897214321942091

Training loss 48898.8359375

Recall on (sampled) validation set: 0.22210383215963977

Training loss 48898.62890625

Recall on (sampled) validation set: 0.22575497150224913

Training loss 48898.41015625

Recall on (sampled) validation set: 0.2189481968592676

Training loss 48898.6484375

Recall on (sampled) validation set: 0.21223434784278705

Training loss 48898.109375

Recall on (sampled) validation set: 0.21813413518994282

Training loss 48898.31640625

Recall on (sampled) validation set: 0.21722280775955913

Training loss 48898.59375

Recall on (sampled) validation set: 0.21526730903364297

Training loss 48898.46875

Recall on (sampled) validation set: 0.21940541946122713

Training loss 48898.05859375

Recall on (sampled) validation set: 0.2139728077595591

Training loss 48898.1953125

Recall on (sampled) validation set: 0.22109691374028942

Training loss 48898.25390625

Recall on (sampled) validation set: 0.2154507221117929

Training loss 48898.2109375

Recall on (sampled) validation set: 0.21744433859814985

Training loss 48898.51171875

Recall on (sampled) validation set: 0.2163703625137382

Training loss 48898.4609375

Recall on (sampled) validation set: 0.23064470759797434

Training loss 48898.3203125

Recall on (sampled) validation set: 0.2341635307792295

Training loss 48898.41015625

Recall on (sampled) validation set: 0.22597333546335358

Training loss 48898.7265625

Recall on (sampled) validation set: 0.2184810631158181

Training loss 48898.05078125

Recall on (sampled) validation set: 0.2156762899498834

Training loss 48898.12890625

Recall on (sampled) validation set: 0.2197038043122435

Training loss 48898.4453125

Recall on (sampled) validation set: 0.2185979842064234

Training loss 48898.44140625

Recall on (sampled) validation set: 0.23339465783930394

Training loss 48898.15625

Recall on (sampled) validation set: 0.23623227107301517

Training loss 48898.30078125

Recall on (sampled) validation set: 0.22811234220172513

Training loss 48898.23828125

Recall on (sampled) validation set: 0.22595389291759527

Training loss 48898.69921875

Recall on (sampled) validation set: 0.2160285191383195

Training loss 48898.0859375

Recall on (sampled) validation set: 0.22277608489178363

Training loss 48899.00390625

Recall on (sampled) validation set: 0.22122439872757477

Training loss 48898.0859375

Recall on (sampled) validation set: 0.2193546296078057

Training loss 48898.171875

Recall on (sampled) validation set: 0.225991767777158

Training loss 48898.31640625

Recall on (sampled) validation set: 0.2171594067020564

Training loss 48898.19921875

Recall on (sampled) validation set: 0.2171143777241781

Training loss 48898.2265625

Recall on (sampled) validation set: 0.22281039414977707

Training loss 48898.08984375

Recall on (sampled) validation set: 0.21236876368909038

Training loss 48898.25390625

Recall on (sampled) validation set: 0.21307635424332338

Training loss 48898.30078125

Recall on (sampled) validation set: 0.2141415289355398

Training loss 48898.28125

Recall on (sampled) validation set: 0.21986189284601262

Training loss 48898.15625

Recall on (sampled) validation set: 0.217282350555944

Training loss 48897.86328125

Recall on (sampled) validation set: 0.21883185323112728

Training loss 48898.4453125

Recall on (sampled) validation set: 0.21751702423072658

Training loss 48898.296875

Recall on (sampled) validation set: 0.21493929202141543

Training loss 48898.6015625

Recall on (sampled) validation set: 0.22389558819549743

Training loss 48897.63671875

Recall on (sampled) validation set: 0.2128688285063058

Training loss 48898.12109375

Recall on (sampled) validation set: 0.22691965960704616

Training loss 48898.01953125

Recall on (sampled) validation set: 0.21728104439084475

Training loss 48898.23828125

Recall on (sampled) validation set: 0.2202394363215597

Training loss 48898.49609375

Recall on (sampled) validation set: 0.2192988232947398

Training loss 48897.734375

Recall on (sampled) validation set: 0.21888709714027318

Training loss 48898.13671875

Recall on (sampled) validation set: 0.22418889329733246

Training loss 48897.94921875

Recall on (sampled) validation set: 0.223260720592844

Training loss 48898.0859375

Recall on (sampled) validation set: 0.22832771802372528

Training loss 48898.26171875

Recall on (sampled) validation set: 0.2264679052210813

Training loss 48897.91015625

Recall on (sampled) validation set: 0.21861465859877838

Training loss 48898.203125

Recall on (sampled) validation set: 0.22357941505627527

Training loss 48897.984375

Recall on (sampled) validation set: 0.22885201727760712

Training loss 48898.1015625

Recall on (sampled) validation set: 0.2150493208814443

Training loss 48897.85546875

Recall on (sampled) validation set: 0.2270258570494505

Training loss 48897.9765625

Recall on (sampled) validation set: 0.22220526389991

Training loss 48897.83984375

Recall on (sampled) validation set: 0.21640437518386704

Training loss 48897.86328125

Recall on (sampled) validation set: 0.22313446189489747

Training loss 48898.19921875

Recall on (sampled) validation set: 0.22135201727760712

Training loss 48897.60546875

Recall on (sampled) validation set: 0.21464374254165544

Training loss 48897.92578125

Recall on (sampled) validation set: 0.2227012236268135

Training loss 48898.07421875

Recall on (sampled) validation set: 0.22051830027873584

Training loss 48897.53125

Recall on (sampled) validation set: 0.22450459176502732

Training loss 48898.14453125

Recall on (sampled) validation set: 0.22908562375985245

Training loss 48897.8359375

Recall on (sampled) validation set: 0.21251050060714308

Training loss 48897.7265625

Recall on (sampled) validation set: 0.2197327228293653

Training loss 48897.66015625

Recall on (sampled) validation set: 0.2172443539185826

Training loss 48897.62890625

Recall on (sampled) validation set: 0.21813049364092923

Training loss 48897.90625

Recall on (sampled) validation set: 0.21182904317568563

Training loss 48898.078125

Recall on (sampled) validation set: 0.21293762903427152

Training loss 48897.80859375

Recall on (sampled) validation set: 0.20949832217255082

Training loss 48897.91015625

Recall on (sampled) validation set: 0.2244983221725509

Training loss 48897.48828125

Recall on (sampled) validation set: 0.21710560186603745

Training loss 48897.51953125

Recall on (sampled) validation set: 0.22137154690103875

Training loss 48897.85546875

Recall on (sampled) validation set: 0.21698265801214983

Training loss 48897.76171875

Recall on (sampled) validation set: 0.2185028600323519

Training loss 48897.63671875

Recall on (sampled) validation set: 0.21750220334884585

Training loss 48897.71484375

Recall on (sampled) validation set: 0.22372249131187422

Training loss 48897.9140625

Recall on (sampled) validation set: 0.21503956949147512

Training loss 48897.85546875

Recall on (sampled) validation set: 0.21876332179281363

Training loss 48897.69921875

Recall on (sampled) validation set: 0.21306215992785865

Training loss 48897.62109375

Recall on (sampled) validation set: 0.22008582541341165

Training loss 48897.69140625

Recall on (sampled) validation set: 0.21644022630592502

Training loss 48898.03125

Recall on (sampled) validation set: 0.2190456151699346

Training loss 48897.69140625

Recall on (sampled) validation set: 0.2167132992704681

Training loss 48897.55859375

Recall on (sampled) validation set: 0.2152165761408048

Training loss 48897.92578125

Recall on (sampled) validation set: 0.21034924519588766

Training loss 48897.390625

Recall on (sampled) validation set: 0.2159022106817025

Training loss 48897.36328125

Recall on (sampled) validation set: 0.2103962298204585

Training loss 48897.80078125

Recall on (sampled) validation set: 0.20668726828391074

Training loss 48897.58984375

Recall on (sampled) validation set: 0.21642832154402025

Training loss 48898.14453125

Recall on (sampled) validation set: 0.21324984897807037

Training loss 48897.10546875

Recall on (sampled) validation set: 0.2152267760135274

Training loss 48897.48046875

Recall on (sampled) validation set: 0.21058438961388143

Training loss 48897.87890625

Recall on (sampled) validation set: 0.21153438215008086

Training loss 48897.53125

Recall on (sampled) validation set: 0.21009773737722923

Training loss 48897.3046875

Recall on (sampled) validation set: 0.21124539819594265

Training loss 48898.06640625

Recall on (sampled) validation set: 0.2142301327596246

Training loss 48897.24609375

Recall on (sampled) validation set: 0.2106700013705458

Training loss 48897.25390625

Recall on (sampled) validation set: 0.20812793041468175

Training loss 48897.36328125

Recall on (sampled) validation set: 0.21565539567309078

Training loss 48897.68359375

Recall on (sampled) validation set: 0.20807981378035825

Training loss 48897.09375

Recall on (sampled) validation set: 0.2162524992819911

Training loss 48897.3359375

Recall on (sampled) validation set: 0.20985867380921827

Training loss 48897.84375

Recall on (sampled) validation set: 0.2079475386480831

Training loss 48897.38671875

Recall on (sampled) validation set: 0.2098597789754777

Training loss 48897.48046875

Recall on (sampled) validation set: 0.21698325053315978

Training loss 48897.05859375

Recall on (sampled) validation set: 0.22482275852466416

Training loss 48897.36328125

Recall on (sampled) validation set: 0.21882632805454946

Training loss 48897.55078125

Recall on (sampled) validation set: 0.2185004487009932

Training loss 48897.515625

Recall on (sampled) validation set: 0.21595966885168338

Training loss 48897.296875

Recall on (sampled) validation set: 0.2127546906276489

Training loss 48897.48828125

Recall on (sampled) validation set: 0.21158944011893194

Training loss 48897.53515625

Recall on (sampled) validation set: 0.20834866773342273

Training loss 48897.625

Recall on (sampled) validation set: 0.2102552333899884

Training loss 48897.16015625

Recall on (sampled) validation set: 0.21563547452748907

Training loss 48897.37890625

Recall on (sampled) validation set: 0.22136995200470702

Training loss 48897.1015625

Recall on (sampled) validation set: 0.22367381772962536

Training loss 48896.81640625

Recall on (sampled) validation set: 0.2162604207313826

Training loss 48897.125

Recall on (sampled) validation set: 0.21489614994469805

Training loss 48897.01953125

Recall on (sampled) validation set: 0.2063171704446659

Training loss 48897.0859375

Recall on (sampled) validation set: 0.20701425214900715

Training loss 48897.56640625

Recall on (sampled) validation set: 0.21983391887067025

Training loss 48897.0390625

Recall on (sampled) validation set: 0.2134573904283523

Training loss 48897.19921875

Recall on (sampled) validation set: 0.21494992466362703

Training loss 48897.21875

Recall on (sampled) validation set: 0.2115006103663091

Training loss 48896.921875

Recall on (sampled) validation set: 0.21314618503094004

Training loss 48897.09375

Recall on (sampled) validation set: 0.21214150994867872

Training loss 48897.3203125

Recall on (sampled) validation set: 0.22204324901421088

Training loss 48897.37109375

Recall on (sampled) validation set: 0.22152751474847662

Training loss 48897.1796875

Recall on (sampled) validation set: 0.21282307928678165

Training loss 48896.98046875

Recall on (sampled) validation set: 0.2123713098422717

Training loss 48896.98046875

Recall on (sampled) validation set: 0.211405581126543

Training loss 48896.76171875

Recall on (sampled) validation set: 0.2182110646629703

Training loss 48896.96484375

Recall on (sampled) validation set: 0.2231702350549901

Training loss 48896.46484375

Recall on (sampled) validation set: 0.221455668466104

Training loss 48897.40625

Recall on (sampled) validation set: 0.21249693804548617

Training loss 48897.26953125

Recall on (sampled) validation set: 0.20943677261100127

Training loss 48896.875

Recall on (sampled) validation set: 0.20927196665672165

Training loss 48897.1953125

Recall on (sampled) validation set: 0.2076917661554685

Training loss 48897.49609375

Recall on (sampled) validation set: 0.20938068935165122

Training loss 48897.125

Recall on (sampled) validation set: 0.21406431128527317

Training loss 48896.953125

Recall on (sampled) validation set: 0.2163600978238002

Training loss 48896.98828125

Recall on (sampled) validation set: 0.22007907520657066

Training loss 48897.16015625

Recall on (sampled) validation set: 0.21549515529506455

Training loss 48897.17578125

Recall on (sampled) validation set: 0.21473555378546302

Training loss 48896.78125

Recall on (sampled) validation set: 0.21962841092832017

Training loss 48896.88671875

Recall on (sampled) validation set: 0.22535222804687416

Training loss 48897.1640625

Recall on (sampled) validation set: 0.22536095807466044

Training loss 48897.10546875

Recall on (sampled) validation set: 0.20502762474132707

Training loss 48897.3046875

Recall on (sampled) validation set: 0.21829949176319416

Training loss 48896.92578125

Recall on (sampled) validation set: 0.20649873988349488

Training loss 48897.10546875

Recall on (sampled) validation set: 0.2178721413358437

Training loss 48897.078125

Recall on (sampled) validation set: 0.21346628212145458

Training loss 48896.74609375

Recall on (sampled) validation set: 0.21981499088395642

Training loss 48897.234375

Recall on (sampled) validation set: 0.21058308536257722

Training loss 48896.984375

Recall on (sampled) validation set: 0.2137848397485421

Training loss 48896.9140625

Recall on (sampled) validation set: 0.2200289309064264

Training loss 48896.98828125

Recall on (sampled) validation set: 0.21760661401178644

Training loss 48897.140625

Recall on (sampled) validation set: 0.2134887854801648

Training loss 48897.3359375

Recall on (sampled) validation set: 0.2206589378726402

Training loss 48897.015625

Recall on (sampled) validation set: 0.21768779790150025

Training loss 48896.60546875

Recall on (sampled) validation set: 0.21710727855192463

Training loss 48896.86328125

Recall on (sampled) validation set: 0.21719231350084342

Training loss 48896.6953125

Recall on (sampled) validation set: 0.2151917661554685

Training loss 48897.078125

Recall on (sampled) validation set: 0.2153136997774021

Training loss 48897.07421875

Recall on (sampled) validation set: 0.21623952203943128

Training loss 48896.71484375

Recall on (sampled) validation set: 0.21427523632514558

Training loss 48896.94921875

Recall on (sampled) validation set: 0.22040496961867195

Training loss 48896.48046875

Recall on (sampled) validation set: 0.2090717731216824

Training loss 48896.69140625

Recall on (sampled) validation set: 0.2089630504267528

Training loss 48896.921875

Recall on (sampled) validation set: 0.213963936967113

Training loss 48897.203125

Recall on (sampled) validation set: 0.20849307978436835

Training loss 48896.53515625

Recall on (sampled) validation set: 0.2156625453762477

Training loss 48896.7890625

Recall on (sampled) validation set: 0.21523569062180675

Training loss 48896.86328125

Recall on (sampled) validation set: 0.21597148452139378

Training loss 48896.39453125

Recall on (sampled) validation set: 0.21548577769948007

Training loss 48897.1953125

Recall on (sampled) validation set: 0.2178415495743082

Training loss 48896.68359375

Recall on (sampled) validation set: 0.21668296939667173

Training loss 48896.3984375

Recall on (sampled) validation set: 0.2147577966162358

Training loss 48896.3359375

Recall on (sampled) validation set: 0.21759429682705544

Training loss 48896.55078125

Recall on (sampled) validation set: 0.22411536504095483

Training loss 48896.6484375

Recall on (sampled) validation set: 0.22137358242349164

Training loss 48896.55078125

Recall on (sampled) validation set: 0.21183512088503012

Training loss 48896.625

Recall on (sampled) validation set: 0.22440620376464296

Training loss 48896.94921875

Recall on (sampled) validation set: 0.21116377952221874

Training loss 48896.890625

Recall on (sampled) validation set: 0.21364291296187848

Training loss 48896.69921875

Recall on (sampled) validation set: 0.20878640452778385

Training loss 48896.3515625

Recall on (sampled) validation set: 0.22358414862679837

Training loss 48896.26953125

Recall on (sampled) validation set: 0.21235503417399967

Training loss 48896.53125

Recall on (sampled) validation set: 0.22032766690525313

Training loss 48896.58984375

Recall on (sampled) validation set: 0.21216967330578945

Training loss 48895.96484375

Recall on (sampled) validation set: 0.21210085515076438

Training loss 48896.7109375

Recall on (sampled) validation set: 0.21173693005589556

Training loss 48896.23828125

Recall on (sampled) validation set: 0.2208481780033504

Training loss 48896.6796875

Recall on (sampled) validation set: 0.21351369039980653

Training loss 48896.36328125

Recall on (sampled) validation set: 0.2087613890612983

Training loss 48896.8203125

Recall on (sampled) validation set: 0.2103696861886517

Training loss 48897.03515625

Recall on (sampled) validation set: 0.21071134160925448

Training loss 48896.65625

Recall on (sampled) validation set: 0.21343188714558947

Training loss 48896.44921875

Recall on (sampled) validation set: 0.21397943417408025

Training loss 48896.51953125

Recall on (sampled) validation set: 0.20917948367086298

Training loss 48896.3203125

Recall on (sampled) validation set: 0.21981117261108185

Training loss 48896.37109375

Recall on (sampled) validation set: 0.2092445856892318

Training loss 48896.0703125

Recall on (sampled) validation set: 0.21441261739537598

Training loss 48896.6484375

Recall on (sampled) validation set: 0.2168413256602912

Training loss 48896.55078125

Recall on (sampled) validation set: 0.21515785370776294

Training loss 48896.26953125

Recall on (sampled) validation set: 0.22386707577224815

Training loss 48896.296875

Recall on (sampled) validation set: 0.22499270206166755

Training loss 48896.26171875

Recall on (sampled) validation set: 0.22755222778498638

Training loss 48896.40625

Recall on (sampled) validation set: 0.21893002643320245

Training loss 48896.42578125

Recall on (sampled) validation set: 0.2184199673251397

Training loss 48896.30078125

Recall on (sampled) validation set: 0.21541087654699267

Training loss 48896.53515625

Recall on (sampled) validation set: 0.21364377658706152

Training loss 48896.23046875

Recall on (sampled) validation set: 0.21610489542386097

Training loss 48896.265625

Recall on (sampled) validation set: 0.21678866925237164

Training loss 48896.48046875

Recall on (sampled) validation set: 0.20940483086853323

Training loss 48896.7734375

Recall on (sampled) validation set: 0.21447409493779732

Training loss 48895.62890625

Recall on (sampled) validation set: 0.21550187271557508

Training loss 48896.1640625

Recall on (sampled) validation set: 0.21287494554917422

Training loss 48896.43359375

Recall on (sampled) validation set: 0.22669965884757176

Training loss 48896.50390625

Recall on (sampled) validation set: 0.21551682514568177

Training loss 48896.37890625

Recall on (sampled) validation set: 0.2195973196662852

Training loss 48896.26953125

Recall on (sampled) validation set: 0.2275634438325001

Training loss 48896.05859375

Recall on (sampled) validation set: 0.2188763885506172

Training loss 48896.40625

Recall on (sampled) validation set: 0.2209253137633355

Training loss 48896.2734375

Recall on (sampled) validation set: 0.2212351263040918

Training loss 48895.88671875

Recall on (sampled) validation set: 0.21986353837397393

Training loss 48896.26953125

Recall on (sampled) validation set: 0.2240052412466206

Training loss 48895.9453125

Recall on (sampled) validation set: 0.2143759138790899

Training loss 48896.06640625

Recall on (sampled) validation set: 0.21550088539879828

Training loss 48896.265625

Recall on (sampled) validation set: 0.21799778726684352

Training loss 48896.12890625

Recall on (sampled) validation set: 0.22472703790126658

Training loss 48896.10546875

Recall on (sampled) validation set: 0.22015684347580902

Training loss 48896.2734375

Recall on (sampled) validation set: 0.21100754978704162

Training loss 48896.125

Recall on (sampled) validation set: 0.22197483149706382

Training loss 48896.421875

Recall on (sampled) validation set: 0.22599442593771082

Training loss 48896.44140625

Recall on (sampled) validation set: 0.2232721316963604

Training loss 48896.37109375

Recall on (sampled) validation set: 0.22239911582334448

Training loss 48896.1015625

Recall on (sampled) validation set: 0.22068728334245577

Training loss 48896.06640625

Recall on (sampled) validation set: 0.22488181486457345

Training loss 48896.24609375

Recall on (sampled) validation set: 0.22367581135004003

Training loss 48896.1484375

Recall on (sampled) validation set: 0.2203015423441921

Training loss 48896.4296875

Recall on (sampled) validation set: 0.23109143373934662

Training loss 48896.3046875

Recall on (sampled) validation set: 0.22302397342188632

Training loss 48896.26171875

Recall on (sampled) validation set: 0.22415203979995268

Training loss 48896.32421875

Recall on (sampled) validation set: 0.21435769042075759

Training loss 48896.1484375

Recall on (sampled) validation set: 0.2200220596772321

Training loss 48895.8984375

Recall on (sampled) validation set: 0.22643420354264274

Training loss 48896.13671875

Recall on (sampled) validation set: 0.2267742202510805

Training loss 48895.87890625

Recall on (sampled) validation set: 0.21771623044898908

Training loss 48896.30859375

Recall on (sampled) validation set: 0.21765788775316908

Training loss 48895.91015625

Recall on (sampled) validation set: 0.21692970758488003

Training loss 48895.55859375

Recall on (sampled) validation set: 0.21919071603599732

Training loss 48895.89453125

Recall on (sampled) validation set: 0.22153295420718289

Training loss 48896.43359375

Recall on (sampled) validation set: 0.2214618065103546

Training loss 48895.62890625

Recall on (sampled) validation set: 0.22232430759064153

Training loss 48895.96484375

Recall on (sampled) validation set: 0.22087043060455036

Training loss 48895.9609375

Recall on (sampled) validation set: 0.21651419518842382

Training loss 48895.765625

Recall on (sampled) validation set: 0.21988808445705

Training loss 48895.68359375

Recall on (sampled) validation set: 0.22186653436971043

Training loss 48896.28515625

Recall on (sampled) validation set: 0.22273307572309384

Training loss 48895.80078125

Recall on (sampled) validation set: 0.2158640281040463

Training loss 48896.171875

Recall on (sampled) validation set: 0.2143831707883432

Training loss 48896.12109375

Recall on (sampled) validation set: 0.21886670917977635

Training loss 48895.76171875

Recall on (sampled) validation set: 0.23002547338391258

Training loss 48895.890625

Recall on (sampled) validation set: 0.2214860645169175

Training loss 48895.9765625

Recall on (sampled) validation set: 0.223823540914285

Training loss 48896.13671875

Recall on (sampled) validation set: 0.21376764686882657

Training loss 48895.8515625

Recall on (sampled) validation set: 0.22296221309106973

Training loss 48895.78515625

Recall on (sampled) validation set: 0.2144539655914429

Training loss 48895.76953125

Recall on (sampled) validation set: 0.2225218887954823

Training loss 48895.375

Recall on (sampled) validation set: 0.21912758865118215

Training loss 48895.890625

Recall on (sampled) validation set: 0.22075033085151052

Training loss 48895.92578125

Recall on (sampled) validation set: 0.2185531791425621

Training loss 48895.93359375

Recall on (sampled) validation set: 0.213513815451202

Training loss 48895.61328125

Recall on (sampled) validation set: 0.22010118185571903

Training loss 48895.78125

Recall on (sampled) validation set: 0.21829159322897979

Training loss 48895.86328125

Recall on (sampled) validation set: 0.21290522959261615

Training loss 48895.984375

Recall on (sampled) validation set: 0.21207313040525377

Training loss 48895.578125

Recall on (sampled) validation set: 0.21580567755159402

Training loss 48895.5546875

Recall on (sampled) validation set: 0.22061136994349334

Training loss 48895.6796875

Recall on (sampled) validation set: 0.22008602881288908

Training loss 48895.55859375

Recall on (sampled) validation set: 0.21671743054955395

Training loss 48895.3515625

Recall on (sampled) validation set: 0.21262071780810435

Training loss 48895.69921875

Recall on (sampled) validation set: 0.212238452933099

Training loss 48895.99609375

Recall on (sampled) validation set: 0.21558290536511948

Training loss 48895.39453125

Recall on (sampled) validation set: 0.21798098716837372

Training loss 48895.734375

Recall on (sampled) validation set: 0.21282810889117604

Training loss 48895.875

Recall on (sampled) validation set: 0.22431280548113577

Training loss 48895.859375

Recall on (sampled) validation set: 0.21756472315410613

Training loss 48895.8515625

Recall on (sampled) validation set: 0.21614395139712742

Training loss 48895.69140625

Recall on (sampled) validation set: 0.2194012161630129

Training loss 48895.3984375

Recall on (sampled) validation set: 0.22074747169211775

Training loss 48895.5546875

Recall on (sampled) validation set: 0.22207286851751457

Training loss 48895.61328125

Recall on (sampled) validation set: 0.2172590307622068

Training loss 48895.65625

Recall on (sampled) validation set: 0.20751489770228426

Training loss 48895.671875

Recall on (sampled) validation set: 0.21597380091844703

Training loss 48895.765625

Recall on (sampled) validation set: 0.21295615235406526

Training loss 48895.6796875

Recall on (sampled) validation set: 0.20718781104625025

Training loss 48895.75390625

Recall on (sampled) validation set: 0.21183599428064037

Training loss 48895.65625

Recall on (sampled) validation set: 0.22587533112850716

Training loss 48895.6796875

Recall on (sampled) validation set: 0.21679603615447532

Training loss 48895.5390625

Recall on (sampled) validation set: 0.22409654120498043

Training loss 48895.26171875

Recall on (sampled) validation set: 0.22090982441300047

Training loss 48895.84375

Recall on (sampled) validation set: 0.2125918291898328

Training loss 48895.69140625

Recall on (sampled) validation set: 0.22571558882402804

Training loss 48895.53125

Recall on (sampled) validation set: 0.2208860148891909

Training loss 48895.17578125

Recall on (sampled) validation set: 0.21891379266696867

Training loss 48895.71484375

Recall on (sampled) validation set: 0.22498167069537303

Training loss 48895.30078125

Recall on (sampled) validation set: 0.21991920392237996

Training loss 48895.30859375

Recall on (sampled) validation set: 0.21457286851751461

Training loss 48895.828125

Recall on (sampled) validation set: 0.2147236640821033

Training loss 48895.265625

Recall on (sampled) validation set: 0.215700936809376

Training loss 48895.421875

Recall on (sampled) validation set: 0.21775892901210503

Training loss 48895.703125

Recall on (sampled) validation set: 0.21735715486033086

Training loss 48895.14453125

Recall on (sampled) validation set: 0.22494445644763247

Training loss 48895.4453125

Recall on (sampled) validation set: 0.2308005170536931

Training loss 48895.48046875

Recall on (sampled) validation set: 0.21714387937799917

Training loss 48895.640625

Recall on (sampled) validation set: 0.22049618058556347

Training loss 48895.48046875

Recall on (sampled) validation set: 0.21940901583460562

Training loss 48895.73828125

Recall on (sampled) validation set: 0.21932568250127232

Training loss 48895.78515625

Recall on (sampled) validation set: 0.21811680018576568

Training loss 48895.57421875

Recall on (sampled) validation set: 0.2108184825526023

Training loss 48895.35546875

Recall on (sampled) validation set: 0.21870369912066825

Training loss 48895.7890625

Recall on (sampled) validation set: 0.21347373418743654

Training loss 48895.25390625

Recall on (sampled) validation set: 0.21686592679015548

Training loss 48895.65625

Recall on (sampled) validation set: 0.21409692094220223

Training loss 48895.68359375

Recall on (sampled) validation set: 0.21605605008690304

Training loss 48895.609375

Recall on (sampled) validation set: 0.21047600540885475

Training loss 48895.32421875

Recall on (sampled) validation set: 0.21994542870586428

Training loss 48895.2890625

Recall on (sampled) validation set: 0.2122637244452127

Training loss 48895.37109375

Recall on (sampled) validation set: 0.21238446189489749

Training loss 48895.62890625

Recall on (sampled) validation set: 0.2128759138790899

Training loss 48895.8203125

Recall on (sampled) validation set: 0.21162386329809196

Training loss 48895.4296875

Recall on (sampled) validation set: 0.21742962770911953

Training loss 48895.28515625

Recall on (sampled) validation set: 0.21098827092112027

Training loss 48895.265625

Recall on (sampled) validation set: 0.2134261570418558

Training loss 48895.6953125

Recall on (sampled) validation set: 0.21466425227995103

Training loss 48895.5546875

Recall on (sampled) validation set: 0.21461578275189888

Training loss 48895.3984375

Recall on (sampled) validation set: 0.21664892595473356

Training loss 48895.19140625

Recall on (sampled) validation set: 0.21435772839447972

Training loss 48895.46484375

Recall on (sampled) validation set: 0.21817982936267877

Training loss 48895.51171875

Recall on (sampled) validation set: 0.20899440367725303

Training loss 48895.1484375

Recall on (sampled) validation set: 0.21507399267063515

Training loss 48895.3515625

Recall on (sampled) validation set: 0.21105217283892416

Training loss 48895.3046875

Recall on (sampled) validation set: 0.2109331252198766

Training loss 48895.2109375

Recall on (sampled) validation set: 0.2119229823077373

Training loss 48895.0

Recall on (sampled) validation set: 0.20282020642864565

Training loss 48895.1796875

Recall on (sampled) validation set: 0.2141814164023783

Training loss 48895.703125

Recall on (sampled) validation set: 0.21015137918813054

Training loss 48894.87109375

Recall on (sampled) validation set: 0.2107930172435617

Training loss 48895.234375

Recall on (sampled) validation set: 0.2095922161289675

Training loss 48895.07421875

Recall on (sampled) validation set: 0.21324557300600858

Training loss 48895.4765625

Recall on (sampled) validation set: 0.22173911354492115

Training loss 48895.34375

Recall on (sampled) validation set: 0.2125932335628343

Training loss 48895.6484375

Recall on (sampled) validation set: 0.21576605590081088

Training loss 48895.5390625

Recall on (sampled) validation set: 0.20932305445780947

Training loss 48895.09375

Recall on (sampled) validation set: 0.20959124387073572

Training loss 48895.625

Recall on (sampled) validation set: 0.21757393963836796

Training loss 48895.4453125

Recall on (sampled) validation set: 0.21935829800031253

Training loss 48895.28125

Recall on (sampled) validation set: 0.22057907722109177

Training loss 48895.03125

Recall on (sampled) validation set: 0.22073349343403786

Training loss 48894.90625

Recall on (sampled) validation set: 0.21512944543525303

Training loss 48895.8515625

Recall on (sampled) validation set: 0.2226877730725281

Training loss 48895.1953125

Recall on (sampled) validation set: 0.22433427962103095

Training loss 48895.296875

Recall on (sampled) validation set: 0.2172666824672269

Training loss 48895.17578125

Recall on (sampled) validation set: 0.21329143740577497

Training loss 48895.35546875

Recall on (sampled) validation set: 0.21990125020841902

Training loss 48895.26953125

Recall on (sampled) validation set: 0.22207433836245088

Training loss 48895.34375

Recall on (sampled) validation set: 0.21783435164015927

Training loss 48895.46875

Recall on (sampled) validation set: 0.22364324888326706

Training loss 48895.1953125

Recall on (sampled) validation set: 0.21750449683072184

Training loss 48895.58984375

Recall on (sampled) validation set: 0.22138235435331624

Training loss 48894.96484375

Recall on (sampled) validation set: 0.22405285243760745

Training loss 48895.0703125

Recall on (sampled) validation set: 0.21906956087536855

Training loss 48894.71484375

Recall on (sampled) validation set: 0.21945311052797442

Training loss 48895.0390625

Recall on (sampled) validation set: 0.21866793180268682

Training loss 48895.53515625

Recall on (sampled) validation set: 0.21906791687508567

Training loss 48895.24609375

Recall on (sampled) validation set: 0.22002837117174684

Training loss 48895.26171875

Recall on (sampled) validation set: 0.21889408430515506

Training loss 48895.453125

Recall on (sampled) validation set: 0.21718401367403184

Training loss 48895.71875

Recall on (sampled) validation set: 0.21824224637700135

Training loss 48895.37890625

Recall on (sampled) validation set: 0.22277412138845895

Training loss 48895.67578125

Recall on (sampled) validation set: 0.2187911565311747

Training loss 48895.16015625

Recall on (sampled) validation set: 0.2249018499313418

Training loss 48894.94921875

Recall on (sampled) validation set: 0.215865607941833

Training loss 48894.953125

Recall on (sampled) validation set: 0.21781893430895247

Training loss 48894.828125

Recall on (sampled) validation set: 0.22106127147370339

Training loss 48895.13671875

Recall on (sampled) validation set: 0.2208569270179978

Training loss 48894.98828125

Recall on (sampled) validation set: 0.21986950417667298

Training loss 48895.37109375

Recall on (sampled) validation set: 0.22209357925465004

Training loss 48894.98828125

Recall on (sampled) validation set: 0.2237188545641359

Training loss 48895.53125

Recall on (sampled) validation set: 0.22464735397357904

Training loss 48894.671875

Recall on (sampled) validation set: 0.22146088401079325

Training loss 48895.0234375

Recall on (sampled) validation set: 0.222729779865896

Training loss 48895.0390625

Recall on (sampled) validation set: 0.22606510289132795

Training loss 48895.56640625

Recall on (sampled) validation set: 0.2253407541406634

Training loss 48895.32421875

Recall on (sampled) validation set: 0.2219491429287255

Training loss 48895.55859375

Recall on (sampled) validation set: 0.22219449049303858

Training loss 48895.25390625

Recall on (sampled) validation set: 0.22556346609295796

Training loss 48895.25

Recall on (sampled) validation set: 0.22268216802018978

Training loss 48895.23046875

Recall on (sampled) validation set: 0.22060443973919472

Training loss 48895.13671875

Recall on (sampled) validation set: 0.22652500264070136

Training loss 48895.2734375

Recall on (sampled) validation set: 0.22546405088827953

Training loss 48895.15625

Recall on (sampled) validation set: 0.2265044248115936

Training loss 48894.87109375

Recall on (sampled) validation set: 0.22386936734032925

Training loss 48895.0

Recall on (sampled) validation set: 0.22723061528778407

Training loss 48895.19921875

Recall on (sampled) validation set: 0.22888544921167428

Training loss 48895.6640625

Recall on (sampled) validation set: 0.22419694372643553

Training loss 48895.50390625

Recall on (sampled) validation set: 0.22602070768177848

Training loss 48895.12890625

Recall on (sampled) validation set: 0.22441056490058306

Training loss 48894.73828125

Recall on (sampled) validation set: 0.2241002246560323

Training loss 48895.34375

Recall on (sampled) validation set: 0.22452692817030387

Training loss 48895.15625

Recall on (sampled) validation set: 0.22770872343694487

Training loss 48895.140625

Recall on (sampled) validation set: 0.23064660955768035

Training loss 48895.0546875

Recall on (sampled) validation set: 0.2236002056691712

Training loss 48894.984375

Recall on (sampled) validation set: 0.22842210891212705

Training loss 48895.16015625

Recall on (sampled) validation set: 0.22293088084195167

Training loss 48894.8515625

Recall on (sampled) validation set: 0.226840036568258

Training loss 48895.23828125

Recall on (sampled) validation set: 0.2259745244336896

Training loss 48895.39453125

Recall on (sampled) validation set: 0.22426467771658334

Training loss 48894.71875

Recall on (sampled) validation set: 0.22557227599650465

Training loss 48894.85546875

Recall on (sampled) validation set: 0.2262179661099806

Training loss 48894.80078125

Recall on (sampled) validation set: 0.22388892773557018

Training loss 48895.171875

Recall on (sampled) validation set: 0.2192168118397701

Training loss 48895.32421875

Recall on (sampled) validation set: 0.225830383386191

Training loss 48894.9453125

Recall on (sampled) validation set: 0.22255129944331395

Training loss 48895.265625

Recall on (sampled) validation set: 0.22686024971868893

Training loss 48894.8359375

Recall on (sampled) validation set: 0.22073858976944274

Training loss 48894.8359375

Recall on (sampled) validation set: 0.21821132070859836

Training loss 48894.93359375

Recall on (sampled) validation set: 0.22092045705521202

Training loss 48894.56640625

Recall on (sampled) validation set: 0.23306219397326478

Training loss 48894.96484375

Recall on (sampled) validation set: 0.22656647387364265

Training loss 48894.7734375

Recall on (sampled) validation set: 0.2236760771660953

Training loss 48895.21875

Recall on (sampled) validation set: 0.21832420152610713

Training loss 48894.8203125

Recall on (sampled) validation set: 0.21831313218609044

Training loss 48894.8046875

Recall on (sampled) validation set: 0.22539433899098146

Training loss 48894.640625

Recall on (sampled) validation set: 0.22521256991311436

Training loss 48895.171875

Recall on (sampled) validation set: 0.22101911671376281

Training loss 48895.25390625

Recall on (sampled) validation set: 0.2280122244831864

Training loss 48895.0390625

Recall on (sampled) validation set: 0.2246412513345363

Training loss 48895.11328125

Recall on (sampled) validation set: 0.21962298990248172

Training loss 48894.82421875

Recall on (sampled) validation set: 0.22442643791645603

Training loss 48895.03515625

Recall on (sampled) validation set: 0.2175596346753334

Training loss 48894.765625

Recall on (sampled) validation set: 0.2273984512832063

Training loss 48894.578125

Recall on (sampled) validation set: 0.22684972772404716

Training loss 48894.765625

Recall on (sampled) validation set: 0.22511649639598819

Training loss 48894.93359375

Recall on (sampled) validation set: 0.22835842305170795

Training loss 48894.76171875

Recall on (sampled) validation set: 0.2281326162410554

Training loss 48894.83984375

Recall on (sampled) validation set: 0.22994126665496897

Training loss 48895.13671875

Recall on (sampled) validation set: 0.22404089071511937

Training loss 48894.88671875

Recall on (sampled) validation set: 0.22034589172338717

Training loss 48894.68359375

Recall on (sampled) validation set: 0.22644661767620022

Training loss 48894.94140625

Recall on (sampled) validation set: 0.23004635893111394

Training loss 48894.69921875

Recall on (sampled) validation set: 0.22271089906933825

Training loss 48894.98828125

Recall on (sampled) validation set: 0.21678903000273236

Training loss 48894.44140625

Recall on (sampled) validation set: 0.22355721941565862

Training loss 48894.8203125

Recall on (sampled) validation set: 0.22813216055638924

Training loss 48894.81640625

Recall on (sampled) validation set: 0.22134966290683167

Training loss 48894.625

Recall on (sampled) validation set: 0.22866822053391928

Training loss 48895.15625

Recall on (sampled) validation set: 0.2289176659866315

Training loss 48894.88671875

Recall on (sampled) validation set: 0.22377146715622218

Training loss 48894.64453125

Recall on (sampled) validation set: 0.21905072110788987

Training loss 48894.74609375

Recall on (sampled) validation set: 0.2172329871177421

Training loss 48894.484375

Recall on (sampled) validation set: 0.22203930367541982

Training loss 48894.55859375

Recall on (sampled) validation set: 0.2195576853575946

Training loss 48894.8515625

Recall on (sampled) validation set: 0.2230776634637796

Training loss 48894.67578125

Recall on (sampled) validation set: 0.22504146664990585

Training loss 48894.5234375

Recall on (sampled) validation set: 0.22298434304151182

Training loss 48894.39453125

Recall on (sampled) validation set: 0.224911459683692

Training loss 48894.38671875

Recall on (sampled) validation set: 0.22231288775753386

Training loss 48894.43359375

Recall on (sampled) validation set: 0.21968536807012304

Training loss 48894.55859375

Recall on (sampled) validation set: 0.22503861229178834

Training loss 48894.6953125

Recall on (sampled) validation set: 0.22557285978792327

Training loss 48894.53515625

Recall on (sampled) validation set: 0.22562256498962482

Training loss 48894.390625

Recall on (sampled) validation set: 0.22664115552727168

Training loss 48894.84375

Recall on (sampled) validation set: 0.22031047249785904

Training loss 48894.7265625

Recall on (sampled) validation set: 0.22084806648282143

Training loss 48894.5390625

Recall on (sampled) validation set: 0.22119622855466778

Training loss 48894.60546875

Recall on (sampled) validation set: 0.2215466539913001

Training loss 48894.421875

Recall on (sampled) validation set: 0.2238400311122634

Training loss 48894.75

Recall on (sampled) validation set: 0.22317952011690664

Training loss 48894.53515625

Recall on (sampled) validation set: 0.2251917705706272

Training loss 48895.06640625

Recall on (sampled) validation set: 0.22986999630738286

Training loss 48894.46484375

Recall on (sampled) validation set: 0.22572508858352777

Training loss 48894.84375

Recall on (sampled) validation set: 0.23149924571294803

Training loss 48894.46875

Recall on (sampled) validation set: 0.22469716868128847

Training loss 48894.62109375

Recall on (sampled) validation set: 0.2245651321354588

Training loss 48894.71875

Recall on (sampled) validation set: 0.22727515366263096

Training loss 48894.44921875

Recall on (sampled) validation set: 0.2298259336448992

Training loss 48894.5703125

Recall on (sampled) validation set: 0.22665024821921373

Training loss 48894.7734375

Recall on (sampled) validation set: 0.2210792373587292

Training loss 48894.5703125

Recall on (sampled) validation set: 0.22655762054037912

Training loss 48894.93359375

Recall on (sampled) validation set: 0.2245451540292738

Training loss 48894.953125

Recall on (sampled) validation set: 0.22179623628035605

Training loss 48894.74609375

Recall on (sampled) validation set: 0.21968104692242624

Training loss 48894.56640625

Recall on (sampled) validation set: 0.22402204309100862

Training loss 48894.390625

Recall on (sampled) validation set: 0.2307616627339858

Training loss 48894.6015625

Recall on (sampled) validation set: 0.22484245767004385

Training loss 48894.4609375

Recall on (sampled) validation set: 0.22631368079054104

Training loss 48894.78515625

Recall on (sampled) validation set: 0.22061369851161136

Training loss 48894.94921875

Recall on (sampled) validation set: 0.22998023746435725

Training loss 48894.8359375

Recall on (sampled) validation set: 0.22787800636212618

Training loss 48894.8203125

Recall on (sampled) validation set: 0.22384480265650863

Training loss 48894.4609375

Recall on (sampled) validation set: 0.22213305878097164

Training loss 48894.6640625

Recall on (sampled) validation set: 0.22876149905414878

Training loss 48894.48828125

Recall on (sampled) validation set: 0.22463179451791063

Training loss 48894.1015625

Recall on (sampled) validation set: 0.22569060315566664

Training loss 48894.51953125

Recall on (sampled) validation set: 0.22553911227913043

Training loss 48894.2265625

Recall on (sampled) validation set: 0.22067838483355723

Training loss 48894.078125

Recall on (sampled) validation set: 0.22443514022779

Training loss 48894.3515625

Recall on (sampled) validation set: 0.22757109985195284

Training loss 48894.375

Recall on (sampled) validation set: 0.2205120939757963

Training loss 48894.71484375

Recall on (sampled) validation set: 0.22272877596289575

Training loss 48894.56640625

Recall on (sampled) validation set: 0.2317339403891128

Training loss 48894.375

Recall on (sampled) validation set: 0.22865955379567

Training loss 48894.59375

Recall on (sampled) validation set: 0.2318802681992337

Training loss 48894.76953125

Recall on (sampled) validation set: 0.22054562870080113

Training loss 48894.37109375

Recall on (sampled) validation set: 0.21807279497070786

Training loss 48894.69140625

Recall on (sampled) validation set: 0.2256160417521579

Training loss 48894.81640625

Recall on (sampled) validation set: 0.22254104893896184

Training loss 48895.30078125

Recall on (sampled) validation set: 0.21524166956925578

Training loss 48894.3046875

Recall on (sampled) validation set: 0.2254386293950722

Training loss 48894.484375

Recall on (sampled) validation set: 0.23055500821018063

Training loss 48894.44921875

Recall on (sampled) validation set: 0.22974972632731255

Training loss 48894.66015625

Recall on (sampled) validation set: 0.22648252221664203

Training loss 48894.5390625

Recall on (sampled) validation set: 0.22575408736252656

Training loss 48894.4453125

Recall on (sampled) validation set: 0.2224208236476839

Training loss 48894.4609375

Recall on (sampled) validation set: 0.21506033910298883

Training loss 48894.33984375

Recall on (sampled) validation set: 0.2137287427904488

Training loss 48894.484375

Recall on (sampled) validation set: 0.2184625192814848

Training loss 48894.6484375

Recall on (sampled) validation set: 0.21794532984324272

Training loss 48894.58984375

Recall on (sampled) validation set: 0.21571902408608398

Training loss 48894.53515625

Recall on (sampled) validation set: 0.22099130920501153

Training loss 48894.6015625

Recall on (sampled) validation set: 0.21277361267152553

Training loss 48894.65625

Recall on (sampled) validation set: 0.2102017781741012

Training loss 48894.36328125

Recall on (sampled) validation set: 0.21147895028611907

Training loss 48895.16015625

Recall on (sampled) validation set: 0.22270731448090794

Training loss 48894.05859375

Recall on (sampled) validation set: 0.21852625184521737

Training loss 48894.453125

Recall on (sampled) validation set: 0.21189241346137896

Training loss 48894.625

Recall on (sampled) validation set: 0.21032617414513965

Training loss 48894.4453125

Recall on (sampled) validation set: 0.21554482683747656

Training loss 48894.65625

Recall on (sampled) validation set: 0.21206282053968076

Training loss 48894.4296875

Recall on (sampled) validation set: 0.21322689386301

Training loss 48894.734375

Recall on (sampled) validation set: 0.21285922442818994

Training loss 48894.796875

Recall on (sampled) validation set: 0.22013583287721217

Training loss 48894.48828125

Recall on (sampled) validation set: 0.21831639006956613

Training loss 48894.61328125

Recall on (sampled) validation set: 0.21474475264266554

Training loss 48894.53125

Recall on (sampled) validation set: 0.21455030819822107

Training loss 48894.43359375

Recall on (sampled) validation set: 0.20775815016468374

Training loss 48894.48046875

Recall on (sampled) validation set: 0.20012480151091766

Training loss 48894.49609375

Recall on (sampled) validation set: 0.2060854149043804

Training loss 48893.87109375

Recall on (sampled) validation set: 0.2019945058134713

Training loss 48894.25

Recall on (sampled) validation set: 0.2122761379240508

Training loss 48894.5234375

Recall on (sampled) validation set: 0.20900954733577237

Training loss 48894.703125

Recall on (sampled) validation set: 0.20755524871042114

Training loss 48894.609375

Recall on (sampled) validation set: 0.20894027933819223

Training loss 48894.55859375

Recall on (sampled) validation set: 0.211924159493125

Training loss 48894.55859375

Recall on (sampled) validation set: 0.21343126057917344

Training loss 48894.25390625

Recall on (sampled) validation set: 0.2086864250053905

Training loss 48894.49609375

Recall on (sampled) validation set: 0.210488259136172

Training loss 48894.24609375

Recall on (sampled) validation set: 0.21015445505962746

Training loss 48894.39453125

Recall on (sampled) validation set: 0.2036840097457157

Training loss 48894.2734375

Recall on (sampled) validation set: 0.20498256700616044

Training loss 48894.46875

Recall on (sampled) validation set: 0.2097722835912491

Training loss 48894.36328125

Recall on (sampled) validation set: 0.20973526314043553

Training loss 48894.48046875

Recall on (sampled) validation set: 0.21201220549632527

Training loss 48894.296875

Recall on (sampled) validation set: 0.21232533680945656

Training loss 48893.8984375

Recall on (sampled) validation set: 0.20847033553930103

Training loss 48894.3359375

Recall on (sampled) validation set: 0.2108517855069579

Training loss 48894.44921875

Recall on (sampled) validation set: 0.21661822027203154

Training loss 48894.30078125

Recall on (sampled) validation set: 0.21079884228160087

Training loss 48894.59375

Recall on (sampled) validation set: 0.20730046009310982

Training loss 48894.6484375

Recall on (sampled) validation set: 0.21448021263538503

Training loss 48894.359375

Recall on (sampled) validation set: 0.21329793484058457

Training loss 48894.50390625

Recall on (sampled) validation set: 0.216178488497454

Training loss 48894.26171875

Recall on (sampled) validation set: 0.21176687233583782

Training loss 48894.48828125

Recall on (sampled) validation set: 0.22088113526589026

Training loss 48894.6015625

Recall on (sampled) validation set: 0.21714002504519744

Training loss 48894.6015625

Recall on (sampled) validation set: 0.2196996928929778

Training loss 48894.71484375

Recall on (sampled) validation set: 0.21359064414781292

Training loss 48894.38671875

Recall on (sampled) validation set: 0.208114388854407

Training loss 48894.44140625

Recall on (sampled) validation set: 0.20940677145668068

Training loss 48894.05078125

Recall on (sampled) validation set: 0.213364388854407

Training loss 48894.0

Recall on (sampled) validation set: 0.21622802521804335

Training loss 48894.7265625

Recall on (sampled) validation set: 0.2075919503129122

Training loss 48894.859375

Recall on (sampled) validation set: 0.2139347580899305

Training loss 48894.21875

Recall on (sampled) validation set: 0.2140669066431317

Training loss 48894.62109375

Recall on (sampled) validation set: 0.21558667589384464

Training loss 48894.55859375

Recall on (sampled) validation set: 0.212437310185949

Training loss 48894.11328125

Recall on (sampled) validation set: 0.21381680778051015

Training loss 48894.43359375

Recall on (sampled) validation set: 0.2154116622102103

Training loss 48894.18359375

Recall on (sampled) validation set: 0.20855500188122691

Training loss 48894.578125

Recall on (sampled) validation set: 0.210674577204069

Training loss 48893.9765625

Recall on (sampled) validation set: 0.20732894824138018

Training loss 48894.28125

Recall on (sampled) validation set: 0.208867066001821

Training loss 48894.6796875

Recall on (sampled) validation set: 0.2084923832133451

Training loss 48894.265625

Recall on (sampled) validation set: 0.20855500188122691

Training loss 48894.0703125

Recall on (sampled) validation set: 0.2114594180941731

Training loss 48894.515625

Recall on (sampled) validation set: 0.21020694260031828

Training loss 48894.21875

Recall on (sampled) validation set: 0.2087610053957604

Training loss 48894.734375

Recall on (sampled) validation set: 0.20169627918629734

Training loss 48894.83984375

Recall on (sampled) validation set: 0.212127167011922

Training loss 48894.5703125

Recall on (sampled) validation set: 0.21112435302816426

Training loss 48894.00390625

Recall on (sampled) validation set: 0.21591225473122022

Training loss 48894.1796875

Recall on (sampled) validation set: 0.21308545680641872

Training loss 48893.96484375

Recall on (sampled) validation set: 0.21892767206242705

Training loss 48894.25

Recall on (sampled) validation set: 0.20991664069613256

Training loss 48894.53515625

Recall on (sampled) validation set: 0.21372720878301635

Training loss 48894.375

Recall on (sampled) validation set: 0.20799346546442735

Training loss 48894.2265625

Recall on (sampled) validation set: 0.2123486526748777

Training loss 48893.953125

Recall on (sampled) validation set: 0.21201222448318638

Training loss 48894.125

Recall on (sampled) validation set: 0.20928993744374869

Training loss 48894.39453125

Recall on (sampled) validation set: 0.20504527668003167

Training loss 48893.89453125

Recall on (sampled) validation set: 0.20333507946983445

Training loss 48893.82421875

Recall on (sampled) validation set: 0.2062447866880716

Training loss 48894.16015625

Recall on (sampled) validation set: 0.21073760638098205

Training loss 48894.0859375

Recall on (sampled) validation set: 0.20702194968438162

Training loss 48894.44921875

Recall on (sampled) validation set: 0.20668086185509052

Training loss 48893.69921875

Recall on (sampled) validation set: 0.20625249928199113

Training loss 48894.1015625

Recall on (sampled) validation set: 0.20641747611802058

Training loss 48894.17578125

Recall on (sampled) validation set: 0.20641054984203802

Training loss 48894.38671875

Recall on (sampled) validation set: 0.20896446139731076

Training loss 48894.12109375

Recall on (sampled) validation set: 0.2067610053957604

Training loss 48894.1484375

Recall on (sampled) validation set: 0.20766590413686603

Training loss 48894.4765625

Recall on (sampled) validation set: 0.21077482783063545

Training loss 48893.828125

Recall on (sampled) validation set: 0.20444149449730215

Training loss 48894.015625

Recall on (sampled) validation set: 0.2069386314095933

Training loss 48893.7109375

Recall on (sampled) validation set: 0.2027693524127281

Training loss 48893.85546875

Recall on (sampled) validation set: 0.2066535207751179

Training loss 48894.1796875

Recall on (sampled) validation set: 0.216582642822661

Training loss 48894.0546875

Recall on (sampled) validation set: 0.2125110053957604

Training loss 48894.13671875

Recall on (sampled) validation set: 0.20779529566689275

Training loss 48894.3203125

Recall on (sampled) validation set: 0.2000894669624252

Training loss 48894.36328125

Recall on (sampled) validation set: 0.20897290662218065

Training loss 48894.01171875

Recall on (sampled) validation set: 0.20800941049942864

Training loss 48894.0

Recall on (sampled) validation set: 0.2068241367088917

Training loss 48893.8515625

Recall on (sampled) validation set: 0.2146035211679495

Training loss 48893.90625

Recall on (sampled) validation set: 0.20824657930964643

Training loss 48894.078125

Recall on (sampled) validation set: 0.20064643387465528

Training loss 48893.9453125

Recall on (sampled) validation set: 0.21040699929901382

Training loss 48894.125

Recall on (sampled) validation set: 0.2129718355013273

Training loss 48894.546875

Recall on (sampled) validation set: 0.2106519487939633

Training loss 48893.85546875

Recall on (sampled) validation set: 0.20459590590897306

Training loss 48894.09375

Recall on (sampled) validation set: 0.20324321863523315

Training loss 48893.953125

Recall on (sampled) validation set: 0.20737800243381005

Training loss 48894.23046875

Recall on (sampled) validation set: 0.21871505719191742

Training loss 48894.12109375

Recall on (sampled) validation set: 0.21477230257811017

Training loss 48894.359375

Recall on (sampled) validation set: 0.2029132459763131

Training loss 48894.39453125

Recall on (sampled) validation set: 0.20365830546411307

Training loss 48894.33984375

Recall on (sampled) validation set: 0.20491876722457483

Training loss 48893.671875

Recall on (sampled) validation set: 0.2092437011633926

Training loss 48894.05078125

Recall on (sampled) validation set: 0.2099699320139429

Training loss 48893.92578125

Recall on (sampled) validation set: 0.21227099641301095

Training loss 48894.26953125

Recall on (sampled) validation set: 0.20644647298322436

Training loss 48894.203125

Recall on (sampled) validation set: 0.20797002061929468

Training loss 48893.87890625

Recall on (sampled) validation set: 0.20989595134649577

Training loss 48893.56640625

Recall on (sampled) validation set: 0.21187708713616155

Training loss 48894.10546875

Recall on (sampled) validation set: 0.20587933151408647

Training loss 48894.359375

Recall on (sampled) validation set: 0.20698904152579287

Training loss 48894.21484375

Recall on (sampled) validation set: 0.20760816116396877

Training loss 48893.8984375

Recall on (sampled) validation set: 0.20902110640586138

Training loss 48893.98046875

Recall on (sampled) validation set: 0.20772491530114034

Training loss 48893.78515625

Recall on (sampled) validation set: 0.21333976289557047

Training loss 48893.89453125

Recall on (sampled) validation set: 0.19828652373706818

Training loss 48893.6015625

Recall on (sampled) validation set: 0.20965352863175005

Training loss 48893.3203125

Recall on (sampled) validation set: 0.20593225182426633

Training loss 48894.0

Recall on (sampled) validation set: 0.2070446691004767

Training loss 48893.71484375

Recall on (sampled) validation set: 0.20812827610649753

Training loss 48893.89453125

Recall on (sampled) validation set: 0.203074611380419

Training loss 48893.86328125

Recall on (sampled) validation set: 0.2045415022229904

Training loss 48894.21484375

Recall on (sampled) validation set: 0.2014304631310076

Training loss 48894.0

Recall on (sampled) validation set: 0.20414437303638755

Training loss 48894.0703125

Recall on (sampled) validation set: 0.202566162227233

Training loss 48893.9609375

Recall on (sampled) validation set: 0.20632226486627575

Training loss 48894.265625

Recall on (sampled) validation set: 0.20649855787151614

Training loss 48893.96484375

Recall on (sampled) validation set: 0.20923181146003286

Training loss 48893.87109375

Recall on (sampled) validation set: 0.2113778924409596

Training loss 48894.11328125

Recall on (sampled) validation set: 0.21560311065891824

Training loss 48894.28515625

Recall on (sampled) validation set: 0.21000931556512317

Training loss 48893.734375

Recall on (sampled) validation set: 0.21063636450932277

Training loss 48893.8359375

Recall on (sampled) validation set: 0.21267215081416532

Training loss 48893.91015625

Recall on (sampled) validation set: 0.20741721030196528

Training loss 48893.73828125

Recall on (sampled) validation set: 0.2123000083367597

Training loss 48894.01953125

Recall on (sampled) validation set: 0.21268247573828336

Training loss 48894.12890625

Recall on (sampled) validation set: 0.20846133576714337

Training loss 48893.89453125

Recall on (sampled) validation set: 0.2075345910055529

Training loss 48893.90625

Recall on (sampled) validation set: 0.20190179297075847

Training loss 48893.8515625

Recall on (sampled) validation set: 0.20949990201033758

Training loss 48893.8203125

Recall on (sampled) validation set: 0.20555371470298872

Training loss 48893.8359375

Recall on (sampled) validation set: 0.20796927227507989

Training loss 48893.3203125

Recall on (sampled) validation set: 0.21221555085030583

Training loss 48893.75390625

Recall on (sampled) validation set: 0.2123266888049102

Training loss 48893.890625

Recall on (sampled) validation set: 0.21096160943983083

Training loss 48893.99609375

Recall on (sampled) validation set: 0.208955487813927

Training loss 48893.59375

Recall on (sampled) validation set: 0.21257059402249961

Training loss 48893.921875

Recall on (sampled) validation set: 0.20918008732210186

Training loss 48893.875

Recall on (sampled) validation set: 0.2133919577767128

Training loss 48893.828125

Recall on (sampled) validation set: 0.2103454478236692

Training loss 48893.60546875

Recall on (sampled) validation set: 0.20662768358548758

Training loss 48893.8359375

Recall on (sampled) validation set: 0.21015052085106534

Training loss 48893.4765625

Recall on (sampled) validation set: 0.21139471087157113

Training loss 48893.68359375

Recall on (sampled) validation set: 0.2140613775382378

Training loss 48894.03515625

Recall on (sampled) validation set: 0.20974732372554514

Training loss 48893.59375

Recall on (sampled) validation set: 0.21710651716368592

Training loss 48893.55078125

Recall on (sampled) validation set: 0.20723061528778405

Training loss 48893.80859375

Recall on (sampled) validation set: 0.21223117703698466

Training loss 48893.80859375

Recall on (sampled) validation set: 0.2136756862986445

Training loss 48893.9765625

Recall on (sampled) validation set: 0.20703663372991865

Training loss 48893.4765625

Recall on (sampled) validation set: 0.21819260359187764

Training loss 48893.8046875

Recall on (sampled) validation set: 0.2106695266990185

Training loss 48893.63671875

Recall on (sampled) validation set: 0.21128829584410347

Training loss 48893.53515625

Recall on (sampled) validation set: 0.21238593894174657

Training loss 48893.71484375

Recall on (sampled) validation set: 0.2149579750927301

Training loss 48893.453125

Recall on (sampled) validation set: 0.21660816116396878

Training loss 48893.234375

Recall on (sampled) validation set: 0.21235994985722756

Training loss 48893.640625

Recall on (sampled) validation set: 0.21517926368516205

Training loss 48893.15625

Recall on (sampled) validation set: 0.21722777838884913

Training loss 48893.484375

Recall on (sampled) validation set: 0.2171810327368403

Training loss 48893.60546875

Recall on (sampled) validation set: 0.21706924202704603

Training loss 48893.99609375

Recall on (sampled) validation set: 0.21498891974799417

Training loss 48893.88671875

Recall on (sampled) validation set: 0.21907280762861522

Training loss 48893.671875

Recall on (sampled) validation set: 0.20469246675553388

Training loss 48893.64453125

Recall on (sampled) validation set: 0.21135878052847198

Training loss 48893.984375

Recall on (sampled) validation set: 0.2094733053462636

Training loss 48893.75

Recall on (sampled) validation set: 0.21198130667141554

Training loss 48893.8203125

Recall on (sampled) validation set: 0.2090024613082689

Training loss 48893.5390625

Recall on (sampled) validation set: 0.20870811192907382

Training loss 48893.39453125

Recall on (sampled) validation set: 0.21687847317702127

Training loss 48893.4296875

Recall on (sampled) validation set: 0.2169507371703379

Training loss 48893.49609375

Recall on (sampled) validation set: 0.212855909584131

Training loss 48893.375

Recall on (sampled) validation set: 0.22281532680534497

Training loss 48893.3359375

Recall on (sampled) validation set: 0.22215598906705983

Training loss 48893.28125

Recall on (sampled) validation set: 0.22826710017817098

Training loss 48893.796875

Recall on (sampled) validation set: 0.21698932240039318

Training loss 48893.73828125

Recall on (sampled) validation set: 0.2183339339292152

Training loss 48893.31640625

Recall on (sampled) validation set: 0.22037451670800123

Training loss 48893.62109375

Recall on (sampled) validation set: 0.21802731510943854

Training loss 48893.1484375

Recall on (sampled) validation set: 0.22041237258070287

Training loss 48893.6796875

Recall on (sampled) validation set: 0.2148673167593313

Training loss 48893.56640625

Recall on (sampled) validation set: 0.22071765446357094

Training loss 48893.51953125

Recall on (sampled) validation set: 0.22164566414294182

Training loss 48892.96875

Recall on (sampled) validation set: 0.22157019529841668

Training loss 48893.3984375

Recall on (sampled) validation set: 0.21289422114149878

Training loss 48893.66015625

Recall on (sampled) validation set: 0.22207662398769476

Training loss 48893.46875

Recall on (sampled) validation set: 0.219581602473617

Training loss 48893.609375

Recall on (sampled) validation set: 0.21363339863067626

Training loss 48893.6484375

Recall on (sampled) validation set: 0.21621927227507987

Training loss 48893.55859375

Recall on (sampled) validation set: 0.20938449594030353

Training loss 48893.51171875

Recall on (sampled) validation set: 0.21942355191357005

Training loss 48893.4453125

Recall on (sampled) validation set: 0.21450595881902595

Training loss 48893.61328125

Recall on (sampled) validation set: 0.21004286534867295

Training loss 48893.48046875

Recall on (sampled) validation set: 0.2225105195940042

Training loss 48893.6953125

Recall on (sampled) validation set: 0.2167224051071601

Training loss 48893.9296875

Recall on (sampled) validation set: 0.21527204069037098

Training loss 48893.4296875

Recall on (sampled) validation set: 0.22198601868656312

Training loss 48893.84375

Recall on (sampled) validation set: 0.22041785978355846

Training loss 48893.6796875

Recall on (sampled) validation set: 0.22587114817695578

Training loss 48893.375

Recall on (sampled) validation set: 0.2156715013325721

Training loss 48893.40625

Recall on (sampled) validation set: 0.2185826199074838

Training loss 48893.44921875

Recall on (sampled) validation set: 0.2159348490959199

Training loss 48893.46875

Recall on (sampled) validation set: 0.21857463822391224

Training loss 48893.0546875

Recall on (sampled) validation set: 0.2149070713181421

Training loss 48893.0

Recall on (sampled) validation set: 0.21595990455064865

Training loss 48893.39453125

Recall on (sampled) validation set: 0.21479968163180502

Training loss 48893.265625

Recall on (sampled) validation set: 0.21141500782607858

Training loss 48893.203125

Recall on (sampled) validation set: 0.21474005895965964

Training loss 48893.71484375

Recall on (sampled) validation set: 0.21970371810752937

Training loss 48893.5546875

Recall on (sampled) validation set: 0.21371269169091311

Training loss 48893.61328125

Recall on (sampled) validation set: 0.21117213575562033

Training loss 48893.09375

Recall on (sampled) validation set: 0.2151608235147255

Training loss 48893.328125

Recall on (sampled) validation set: 0.2132677647183092

Training loss 48893.6484375

Recall on (sampled) validation set: 0.2126727354785431

Training loss 48893.37890625

Recall on (sampled) validation set: 0.21265323990051757

Training loss 48893.421875

Recall on (sampled) validation set: 0.2197681824292532

Training loss 48893.75

Recall on (sampled) validation set: 0.2149508589481366

Training loss 48893.48046875

Recall on (sampled) validation set: 0.21682415569575278

Training loss 48893.44140625

Recall on (sampled) validation set: 0.21957763421964874

Training loss 48893.296875

Recall on (sampled) validation set: 0.21930131843017506

Training loss 48893.5234375

Recall on (sampled) validation set: 0.218086542985817

Training loss 48893.57421875

Recall on (sampled) validation set: 0.21679602502424644

Training loss 48893.1796875

Recall on (sampled) validation set: 0.22115372963058982

Training loss 48893.5859375

Recall on (sampled) validation set: 0.21888213829593137

Training loss 48892.953125

Recall on (sampled) validation set: 0.21927841634738182

Training loss 48893.6015625

Recall on (sampled) validation set: 0.2172667394278102

Training loss 48893.67578125

Recall on (sampled) validation set: 0.22114326787012809

Training loss 48893.33984375

Recall on (sampled) validation set: 0.22414723612409634

Training loss 48893.87890625

Recall on (sampled) validation set: 0.2141630239760911

Training loss 48893.36328125

Recall on (sampled) validation set: 0.2139176129543643

Training loss 48893.55859375

Recall on (sampled) validation set: 0.2136098568367171

Training loss 48893.63671875

Recall on (sampled) validation set: 0.21214365153566603

Training loss 48893.23046875

Recall on (sampled) validation set: 0.2258908526104533

Training loss 48893.21875

Recall on (sampled) validation set: 0.22188787952989406

Training loss 48893.4296875

Recall on (sampled) validation set: 0.2168817317152163

Training loss 48893.375

Recall on (sampled) validation set: 0.22266854331055783

Training loss 48893.51953125

Recall on (sampled) validation set: 0.21966067882174958

Training loss 48893.1484375

Recall on (sampled) validation set: 0.2216115150225858

Training loss 48893.21484375

Recall on (sampled) validation set: 0.22316541239227264

Training loss 48893.51171875

Recall on (sampled) validation set: 0.22171699969385997

Training loss 48893.0546875

Recall on (sampled) validation set: 0.21733343498270902

Training loss 48893.28515625

Recall on (sampled) validation set: 0.21889173779101184

Training loss 48893.4765625

Recall on (sampled) validation set: 0.21337437201502535

Training loss 48892.81640625

Recall on (sampled) validation set: 0.22309950315531077

Training loss 48893.00390625

Recall on (sampled) validation set: 0.22051736599422625

Training loss 48893.53125

Recall on (sampled) validation set: 0.22184686790993505

Training loss 48893.1015625

Recall on (sampled) validation set: 0.21787559110245136

Training loss 48893.109375

Recall on (sampled) validation set: 0.21542450125662468

Training loss 48893.38671875

Recall on (sampled) validation set: 0.22133073300632286

Training loss 48893.26171875

Recall on (sampled) validation set: 0.2196025980136688

Training loss 48893.5859375

Recall on (sampled) validation set: 0.2248853163036466

Training loss 48893.359375

Recall on (sampled) validation set: 0.2228966533735136

Training loss 48893.0859375

Recall on (sampled) validation set: 0.22686184068670456

Training loss 48893.07421875

Recall on (sampled) validation set: 0.23409788005568408

Training loss 48893.48046875

Recall on (sampled) validation set: 0.23257076681804448

Training loss 48893.140625

Recall on (sampled) validation set: 0.22570843661950743

Training loss 48893.0859375

Recall on (sampled) validation set: 0.226080579096913

Training loss 48892.9765625

Recall on (sampled) validation set: 0.22429152312364656

Training loss 48892.99609375

Recall on (sampled) validation set: 0.22243546251758592

Training loss 48893.1953125

Recall on (sampled) validation set: 0.2216526990519731

Training loss 48893.37109375

Recall on (sampled) validation set: 0.22810602541909256

Training loss 48893.24609375

Recall on (sampled) validation set: 0.22466185464733557

Training loss 48893.19921875

Recall on (sampled) validation set: 0.2259217540038774

Training loss 48892.98828125

Recall on (sampled) validation set: 0.22896399785601237

Training loss 48893.03125

Recall on (sampled) validation set: 0.21967936773517535

Training loss 48892.984375

Recall on (sampled) validation set: 0.22008150945310656

Training loss 48892.86328125

Recall on (sampled) validation set: 0.22595408278620618

Training loss 48892.8984375

Recall on (sampled) validation set: 0.22332612111287248

Training loss 48893.35546875

Recall on (sampled) validation set: 0.22700163172849197

Training loss 48893.21875

Recall on (sampled) validation set: 0.22109739032561174

Training loss 48893.0

Recall on (sampled) validation set: 0.22288279296491637

Training loss 48893.26953125

Recall on (sampled) validation set: 0.2305101155818034

Training loss 48893.00390625

Recall on (sampled) validation set: 0.23358893331579358

Training loss 48893.6796875

Recall on (sampled) validation set: 0.2317040126808729

Training loss 48893.015625

Recall on (sampled) validation set: 0.22760877458563486

Training loss 48893.3359375

Recall on (sampled) validation set: 0.22990329877489585

Training loss 48893.06640625

Recall on (sampled) validation set: 0.22886793018099733

Training loss 48893.203125

Recall on (sampled) validation set: 0.23271445938278967

Training loss 48893.11328125

Recall on (sampled) validation set: 0.22650400508612847

Training loss 48893.00390625

Recall on (sampled) validation set: 0.2243478853438019

Training loss 48893.26953125

Recall on (sampled) validation set: 0.23353351268278671

Training loss 48893.046875

Recall on (sampled) validation set: 0.22980669755397523

Training loss 48893.03125

Recall on (sampled) validation set: 0.2326971584240187

Training loss 48893.109375

Recall on (sampled) validation set: 0.22475256649984415

Training loss 48892.99609375

Recall on (sampled) validation set: 0.22491022313708336

Training loss 48893.078125

Recall on (sampled) validation set: 0.22661173069385407

Training loss 48892.859375

Recall on (sampled) validation set: 0.22847350634510344

Training loss 48893.08984375

Recall on (sampled) validation set: 0.22924053363118696

Training loss 48893.14453125

Recall on (sampled) validation set: 0.2296501718856528

Training loss 48892.765625

Recall on (sampled) validation set: 0.23011588745663156

Training loss 48893.0546875

Recall on (sampled) validation set: 0.22900813117782262

Training loss 48893.08984375

Recall on (sampled) validation set: 0.22885985492292207

Training loss 48893.19140625

Recall on (sampled) validation set: 0.23152709119542153

Training loss 48892.859375

Recall on (sampled) validation set: 0.2306021992895859

Training loss 48893.03125

Recall on (sampled) validation set: 0.22663427394008154

Training loss 48893.2109375

Recall on (sampled) validation set: 0.2300165305723382

Training loss 48892.94140625

Recall on (sampled) validation set: 0.2294333209305986

Training loss 48892.88671875

Recall on (sampled) validation set: 0.2213340629089268

Training loss 48893.23828125

Recall on (sampled) validation set: 0.22744449442135467

Training loss 48893.44140625

Recall on (sampled) validation set: 0.23506094476874873

Training loss 48892.66015625

Recall on (sampled) validation set: 0.22905997251051702

Training loss 48892.65625

Recall on (sampled) validation set: 0.23236551492132254

Training loss 48893.078125

Recall on (sampled) validation set: 0.23209423065003823

Training loss 48893.16015625

Recall on (sampled) validation set: 0.2226963230021306

Training loss 48892.75

Recall on (sampled) validation set: 0.22837503126704575

Training loss 48892.7734375

Recall on (sampled) validation set: 0.2325299300081514

Training loss 48892.9765625

Recall on (sampled) validation set: 0.23383632098559504

Training loss 48893.32421875

Recall on (sampled) validation set: 0.2302139126921341

Training loss 48892.6015625

Recall on (sampled) validation set: 0.22654532049586498

Training loss 48893.01953125

Recall on (sampled) validation set: 0.230034386078397

Training loss 48893.296875

Recall on (sampled) validation set: 0.23237913635735774

Training loss 48892.91015625

Recall on (sampled) validation set: 0.22809104085737478

Training loss 48893.16015625

Recall on (sampled) validation set: 0.2270037392700732

Training loss 48892.58984375

Recall on (sampled) validation set: 0.22638406508460956

Training loss 48892.91015625

Recall on (sampled) validation set: 0.22276543517650593

Training loss 48892.80859375

Recall on (sampled) validation set: 0.23211031252138326

Training loss 48893.18359375

Recall on (sampled) validation set: 0.22895029125609886

Training loss 48893.05078125

Recall on (sampled) validation set: 0.22619675385782462

Training loss 48893.23046875

Recall on (sampled) validation set: 0.22510609743822083

Training loss 48892.73828125

Recall on (sampled) validation set: 0.22851521126248892

Training loss 48893.18359375

Recall on (sampled) validation set: 0.22210381901488982

Training loss 48892.9453125

Recall on (sampled) validation set: 0.22404109035415748

Training loss 48893.05078125

Recall on (sampled) validation set: 0.22430114754842526

Training loss 48892.9296875

Recall on (sampled) validation set: 0.2230816744927453

Training loss 48892.78515625

Recall on (sampled) validation set: 0.22408904330864407

Training loss 48892.80078125

Recall on (sampled) validation set: 0.22652568808149567

Training loss 48893.11328125

Recall on (sampled) validation set: 0.22846472127052886

Training loss 48893.0859375

Recall on (sampled) validation set: 0.22168044807246262

Training loss 48892.8046875

Recall on (sampled) validation set: 0.2274357093467801

Training loss 48892.9296875

Recall on (sampled) validation set: 0.22436088212721605

Training loss 48893.25

Recall on (sampled) validation set: 0.22356559262140024

Training loss 48892.94140625

Recall on (sampled) validation set: 0.22253087542288996

Training loss 48892.8984375

Recall on (sampled) validation set: 0.223620102539794

Training loss 48892.80078125

Recall on (sampled) validation set: 0.22538946128147577

Training loss 48892.7890625

Recall on (sampled) validation set: 0.22203218158798924

Training loss 48892.85546875

Recall on (sampled) validation set: 0.22554682045789126

Training loss 48893.2734375

Recall on (sampled) validation set: 0.23158397774504855

Training loss 48892.7890625

Recall on (sampled) validation set: 0.22755389671496748

Training loss 48892.66015625

Recall on (sampled) validation set: 0.2271155149213226

Training loss 48892.9140625

Recall on (sampled) validation set: 0.22411551492132256

Training loss 48892.5

Recall on (sampled) validation set: 0.22325057239258692

Training loss 48892.7109375

Recall on (sampled) validation set: 0.22934951101194295

Training loss 48892.63671875

Recall on (sampled) validation set: 0.2220273779121329

Training loss 48892.94140625

Recall on (sampled) validation set: 0.22612407079376226

Training loss 48892.78125

Recall on (sampled) validation set: 0.2271257488394512

Training loss 48892.5390625

Recall on (sampled) validation set: 0.22445534176114937

Training loss 48893.06640625

Recall on (sampled) validation set: 0.217574598235669

Training loss 48892.46484375

Recall on (sampled) validation set: 0.22319884825465588

Training loss 48892.8984375

Recall on (sampled) validation set: 0.2219370155118794

Training loss 48892.73828125

Recall on (sampled) validation set: 0.21797182235657733

Training loss 48892.8203125

Recall on (sampled) validation set: 0.2216787981293426

Training loss 48892.78125

Recall on (sampled) validation set: 0.2202303703723849

Training loss 48892.5703125

Recall on (sampled) validation set: 0.22416710222290984

Training loss 48892.8046875

Recall on (sampled) validation set: 0.22180229653051792

Training loss 48892.734375

Recall on (sampled) validation set: 0.22284546479600925

Training loss 48892.8359375

Recall on (sampled) validation set: 0.22344495201981593

Training loss 48893.21875

Recall on (sampled) validation set: 0.21960277473752973

Training loss 48892.53515625

Recall on (sampled) validation set: 0.21901171375173192

Training loss 48892.5234375

Recall on (sampled) validation set: 0.22049878369932818

Training loss 48892.5234375

Recall on (sampled) validation set: 0.21819740525321288

Training loss 48892.625

Recall on (sampled) validation set: 0.21844357383558835

Training loss 48892.94921875

Recall on (sampled) validation set: 0.21977835017036468

Training loss 48893.01171875

Recall on (sampled) validation set: 0.21582993747195198

Training loss 48892.5703125

Recall on (sampled) validation set: 0.21825377724379535

Training loss 48892.57421875

Recall on (sampled) validation set: 0.22487762853869933

Training loss 48893.1953125

Recall on (sampled) validation set: 0.2181744121644303

Training loss 48892.2890625

Recall on (sampled) validation set: 0.21880497896604975

Training loss 48893.015625

Recall on (sampled) validation set: 0.22434594732416874

Training loss 48892.76953125

Recall on (sampled) validation set: 0.21419488000068762

Training loss 48892.4296875

Recall on (sampled) validation set: 0.21820713045440812

Training loss 48892.69140625

Recall on (sampled) validation set: 0.21651904268011346

Training loss 48892.53125

Recall on (sampled) validation set: 0.2192052697420211

Training loss 48892.46484375

Recall on (sampled) validation set: 0.2160154011310999

Training loss 48892.73046875

Recall on (sampled) validation set: 0.22396054416108863

Training loss 48892.8515625

Recall on (sampled) validation set: 0.21619187030620785

Training loss 48892.91015625

Recall on (sampled) validation set: 0.2205230639663489

Training loss 48892.86328125

Recall on (sampled) validation set: 0.21927835017036468

Training loss 48892.23828125

Recall on (sampled) validation set: 0.2232426358846504

Training loss 48892.58984375

Recall on (sampled) validation set: 0.21823873964981041

Training loss 48892.515625

Recall on (sampled) validation set: 0.22070873167969352

Training loss 48892.3984375

Recall on (sampled) validation set: 0.21139356637178777

Training loss 48892.51953125

Recall on (sampled) validation set: 0.22148901332249787

Training loss 48892.765625

Recall on (sampled) validation set: 0.22238911558966004

Training loss 48892.546875

Recall on (sampled) validation set: 0.22407610605432743

Training loss 48892.6796875

Recall on (sampled) validation set: 0.21196903521631288

Training loss 48892.33984375

Recall on (sampled) validation set: 0.22003594098648543

Training loss 48892.58984375

Recall on (sampled) validation set: 0.22551268600996366

Training loss 48892.6484375

Recall on (sampled) validation set: 0.21994905711012785

Training loss 48892.6953125

Recall on (sampled) validation set: 0.21638410305833172

Training loss 48893.0546875

Recall on (sampled) validation set: 0.21522634515783337

Training loss 48892.5546875

Recall on (sampled) validation set: 0.21782812979183214

Training loss 48892.08984375

Recall on (sampled) validation set: 0.2147622034818042

Training loss 48892.453125

Recall on (sampled) validation set: 0.2191038190148898

Training loss 48892.6953125

Recall on (sampled) validation set: 0.21888173362901134

Training loss 48892.89453125

Recall on (sampled) validation set: 0.22064335751631575

Training loss 48892.21484375

Recall on (sampled) validation set: 0.2264794453043092

Training loss 48892.44140625

Recall on (sampled) validation set: 0.2204889413033696

Training loss 48892.16015625

Recall on (sampled) validation set: 0.22352062251790017

Training loss 48892.49609375

Recall on (sampled) validation set: 0.2260225742362766

Training loss 48892.23828125

Recall on (sampled) validation set: 0.2196870803290948

Training loss 48892.76171875

Recall on (sampled) validation set: 0.21700440381021138

Training loss 48892.50390625

Recall on (sampled) validation set: 0.21404717929445696

Training loss 48892.2734375

Recall on (sampled) validation set: 0.21303513769620847

Training loss 48892.828125

Recall on (sampled) validation set: 0.21788772562048422

Training loss 48892.1640625

Recall on (sampled) validation set: 0.2159291097757522

Training loss 48892.4765625

Recall on (sampled) validation set: 0.21557248349217492

Training loss 48892.34375

Recall on (sampled) validation set: 0.2219912459154746

Training loss 48892.55078125

Recall on (sampled) validation set: 0.2175866928661847

Training loss 48892.68359375

Recall on (sampled) validation set: 0.21979826345933423

Training loss 48892.5

Recall on (sampled) validation set: 0.2249556874529651

Training loss 48892.5

Recall on (sampled) validation set: 0.22327697918805

Training loss 48891.92578125

Recall on (sampled) validation set: 0.2140414471762022

Training loss 48892.24609375

Recall on (sampled) validation set: 0.22261565175766626

Training loss 48892.359375

Recall on (sampled) validation set: 0.2229475420895566

Training loss 48892.3984375

Recall on (sampled) validation set: 0.22104840029567796

Training loss 48892.42578125

Recall on (sampled) validation set: 0.2154133428244136

Training loss 48892.0390625

Recall on (sampled) validation set: 0.21395526974202114

Training loss 48892.46875

Recall on (sampled) validation set: 0.21597710856059318

Training loss 48892.26171875

Recall on (sampled) validation set: 0.21750719095047585

Training loss 48892.296875

Recall on (sampled) validation set: 0.21672620832148964

Training loss 48892.05859375

Recall on (sampled) validation set: 0.22333504100926968

Training loss 48892.11328125

Recall on (sampled) validation set: 0.229870787426595

Training loss 48892.26953125

Recall on (sampled) validation set: 0.2188677592992475

Training loss 48892.21875

Recall on (sampled) validation set: 0.21914877405984484

Training loss 48892.38671875

Recall on (sampled) validation set: 0.2265311694422402

Training loss 48892.23828125

Recall on (sampled) validation set: 0.2237047151947333

Training loss 48892.30078125

Recall on (sampled) validation set: 0.221180095178734

Training loss 48892.3046875

Recall on (sampled) validation set: 0.2147847127833516

Training loss 48892.7109375

Recall on (sampled) validation set: 0.21659175651598517

Training loss 48892.25

Recall on (sampled) validation set: 0.2202507603474028

Training loss 48892.3046875

Recall on (sampled) validation set: 0.22946746852327615

Training loss 48891.89453125

Recall on (sampled) validation set: 0.22027459077186848

Training loss 48892.3203125

Recall on (sampled) validation set: 0.2188993048189963

Training loss 48892.37109375

Recall on (sampled) validation set: 0.21676322157039032

Training loss 48892.375

Recall on (sampled) validation set: 0.21790415318364503

Training loss 48892.07421875

Recall on (sampled) validation set: 0.222588414828433

Training loss 48892.4140625

Recall on (sampled) validation set: 0.22269884825465586

Training loss 48892.11328125

Recall on (sampled) validation set: 0.21883397774504854

Training loss 48892.37109375

Recall on (sampled) validation set: 0.21032856648963724

Training loss 48892.10546875

Recall on (sampled) validation set: 0.21879422318623773

Training loss 48892.06640625

Recall on (sampled) validation set: 0.21517416342144108

Training loss 48892.4453125

Recall on (sampled) validation set: 0.22485012443360897

Training loss 48892.19921875

Recall on (sampled) validation set: 0.22138953330060407

Training loss 48892.18359375

Recall on (sampled) validation set: 0.2199287392549643

Training loss 48892.640625

Recall on (sampled) validation set: 0.2157855232755414

Training loss 48892.26953125

Recall on (sampled) validation set: 0.2175099898756886

Training loss 48892.01953125

Recall on (sampled) validation set: 0.21518570934678014

Training loss 48892.56640625

Recall on (sampled) validation set: 0.2132559169169877

Training loss 48892.0

Recall on (sampled) validation set: 0.2205854188326965

Training loss 48892.4296875

Recall on (sampled) validation set: 0.21514507947856407

Training loss 48892.05078125

Recall on (sampled) validation set: 0.21665982305319872

Training loss 48892.0390625

Recall on (sampled) validation set: 0.21851137984486443

Training loss 48892.28515625

Recall on (sampled) validation set: 0.2172012366708374

Training loss 48891.9609375

Recall on (sampled) validation set: 0.21526234031814795

Training loss 48891.9453125

Recall on (sampled) validation set: 0.21435374699576148

Training loss 48892.26953125

Recall on (sampled) validation set: 0.2129027423138131

Training loss 48891.84375

Recall on (sampled) validation set: 0.21496234599909736

Training loss 48892.03125

Recall on (sampled) validation set: 0.21615738296455173

Training loss 48892.2734375

Recall on (sampled) validation set: 0.21490623589625404

Training loss 48892.33984375

Recall on (sampled) validation set: 0.22150366725094492

Training loss 48891.94921875

Recall on (sampled) validation set: 0.21962099628206705

Training loss 48892.05078125

Recall on (sampled) validation set: 0.21824798040905116

Training loss 48891.94921875

Recall on (sampled) validation set: 0.21429596020703096

Training loss 48891.515625

Recall on (sampled) validation set: 0.21413686929794007

Training loss 48892.40625

Recall on (sampled) validation set: 0.21293484909591986

Training loss 48891.85546875

Recall on (sampled) validation set: 0.21725318280899045

Training loss 48892.11328125

Recall on (sampled) validation set: 0.21429429520536603

Training loss 48892.06640625

Recall on (sampled) validation set: 0.21632738537593346

Training loss 48892.12109375

Recall on (sampled) validation set: 0.2158525980136688

Training loss 48891.96875

Recall on (sampled) validation set: 0.21218965277177618

Training loss 48892.56640625

Recall on (sampled) validation set: 0.21467012314834458

Training loss 48892.19921875

Recall on (sampled) validation set: 0.21667729625352128

Training loss 48892.125

Recall on (sampled) validation set: 0.22191595324081712

Training loss 48892.11328125

Recall on (sampled) validation set: 0.2216996461896643

Training loss 48892.15625

Recall on (sampled) validation set: 0.2194094715192719

Training loss 48891.953125

Recall on (sampled) validation set: 0.21568314420673762

Training loss 48892.0390625

Recall on (sampled) validation set: 0.22349148690255768

Training loss 48892.015625

Recall on (sampled) validation set: 0.22564262624516707

Training loss 48891.5859375

Recall on (sampled) validation set: 0.22046767737874817

Training loss 48892.00390625

Recall on (sampled) validation set: 0.22153659248259971

Training loss 48891.74609375

Recall on (sampled) validation set: 0.22916966746367834

Training loss 48892.1953125

Recall on (sampled) validation set: 0.2276409174276688

Training loss 48891.96875

Recall on (sampled) validation set: 0.2230932691359189

Training loss 48891.8046875

Recall on (sampled) validation set: 0.22581792800531456

Training loss 48891.91015625

Recall on (sampled) validation set: 0.22615522959261616

Training loss 48891.8046875

Recall on (sampled) validation set: 0.22958769725602754

Training loss 48892.01171875

Recall on (sampled) validation set: 0.2231262327274124

Training loss 48892.2890625

Recall on (sampled) validation set: 0.2223080738244078

Training loss 48892.46875

Recall on (sampled) validation set: 0.22667903911642567

Training loss 48892.30859375

Recall on (sampled) validation set: 0.21821078514817174

Training loss 48892.0

Recall on (sampled) validation set: 0.21918004934837967

Training loss 48892.48046875

Recall on (sampled) validation set: 0.23396151450552538

Training loss 48892.06640625

Recall on (sampled) validation set: 0.2276086207769511

Training loss 48892.10546875

Recall on (sampled) validation set: 0.22557881533335253

Training loss 48892.08984375

Recall on (sampled) validation set: 0.21932147854833878

Training loss 48891.6796875

Recall on (sampled) validation set: 0.22039791725045813

Training loss 48891.86328125

Recall on (sampled) validation set: 0.22400189563075226

Training loss 48892.265625

Recall on (sampled) validation set: 0.22288836925996633

Training loss 48892.26953125

Recall on (sampled) validation set: 0.22022300875839892

Training loss 48891.94921875

Recall on (sampled) validation set: 0.2219201152917124

Training loss 48891.8203125

Recall on (sampled) validation set: 0.21900067654332625

Training loss 48891.7109375

Recall on (sampled) validation set: 0.22283432152306926

Training loss 48892.01171875

Recall on (sampled) validation set: 0.2189501714928212

Training loss 48892.0859375

Recall on (sampled) validation set: 0.22504015022753682

Training loss 48892.09375

Recall on (sampled) validation set: 0.2178579562368128

Training loss 48892.125

Recall on (sampled) validation set: 0.21879212093277425

Training loss 48892.0546875

Recall on (sampled) validation set: 0.2175116422194462

Training loss 48892.078125

Recall on (sampled) validation set: 0.2213545084847263

Training loss 48892.00390625

Recall on (sampled) validation set: 0.2278624521945756

Training loss 48892.35546875

Recall on (sampled) validation set: 0.225711867399254

Training loss 48891.76953125

Recall on (sampled) validation set: 0.21953350482615458

Training loss 48891.5390625

Recall on (sampled) validation set: 0.21397794927059896

Training loss 48891.90625

Recall on (sampled) validation set: 0.21483028845188556

Training loss 48892.265625

Recall on (sampled) validation set: 0.2244063118436984

Training loss 48892.15625

Recall on (sampled) validation set: 0.2243580662296633

Training loss 48891.8515625

Recall on (sampled) validation set: 0.22111300674186335

Training loss 48891.9296875

Recall on (sampled) validation set: 0.22510040339441426

Training loss 48892.26953125

Recall on (sampled) validation set: 0.22111600273759985

Training loss 48891.625

Recall on (sampled) validation set: 0.2268171305571487

Training loss 48891.8046875

Recall on (sampled) validation set: 0.22430654374529146

Training loss 48891.9765625

Recall on (sampled) validation set: 0.22131803799816505

Training loss 48892.26953125

Recall on (sampled) validation set: 0.2171524804260739

Training loss 48891.74609375

Recall on (sampled) validation set: 0.22125360051993445

Training loss 48891.76171875

Recall on (sampled) validation set: 0.22098339849973242

Training loss 48891.50390625

Recall on (sampled) validation set: 0.2195998488471265

Training loss 48892.1484375

Recall on (sampled) validation set: 0.22121917734077443

Training loss 48891.42578125

Recall on (sampled) validation set: 0.21840062757031906

Training loss 48891.6796875

Recall on (sampled) validation set: 0.22143196309303387

Training loss 48891.84375

Recall on (sampled) validation set: 0.21482523794683506

Training loss 48892.17578125

Recall on (sampled) validation set: 0.21790418531525613

Training loss 48891.703125

Recall on (sampled) validation set: 0.21569523098062116

Training loss 48891.67578125

Recall on (sampled) validation set: 0.21234984884712652

Training loss 48891.33984375

Recall on (sampled) validation set: 0.21135806622966333

Training loss 48892.05859375

Recall on (sampled) validation set: 0.21913742384522786

Training loss 48891.96484375

Recall on (sampled) validation set: 0.22080623209888184

Training loss 48891.765625

Recall on (sampled) validation set: 0.21883432152306923

Training loss 48892.2890625

Recall on (sampled) validation set: 0.22575763359111817

Training loss 48891.84375

Recall on (sampled) validation set: 0.21697985581334042

Training loss 48891.9609375

Recall on (sampled) validation set: 0.21686088021342106

Training loss 48892.25390625

Recall on (sampled) validation set: 0.21346432848928307

Training loss 48892.484375

Recall on (sampled) validation set: 0.2158098206156282

Training loss 48892.0234375

Recall on (sampled) validation set: 0.2144615145055254

Training loss 48892.171875

Recall on (sampled) validation set: 0.21165979036759436

Training loss 48892.03125

Recall on (sampled) validation set: 0.2128302884518856

Training loss 48891.98828125

Recall on (sampled) validation set: 0.21517868622269712

Training loss 48891.98828125

Recall on (sampled) validation set: 0.21405023225077674

Training loss 48892.078125

Recall on (sampled) validation set: 0.2203419843583183

Training loss 48892.05078125

Recall on (sampled) validation set: 0.21737574299734008

Training loss 48892.0546875

Recall on (sampled) validation set: 0.21320263258285035

Training loss 48891.59375

Recall on (sampled) validation set: 0.21470712854061313

Training loss 48891.5859375

Recall on (sampled) validation set: 0.21659601742950202

Training loss 48892.12109375

Recall on (sampled) validation set: 0.2209919046135017

Training loss 48891.98046875

Recall on (sampled) validation set: 0.20900360051993444

Training loss 48891.6015625

Recall on (sampled) validation set: 0.20786088021342106

Training loss 48891.96484375

Recall on (sampled) validation set: 0.21320590945318713

Training loss 48891.94140625

Recall on (sampled) validation set: 0.215908882926578

Training loss 48891.96484375

Recall on (sampled) validation set: 0.21442093172673934

Training loss 48892.10546875

Recall on (sampled) validation set: 0.21538462492001514

Training loss 48892.08984375

Recall on (sampled) validation set: 0.21165671056778135

Training loss 48892.03515625

Recall on (sampled) validation set: 0.20757085198192277

Training loss 48891.84375

Recall on (sampled) validation set: 0.20712769864403258

Training loss 48891.9609375

Recall on (sampled) validation set: 0.2165038021734936

Training loss 48892.015625

Recall on (sampled) validation set: 0.21289240233115006

Training loss 48892.10546875

Recall on (sampled) validation set: 0.21678204283785044

Training loss 48891.76953125

Recall on (sampled) validation set: 0.21522613438856633

Training loss 48891.96875

Recall on (sampled) validation set: 0.21569880116522583

Training loss 48891.6015625

Recall on (sampled) validation set: 0.21200734485988568

Training loss 48892.0390625

Recall on (sampled) validation set: 0.2172614650087427

Training loss 48891.86328125

Recall on (sampled) validation set: 0.20785237409965177

Training loss 48891.90625

Recall on (sampled) validation set: 0.21098339849973247

Training loss 48891.82421875

Recall on (sampled) validation set: 0.21470974087081166

Training loss 48891.828125

Recall on (sampled) validation set: 0.21812640753747833

Training loss 48891.87109375

Recall on (sampled) validation set: 0.21231168132801523

Training loss 48892.0390625

Recall on (sampled) validation set: 0.21972199132453218

Training loss 48891.6796875

Recall on (sampled) validation set: 0.2161870135980844

Training loss 48891.94140625

Recall on (sampled) validation set: 0.21170178930433015

Training loss 48891.42578125

Recall on (sampled) validation set: 0.21405570832340345

Training loss 48891.84375

Recall on (sampled) validation set: 0.2130314280563827

Training loss 48891.71484375

Recall on (sampled) validation set: 0.2110481247091955

Training loss 48892.12109375

Recall on (sampled) validation set: 0.21630606121713195

Training loss 48891.91015625

Recall on (sampled) validation set: 0.2159130672379311

Training loss 48891.68359375

Recall on (sampled) validation set: 0.2169171003091148

Training loss 48892.16015625

Recall on (sampled) validation set: 0.21670309546942937

Training loss 48892.109375

Recall on (sampled) validation set: 0.20882207106934875

Training loss 48891.9765625

Recall on (sampled) validation set: 0.2156471222029298

Training loss 48891.9609375

Recall on (sampled) validation set: 0.2166515081678421

Training loss 48891.4609375

Recall on (sampled) validation set: 0.2112030954694294

Training loss 48891.67578125

Recall on (sampled) validation set: 0.2176960323571031

Training loss 48892.16015625

Recall on (sampled) validation set: 0.20873362241374946

Training loss 48891.81640625

Recall on (sampled) validation set: 0.20909595261228656

Training loss 48891.56640625

Recall on (sampled) validation set: 0.21160751168237554

Training loss 48892.0

Recall on (sampled) validation set: 0.21879436531069923

Training loss 48891.99609375

Recall on (sampled) validation set: 0.2126663486913033

Training loss 48891.80078125

Recall on (sampled) validation set: 0.21134198435831827

Training loss 48891.55078125

Recall on (sampled) validation set: 0.21775748169622944

Training loss 48892.06640625

Recall on (sampled) validation set: 0.2107768404379112

Training loss 48891.94140625

Recall on (sampled) validation set: 0.2126519186768733

Training loss 48891.57421875

Recall on (sampled) validation set: 0.21133895431717573

Training loss 48892.13671875

Recall on (sampled) validation set: 0.21200823331404092

Training loss 48891.890625

Recall on (sampled) validation set: 0.21492489998070757

Training loss 48892.125

Recall on (sampled) validation set: 0.2130003688252327

Training loss 48891.9609375

Recall on (sampled) validation set: 0.22588159487887252

Training loss 48892.1015625

Recall on (sampled) validation set: 0.21736161677268753

Training loss 48892.10546875

Recall on (sampled) validation set: 0.21314240233115006

Training loss 48891.9609375

Recall on (sampled) validation set: 0.21066854331055784

Training loss 48891.48828125

Recall on (sampled) validation set: 0.21654321104048876

Training loss 48892.06640625

Recall on (sampled) validation set: 0.21567423544056935

Training loss 48892.07421875

Recall on (sampled) validation set: 0.22643217194850587

Training loss 48891.8203125

Recall on (sampled) validation set: 0.2119637091247799

Training loss 48891.6015625

Recall on (sampled) validation set: 0.20901926468033546

Training loss 48892.19140625

Recall on (sampled) validation set: 0.20947157361358815

Training loss 48891.734375

Recall on (sampled) validation set: 0.20505497896604974

Training loss 48891.80859375

Recall on (sampled) validation set: 0.21085315256095655

Training loss 48892.078125

Recall on (sampled) validation set: 0.2059871009376454

Training loss 48891.7890625

Recall on (sampled) validation set: 0.20865691942325337

Training loss 48892.30078125

Recall on (sampled) validation set: 0.21434090210723605

Training loss 48891.828125

Recall on (sampled) validation set: 0.20596788623422013

Training loss 48891.51171875

Recall on (sampled) validation set: 0.20783268472469926

Training loss 48891.92578125

Recall on (sampled) validation set: 0.20542778598359362

Training loss 48891.78125

Recall on (sampled) validation set: 0.20453178880674344

Training loss 48892.13671875

Recall on (sampled) validation set: 0.2033605345216053

Training loss 48892.046875

Recall on (sampled) validation set: 0.22055497896604975

Training loss 48891.66015625

Recall on (sampled) validation set: 0.21349559199286966

Training loss 48891.73828125

Recall on (sampled) validation set: 0.21947547705034093

Training loss 48891.48046875

Recall on (sampled) validation set: 0.21320556376137137

Training loss 48892.078125

Recall on (sampled) validation set: 0.21803931480564875

Training loss 48891.69140625

Recall on (sampled) validation set: 0.2207641105113882

Training loss 48892.25390625

Recall on (sampled) validation set: 0.21566609007716087

Training loss 48891.578125

Recall on (sampled) validation set: 0.21149176057524516

Training loss 48891.7265625

Recall on (sampled) validation set: 0.21330114754842525

Training loss 48891.78125

Recall on (sampled) validation set: 0.21698710093764542

Training loss 48891.9296875

Recall on (sampled) validation set: 0.21190853723476227

Training loss 48891.453125

Recall on (sampled) validation set: 0.2087645978408229

Training loss 48891.80859375

Recall on (sampled) validation set: 0.20894024529278613

Training loss 48892.015625

Recall on (sampled) validation set: 0.20782856457584226

Training loss 48892.125

Recall on (sampled) validation set: 0.20433678981501124

Training loss 48891.6015625

Recall on (sampled) validation set: 0.2162544739155447

Training loss 48891.76171875

Recall on (sampled) validation set: 0.21210656626763705

Training loss 48891.53125

Recall on (sampled) validation set: 0.21815090124300648

Training loss 48891.68359375

Recall on (sampled) validation set: 0.20824176057524516

Training loss 48891.75390625

Recall on (sampled) validation set: 0.20974065148066962

Training loss 48892.2890625

Recall on (sampled) validation set: 0.20780114754842524

Training loss 48891.82421875

Recall on (sampled) validation set: 0.21506722941977027

Training loss 48891.87109375

Recall on (sampled) validation set: 0.22197986301525324

Training loss 48892.00390625

Recall on (sampled) validation set: 0.22026233840435291

Training loss 48891.60546875

Recall on (sampled) validation set: 0.21030128438476894

Training loss 48891.90625

Recall on (sampled) validation set: 0.21174134286430113

Training loss 48891.67578125

Recall on (sampled) validation set: 0.21481428645630093

Training loss 48892.0234375

Recall on (sampled) validation set: 0.21354155918357368

Training loss 48891.67578125

Recall on (sampled) validation set: 0.2148515007040415

Training loss 48891.90625

Recall on (sampled) validation set: 0.2210648410035887

Training loss 48891.99609375

Recall on (sampled) validation set: 0.21726967518936666

Training loss 48891.7109375

Recall on (sampled) validation set: 0.21457947987349077

Training loss 48891.765625

Recall on (sampled) validation set: 0.21587675322929403

Training loss 48891.85546875

Recall on (sampled) validation set: 0.2147908946434355

Training loss 48891.76953125

Recall on (sampled) validation set: 0.214846226284974

Training loss 48892.01171875

Recall on (sampled) validation set: 0.21473937215906366

Training loss 48891.6484375

Recall on (sampled) validation set: 0.21747047630396088

Training loss 48891.4296875

Recall on (sampled) validation set: 0.21466753307860387

Training loss 48891.359375

Recall on (sampled) validation set: 0.2181119775230483

Training loss 48891.82421875

Recall on (sampled) validation set: 0.21921494327075086

Training loss 48891.50390625

Recall on (sampled) validation set: 0.2179692572165349

Training loss 48892.1015625

Recall on (sampled) validation set: 0.2123341997452705

Training loss 48891.765625

Recall on (sampled) validation set: 0.2199414794387571

Training loss 48891.765625

Recall on (sampled) validation set: 0.2249414794387571

Training loss 48891.609375

Recall on (sampled) validation set: 0.22200500947597135

Training loss 48891.76953125

Recall on (sampled) validation set: 0.22111197752304831

Training loss 48891.69140625

Recall on (sampled) validation set: 0.21463310989944384

Training loss 48891.49609375

Recall on (sampled) validation set: 0.21839480580587656

Training loss 48892.05859375

Recall on (sampled) validation set: 0.22328369469476547

Training loss 48891.640625

Recall on (sampled) validation set: 0.2269860756471464

Training loss 48891.61328125

Recall on (sampled) validation set: 0.22276714993684144

Training loss 48891.69921875

Recall on (sampled) validation set: 0.22741370166097938

Training loss 48891.78515625

Recall on (sampled) validation set: 0.22688209246557706

Training loss 48891.7734375

Recall on (sampled) validation set: 0.22148917050550446

Training loss 48891.83984375

Recall on (sampled) validation set: 0.22352603185951642

Training loss 48891.57421875

Recall on (sampled) validation set: 0.22315931569606703

Training loss 48891.69140625

Recall on (sampled) validation set: 0.2275827377569664

Training loss 48891.921875

Recall on (sampled) validation set: 0.22245359305613385

Training loss 48891.28515625

Recall on (sampled) validation set: 0.22266753307860385

Training loss 48892.12109375

Recall on (sampled) validation set: 0.21937367342948103

Training loss 48891.59375

Recall on (sampled) validation set: 0.22194934392756532

Training loss 48891.65625

Recall on (sampled) validation set: 0.22126256231836994

Training loss 48891.76171875

Recall on (sampled) validation set: 0.22291021593517055

Training loss 48891.8984375

Recall on (sampled) validation set: 0.21900873090074546

Training loss 48891.359375

Recall on (sampled) validation set: 0.22356867242121325

Training loss 48891.44921875

Recall on (sampled) validation set: 0.21253752611239

Training loss 48891.734375

Recall on (sampled) validation set: 0.2233224167611645

Training loss 48891.8046875

Recall on (sampled) validation set: 0.22339480580587656

Training loss 48891.078125

Recall on (sampled) validation set: 0.21887422797676875

Training loss 48891.328125

Recall on (sampled) validation set: 0.22342595211469984

Training loss 48891.71875

Recall on (sampled) validation set: 0.222346450198991

Training loss 48891.57421875

Recall on (sampled) validation set: 0.22332755434388823

Training loss 48891.890625

Recall on (sampled) validation set: 0.22211273372389523

Training loss 48891.73046875

Recall on (sampled) validation set: 0.22242978353232434

Training loss 48891.44921875

Recall on (sampled) validation set: 0.22094989847485308

Training loss 48891.38671875

Recall on (sampled) validation set: 0.226528853045187

Training loss 48891.73828125

Recall on (sampled) validation set: 0.22922747459907167

Training loss 48892.0546875

Recall on (sampled) validation set: 0.2192669482832822

Training loss 48891.4609375

Recall on (sampled) validation set: 0.21232250383883777

Training loss 48891.24609375

Recall on (sampled) validation set: 0.22067846078100162

Training loss 48892.25

Recall on (sampled) validation set: 0.22430697651478046

Training loss 48891.35546875

Recall on (sampled) validation set: 0.2195209813544659

Training loss 48891.98828125

Recall on (sampled) validation set: 0.2224649432707509

Training loss 48891.609375

Recall on (sampled) validation set: 0.2241719190435161

Training loss 48891.84375

Recall on (sampled) validation set: 0.21918751118478885

Training loss 48891.63671875

Recall on (sampled) validation set: 0.22092922898503659

Training loss 48891.3984375

Recall on (sampled) validation set: 0.2186599422624831

Training loss 48891.30859375

Recall on (sampled) validation set: 0.21882222296423748

Training loss 48891.64453125

Recall on (sampled) validation set: 0.2167804178244287

Training loss 48891.48046875

Recall on (sampled) validation set: 0.22389817433692205

Training loss 48891.68359375

Recall on (sampled) validation set: 0.22613975530082608

Training loss 48891.07421875

Recall on (sampled) validation set: 0.23254110349890747

Training loss 48891.890625

Recall on (sampled) validation set: 0.22725107526740917

Training loss 48891.40625

Recall on (sampled) validation set: 0.22433044034677427

Training loss 48891.328125

Recall on (sampled) validation set: 0.2212631168656577

Training loss 48891.453125

Recall on (sampled) validation set: 0.22095372989247758

Training loss 48891.59375

Recall on (sampled) validation set: 0.22272308863415938

Training loss 48891.56640625

Recall on (sampled) validation set: 0.2243027994053402

Training loss 48891.23828125

Recall on (sampled) validation set: 0.22367943784050862

Training loss 48891.5234375

Recall on (sampled) validation set: 0.2261717750052596

Training loss 48891.64453125

Recall on (sampled) validation set: 0.22205279940534026

Training loss 48891.5703125

Recall on (sampled) validation set: 0.22474724384978467

Training loss 48891.546875

Recall on (sampled) validation set: 0.22621891152471912

Training loss 48891.4140625

Recall on (sampled) validation set: 0.22499724384978464

Training loss 48891.50390625

Recall on (sampled) validation set: 0.22442978353232435

Training loss 48891.37890625

Recall on (sampled) validation set: 0.22165145120725882

Training loss 48891.07421875

Recall on (sampled) validation set: 0.22430930076846592

Training loss 48891.171875

Recall on (sampled) validation set: 0.22194606705722858

Training loss 48891.55078125

Recall on (sampled) validation set: 0.2217230886341594

Training loss 48891.69921875

Recall on (sampled) validation set: 0.22809227308955077

Training loss 48891.21484375

Recall on (sampled) validation set: 0.22208057718311797

Training loss 48891.515625

Recall on (sampled) validation set: 0.22157552667806749

Training loss 48891.0390625

Recall on (sampled) validation set: 0.22828363773418223

Training loss 48891.25390625

Recall on (sampled) validation set: 0.2259734991431906

Training loss 48891.71484375

Recall on (sampled) validation set: 0.22180122742418565

Training loss 48891.32421875

Recall on (sampled) validation set: 0.2282633257211297

Training loss 48891.703125

Recall on (sampled) validation set: 0.2238255266780675

Training loss 48891.453125

Recall on (sampled) validation set: 0.23103180386528843

Training loss 48891.3515625

Recall on (sampled) validation set: 0.22656766218925928

Training loss 48892.05078125

Recall on (sampled) validation set: 0.2257816670289447

Training loss 48891.44140625

Recall on (sampled) validation set: 0.227519971122512

Training loss 48891.1953125

Recall on (sampled) validation set: 0.22596824698458087

Training loss 48891.65625

Recall on (sampled) validation set: 0.22266377368010762

Training loss 48891.12109375

Recall on (sampled) validation set: 0.22281108160509247

Training loss 48891.2734375

Recall on (sampled) validation set: 0.2220640324251939

Training loss 48891.0703125

Recall on (sampled) validation set: 0.22179444518645972

Training loss 48891.4765625

Recall on (sampled) validation set: 0.2264216381689158

Training loss 48891.5390625

Recall on (sampled) validation set: 0.22667943784050862

Training loss 48891.01171875

Recall on (sampled) validation set: 0.2248110816050925

Training loss 48891.11328125

Recall on (sampled) validation set: 0.22523833508361638

Training loss 48891.0234375

Recall on (sampled) validation set: 0.21865779281886358

Training loss 48891.31640625

Recall on (sampled) validation set: 0.2208976918087626

Training loss 48891.1484375

Recall on (sampled) validation set: 0.22252329775151916

Training loss 48890.91015625

Recall on (sampled) validation set: 0.22958693385326778

Training loss 48891.3203125

Recall on (sampled) validation set: 0.22155518782152175

Training loss 48891.32421875

Recall on (sampled) validation set: 0.22080286422255568

Training loss 48891.12890625

Recall on (sampled) validation set: 0.22850749675477444

Training loss 48891.25

Recall on (sampled) validation set: 0.22494024529278614

Training loss 48891.7109375

Recall on (sampled) validation set: 0.22532837077891524

Training loss 48891.609375

Recall on (sampled) validation set: 0.22476495073455147

Training loss 48891.33984375

Recall on (sampled) validation set: 0.22643982758184214

Training loss 48891.125

Recall on (sampled) validation set: 0.22613044060866203

Training loss 48891.17578125

Recall on (sampled) validation set: 0.22532085198192278

Training loss 48891.359375

Recall on (sampled) validation set: 0.22531940898047978

Training loss 48891.421875

Recall on (sampled) validation set: 0.22662594465089925

Training loss 48891.23828125

Recall on (sampled) validation set: 0.22490129931237007

Training loss 48891.30078125

Recall on (sampled) validation set: 0.22447958214065292

Training loss 48891.515625

Recall on (sampled) validation set: 0.22217732309701457

Training loss 48891.359375

Recall on (sampled) validation set: 0.2219043941707281

Training loss 48891.26171875

Recall on (sampled) validation set: 0.22317450911325684

Training loss 48891.03125

Recall on (sampled) validation set: 0.2251881139630686

Training loss 48891.51953125

Recall on (sampled) validation set: 0.22441103957211037

Training loss 48891.0234375

Recall on (sampled) validation set: 0.21720510087479236

Training loss 48891.06640625

Recall on (sampled) validation set: 0.22302357142420665

Training loss 48890.8203125

Recall on (sampled) validation set: 0.22241103957211034

Training loss 48891.3359375

Recall on (sampled) validation set: 0.2167167967812251

Training loss 48891.48828125

Recall on (sampled) validation set: 0.22145051325632087

Training loss 48890.8203125

Recall on (sampled) validation set: 0.22107509390857846

Training loss 48891.2109375

Recall on (sampled) validation set: 0.2210666748724825

Training loss 48891.1484375

Recall on (sampled) validation set: 0.22289617678819126

Training loss 48890.7109375

Recall on (sampled) validation set: 0.222578925326203

Training loss 48891.39453125

Recall on (sampled) validation set: 0.2239501603625923

Training loss 48891.63671875

Recall on (sampled) validation set: 0.22369386785493864

Training loss 48891.140625

Recall on (sampled) validation set: 0.23035123488798623

Training loss 48891.4453125

Recall on (sampled) validation set: 0.22498629956116345

Training loss 48891.5

Recall on (sampled) validation set: 0.22274450974178744

Training loss 48890.82421875

Recall on (sampled) validation set: 0.22058275674382752

Training loss 48891.0859375

Recall on (sampled) validation set: 0.2210388970947047

Training loss 48891.2109375

Recall on (sampled) validation set: 0.2207650875708952

Training loss 48891.453125

Recall on (sampled) validation set: 0.21141170411224858

Training loss 48891.140625

Recall on (sampled) validation set: 0.21665459582428734

Training loss 48891.19140625

Recall on (sampled) validation set: 0.222360671357949

Training loss 48891.23046875

Recall on (sampled) validation set: 0.22058275674382752

Training loss 48890.85546875

Recall on (sampled) validation set: 0.21504992846099924

Training loss 48890.984375

Recall on (sampled) validation set: 0.2191207952832272

Training loss 48891.06640625

Recall on (sampled) validation set: 0.2252443729054437

Training loss 48890.80859375

Recall on (sampled) validation set: 0.22481559262140025

Training loss 48891.0390625

Recall on (sampled) validation set: 0.2221312491870568

Training loss 48891.26171875

Recall on (sampled) validation set: 0.2190490210199829

Training loss 48891.0234375

Recall on (sampled) validation set: 0.22249982213457714

Training loss 48891.078125

Recall on (sampled) validation set: 0.22640690043639225

Training loss 48890.82421875

Recall on (sampled) validation set: 0.22552239751241568

Training loss 48891.31640625

Recall on (sampled) validation set: 0.21862967720590223

Training loss 48891.17578125

Recall on (sampled) validation set: 0.22598358836834337

Training loss 48890.90625

Recall on (sampled) validation set: 0.22474044262519763

Training loss 48891.36328125

Recall on (sampled) validation set: 0.21748292382820514

Training loss 48891.42578125

Recall on (sampled) validation set: 0.2294150078260786

Training loss 48890.875

Recall on (sampled) validation set: 0.2196819630930339

Training loss 48891.140625

Recall on (sampled) validation set: 0.21853746194989387

Training loss 48890.953125

Recall on (sampled) validation set: 0.22459357205273722

Training loss 48891.07421875

Recall on (sampled) validation set: 0.22389036288038103

Training loss 48891.03125

Recall on (sampled) validation set: 0.22466622691350457

Training loss 48891.0546875

Recall on (sampled) validation set: 0.2204588334297953

Training loss 48891.12890625

Recall on (sampled) validation set: 0.2244229823077373

Training loss 48891.13671875

Recall on (sampled) validation set: 0.21901856609479117

Training loss 48891.08984375

Recall on (sampled) validation set: 0.21840397645978407

Training loss 48891.328125

Recall on (sampled) validation set: 0.2234720925877913

Training loss 48890.75

Recall on (sampled) validation set: 0.22355024010740887

Training loss 48890.91015625

Recall on (sampled) validation set: 0.22049845115226238

Training loss 48890.80078125

Recall on (sampled) validation set: 0.2215059169169877

Training loss 48891.21875

Recall on (sampled) validation set: 0.22431305231033

Training loss 48891.3984375

Recall on (sampled) validation set: 0.22812119793562624

Training loss 48891.21875

Recall on (sampled) validation set: 0.22358672499779578

Training loss 48890.7265625

Recall on (sampled) validation set: 0.2209961995724246

Training loss 48890.703125

Recall on (sampled) validation set: 0.21835983593606098

Training loss 48891.21484375

Recall on (sampled) validation set: 0.22224498048499863

Training loss 48890.81640625

Recall on (sampled) validation set: 0.21759122881219065

Training loss 48891.171875

Recall on (sampled) validation set: 0.21746547883117756

Training loss 48890.6640625

Recall on (sampled) validation set: 0.21768550643414528

Training loss 48890.93359375

Recall on (sampled) validation set: 0.2180215889340209

Training loss 48891.171875

Recall on (sampled) validation set: 0.22111763560765374

Training loss 48891.01171875

Recall on (sampled) validation set: 0.22443836559353797

Training loss 48891.09375

Recall on (sampled) validation set: 0.22717319116320933

Training loss 48891.296875

Recall on (sampled) validation set: 0.21817319116320932

Training loss 48890.82421875

Recall on (sampled) validation set: 0.21749078831701335

Training loss 48891.2265625

Recall on (sampled) validation set: 0.21944447543449358

Training loss 48891.01953125

Recall on (sampled) validation set: 0.22057412165034673

Training loss 48891.05078125

Recall on (sampled) validation set: 0.2162420944821126

Training loss 48891.109375

Recall on (sampled) validation set: 0.22802794560417064

Training loss 48891.4609375

Recall on (sampled) validation set: 0.22152773674869863

Training loss 48890.9765625

Recall on (sampled) validation set: 0.22187680626156123

Training loss 48891.07421875

Recall on (sampled) validation set: 0.2223387035596654

Training loss 48890.828125

Recall on (sampled) validation set: 0.21937210144832647

Training loss 48891.30859375

Recall on (sampled) validation set: 0.22852420126421943

Training loss 48890.91015625

Recall on (sampled) validation set: 0.22283767826916645

Training loss 48891.0546875

Recall on (sampled) validation set: 0.22460753459755273

Training loss 48891.31640625

Recall on (sampled) validation set: 0.22690774371491249

Training loss 48891.17578125

Recall on (sampled) validation set: 0.21375036947995207

Training loss 48891.1015625

Recall on (sampled) validation set: 0.22336957619580122

Training loss 48890.75

Recall on (sampled) validation set: 0.22323573781196282

Training loss 48891.0859375

Recall on (sampled) validation set: 0.22187845811847628

Training loss 48890.94140625

Recall on (sampled) validation set: 0.23182209398452594

Training loss 48891.37890625

Recall on (sampled) validation set: 0.22892066591068405

Training loss 48891.06640625

Recall on (sampled) validation set: 0.22153588211210717

Training loss 48890.8046875

Recall on (sampled) validation set: 0.21863119222647356

Training loss 48890.9296875

Recall on (sampled) validation set: 0.22356278649427466

Training loss 48891.12109375

Recall on (sampled) validation set: 0.21752925176926988

Training loss 48890.953125

Recall on (sampled) validation set: 0.2179774405536656

Training loss 48891.07421875

Recall on (sampled) validation set: 0.21853897697046515

Training loss 48891.484375

Recall on (sampled) validation set: 0.2147506005958819

Training loss 48891.1796875

Recall on (sampled) validation set: 0.21674676917825736

Training loss 48891.046875

Recall on (sampled) validation set: 0.22094373887522706

Training loss 48890.7734375

Recall on (sampled) validation set: 0.22216979251507382

Training loss 48890.9765625

Recall on (sampled) validation set: 0.22195639525494334

Training loss 48891.1015625

Recall on (sampled) validation set: 0.22130928898351765

Training loss 48891.0

Recall on (sampled) validation set: 0.21931483707527263

Training loss 48891.23828125

Recall on (sampled) validation set: 0.22230524871042112

Training loss 48890.6953125

Recall on (sampled) validation set: 0.21660854482950667

Training loss 48891.09375

Recall on (sampled) validation set: 0.21302492276494092

Training loss 48891.0234375

Recall on (sampled) validation set: 0.21974582376351884

Training loss 48891.03515625

Recall on (sampled) validation set: 0.22550443201350637

Training loss 48890.953125

Recall on (sampled) validation set: 0.22315118539120354

Training loss 48891.44921875

Recall on (sampled) validation set: 0.22358898443426573

Training loss 48891.0234375

Recall on (sampled) validation set: 0.2189293736780125

Training loss 48891.16015625

Recall on (sampled) validation set: 0.21363350862352679

Training loss 48890.75390625

Recall on (sampled) validation set: 0.2198189343089525

Training loss 48890.9609375

Recall on (sampled) validation set: 0.22055075275265834

Training loss 48891.3046875

Recall on (sampled) validation set: 0.23430177018652515

Training loss 48890.8359375

Recall on (sampled) validation set: 0.2259656228694341

Training loss 48891.28515625

Recall on (sampled) validation set: 0.22778951973280465

Training loss 48891.11328125

Recall on (sampled) validation set: 0.22289735397357902

Training loss 48890.875

Recall on (sampled) validation set: 0.21870169044170856

Training loss 48891.05078125

Recall on (sampled) validation set: 0.2227189914004796

Training loss 48890.82421875

Recall on (sampled) validation set: 0.22745565869567685

Training loss 48891.30078125

Recall on (sampled) validation set: 0.22120674094675905

Training loss 48890.8984375

Recall on (sampled) validation set: 0.2229422310565686

Training loss 48890.84375

Recall on (sampled) validation set: 0.22808741245311115

Training loss 48890.796875

Recall on (sampled) validation set: 0.2239624978939861

Training loss 48890.8515625

Recall on (sampled) validation set: 0.22037714802506092

Training loss 48890.87109375

Recall on (sampled) validation set: 0.22474163159553356

Training loss 48891.328125

Recall on (sampled) validation set: 0.2236052031419545

Training loss 48891.5

Recall on (sampled) validation set: 0.22026825052006538

Training loss 48890.8359375

Recall on (sampled) validation set: 0.2221783634460585

Training loss 48890.890625

Recall on (sampled) validation set: 0.22490452707875572

Training loss 48891.0859375

Recall on (sampled) validation set: 0.22137183563227117

Training loss 48890.96484375

Recall on (sampled) validation set: 0.22143367583884824

Training loss 48891.06640625

Recall on (sampled) validation set: 0.2249490512680168

Training loss 48890.8984375

Recall on (sampled) validation set: 0.21946910139333003

Training loss 48891.21875

Recall on (sampled) validation set: 0.22862940353321476

Training loss 48891.3359375

Recall on (sampled) validation set: 0.23147007365156186

Training loss 48890.73046875

Recall on (sampled) validation set: 0.23258501618029745

Training loss 48890.67578125

Recall on (sampled) validation set: 0.22604971087593592

Training loss 48890.46875

Recall on (sampled) validation set: 0.2179574205454423

Training loss 48890.7734375

Recall on (sampled) validation set: 0.2192499740294659

Training loss 48890.7890625

Recall on (sampled) validation set: 0.2225317200612119

Training loss 48890.8359375

Recall on (sampled) validation set: 0.21779341596764462

Training loss 48891.00390625

Recall on (sampled) validation set: 0.22637291788335345

Training loss 48891.26171875

Recall on (sampled) validation set: 0.2250054003434221

Training loss 48891.21484375

Recall on (sampled) validation set: 0.2197250102354458

Training loss 48890.99609375

Recall on (sampled) validation set: 0.22790720422616975

Training loss 48891.00390625

Recall on (sampled) validation set: 0.22440418138694

Training loss 48891.53125

Recall on (sampled) validation set: 0.22281388380390194

Training loss 48890.76953125

Recall on (sampled) validation set: 0.22600132995323557

Training loss 48890.953125

Recall on (sampled) validation set: 0.23104449821872686

Training loss 48891.1484375

Recall on (sampled) validation set: 0.22187413697077943

Training loss 48890.87890625

Recall on (sampled) validation set: 0.22033452645022517

Training loss 48891.0

Recall on (sampled) validation set: 0.2222454361696648

Training loss 48891.15625

Recall on (sampled) validation set: 0.22504797674262284

Training loss 48890.71875

Recall on (sampled) validation set: 0.2219175140917428

Training loss 48890.80859375

Recall on (sampled) validation set: 0.2307774709326433

Training loss 48890.76171875

Recall on (sampled) validation set: 0.22456572552942788

Training loss 48891.140625

Recall on (sampled) validation set: 0.22205135247558114

Training loss 48890.94140625

Recall on (sampled) validation set: 0.21455907483992784

Training loss 48890.68359375

Recall on (sampled) validation set: 0.21863903964221568

Training loss 48890.734375

Recall on (sampled) validation set: 0.21725181575499178

Training loss 48890.88671875

Recall on (sampled) validation set: 0.2078578763610524

Training loss 48890.99609375

Recall on (sampled) validation set: 0.20960007668945962

Training loss 48891.140625

Recall on (sampled) validation set: 0.21652576211514504

Training loss 48891.328125

Recall on (sampled) validation set: 0.21764986023924318

Training loss 48891.14453125

Recall on (sampled) validation set: 0.2212854074405798

Training loss 48890.71875

Recall on (sampled) validation set: 0.22382568441506734

Training loss 48891.07421875

Recall on (sampled) validation set: 0.21780162806206363

Training loss 48890.9765625

Recall on (sampled) validation set: 0.22337047970850152

Training loss 48890.90625

Recall on (sampled) validation set: 0.2248399926516986

Training loss 48890.87109375

Recall on (sampled) validation set: 0.22018846636995457

Training loss 48891.046875

Recall on (sampled) validation set: 0.21960143981514216

Training loss 48890.9453125

Recall on (sampled) validation set: 0.22349847406743956

Training loss 48891.12890625

Recall on (sampled) validation set: 0.220746469316796

Training loss 48891.140625

Recall on (sampled) validation set: 0.23021854155792446

Training loss 48891.1640625

Recall on (sampled) validation set: 0.22615912189914003

Training loss 48891.15625

Recall on (sampled) validation set: 0.22953874127149987

Training loss 48890.61328125

Recall on (sampled) validation set: 0.22235888659300637

Training loss 48891.09375

Recall on (sampled) validation set: 0.2192738483704908

Training loss 48891.14453125

Recall on (sampled) validation set: 0.22152262928306485

Training loss 48891.03125

Recall on (sampled) validation set: 0.2222881566071221

Training loss 48890.9765625

Recall on (sampled) validation set: 0.21604814762437266

Training loss 48890.640625

Recall on (sampled) validation set: 0.2050428463618119

Training loss 48890.87109375

Recall on (sampled) validation set: 0.22167632590908454

Training loss 48890.75

Recall on (sampled) validation set: 0.22201651158547708

Training loss 48891.09375

Recall on (sampled) validation set: 0.22458807890704444

Training loss 48890.890625

Recall on (sampled) validation set: 0.22545604236121478

Training loss 48890.78515625

Recall on (sampled) validation set: 0.22726831533728084

Training loss 48890.89453125

Recall on (sampled) validation set: 0.22455928898351762

Training loss 48890.6015625

Recall on (sampled) validation set: 0.23414248548050726

Training loss 48890.8359375

Recall on (sampled) validation set: 0.22016924582441827

Training loss 48890.9609375

Recall on (sampled) validation set: 0.22359671400052525

Training loss 48890.80078125

Recall on (sampled) validation set: 0.22388493263810869

Training loss 48890.87109375

Recall on (sampled) validation set: 0.220392413461379

Training loss 48891.10546875

Recall on (sampled) validation set: 0.2238272563962219

Training loss 48890.515625

Recall on (sampled) validation set: 0.22252458684355236

Training loss 48891.0859375

Recall on (sampled) validation set: 0.23038281195177746

Training loss 48891.1953125

Recall on (sampled) validation set: 0.22089610804265977

Training loss 48890.76953125

Recall on (sampled) validation set: 0.2270385671161533

Training loss 48891.0390625

Recall on (sampled) validation set: 0.22896794712311955

Training loss 48890.87890625

Recall on (sampled) validation set: 0.23067499491501303

Training loss 48890.88671875

Recall on (sampled) validation set: 0.22537393002910244

Training loss 48890.890625

Recall on (sampled) validation set: 0.23746864762245887

Training loss 48890.76953125

Recall on (sampled) validation set: 0.22428540744057984

Training loss 48891.17578125

Recall on (sampled) validation set: 0.22691622298518851

Training loss 48891.05078125

Recall on (sampled) validation set: 0.2303226557337265

Training loss 48891.12109375

Recall on (sampled) validation set: 0.22551110818669798

Training loss 48890.7890625

Recall on (sampled) validation set: 0.22416239156756396

Training loss 48890.8046875

Recall on (sampled) validation set: 0.22795085501982054

Training loss 48890.98046875

Recall on (sampled) validation set: 0.22224944632567134

Training loss 48891.05859375

Recall on (sampled) validation set: 0.23055465618941118

Training loss 48890.6484375

Recall on (sampled) validation set: 0.2259979614221901

Training loss 48891.15625

Recall on (sampled) validation set: 0.22720486517582705

Training loss 48890.625

Recall on (sampled) validation set: 0.22505608413230915

Training loss 48890.69140625

Recall on (sampled) validation set: 0.2275774181622639

Training loss 48890.58984375

Recall on (sampled) validation set: 0.2266995030243669

Training loss 48890.48828125

Recall on (sampled) validation set: 0.2220814964090826

Training loss 48890.71484375

Recall on (sampled) validation set: 0.21769700068701886

Training loss 48890.71484375

Recall on (sampled) validation set: 0.2183361632485952

Training loss 48890.953125

Recall on (sampled) validation set: 0.21891574438534508

Training loss 48890.390625

Recall on (sampled) validation set: 0.21914144513146325

Training loss 48890.859375

Recall on (sampled) validation set: 0.23787974922503052

Training loss 48891.34375

Recall on (sampled) validation set: 0.22355497896604973

Training loss 48890.63671875

Recall on (sampled) validation set: 0.22611477644826106

Training loss 48890.57421875

Recall on (sampled) validation set: 0.21878370255139762

Training loss 48890.80859375

Recall on (sampled) validation set: 0.2274591293629406

Training loss 48890.68359375

Recall on (sampled) validation set: 0.22054740320847396

Training loss 48890.8515625

Recall on (sampled) validation set: 0.22723036060195767

Training loss 48890.390625

Recall on (sampled) validation set: 0.23019415658617107

Training loss 48890.83984375

Recall on (sampled) validation set: 0.22238554021766363

Training loss 48890.66015625

Recall on (sampled) validation set: 0.21998520225153617

Training loss 48891.08984375

Recall on (sampled) validation set: 0.2316891551850717

Training loss 48890.99609375

Recall on (sampled) validation set: 0.23190439417072808

Training loss 48890.50390625

Recall on (sampled) validation set: 0.2295361819735685

Training loss 48890.78125

Recall on (sampled) validation set: 0.23495862064600725

Training loss 48890.51953125

Recall on (sampled) validation set: 0.22574750573752386

Training loss 48891.265625

Recall on (sampled) validation set: 0.23189888798101138

Training loss 48890.8359375

Recall on (sampled) validation set: 0.22839253131086157

Training loss 48890.6484375

Recall on (sampled) validation set: 0.23197958606896898

Training loss 48890.81640625

Recall on (sampled) validation set: 0.22951589287569324

Training loss 48890.80859375

Recall on (sampled) validation set: 0.2331037221667893

Training loss 48890.8515625

Recall on (sampled) validation set: 0.23067349888130284

Training loss 48890.7109375

Recall on (sampled) validation set: 0.22864636272848615

Training loss 48890.71875

Recall on (sampled) validation set: 0.22347417481355777

Training loss 48890.8359375

Recall on (sampled) validation set: 0.23043610222875194

Training loss 48890.8515625

Recall on (sampled) validation set: 0.2336942475921605

Training loss 48890.59375

Recall on (sampled) validation set: 0.2286033385012514

Training loss 48890.53125

Recall on (sampled) validation set: 0.23426916974603

Training loss 48890.94921875

Recall on (sampled) validation set: 0.2293793354424026

Training loss 48890.67578125

Recall on (sampled) validation set: 0.23215008415326016

Training loss 48890.9140625

Recall on (sampled) validation set: 0.22418836166522194

Training loss 48890.69140625

Recall on (sampled) validation set: 0.2306850049191247

Training loss 48891.03515625

Recall on (sampled) validation set: 0.2288654900923503

Training loss 48890.75

Recall on (sampled) validation set: 0.22901903290968623

Training loss 48890.76953125

Recall on (sampled) validation set: 0.22117776306841638

Training loss 48890.81640625

Recall on (sampled) validation set: 0.22592789990476017

Training loss 48891.06640625

Recall on (sampled) validation set: 0.2331789821558424

Training loss 48890.86328125

Recall on (sampled) validation set: 0.22588831622769917

Training loss 48891.046875

Recall on (sampled) validation set: 0.22621357621675225

Training loss 48890.859375

Recall on (sampled) validation set: 0.229709607962784

Training loss 48890.74609375

Recall on (sampled) validation set: 0.23187919860605888

Training loss 48890.6796875

Recall on (sampled) validation set: 0.22990963847270562

Training loss 48890.6015625

Recall on (sampled) validation set: 0.22513738194318955

Training loss 48890.53515625

Recall on (sampled) validation set: 0.22931137753823777

Training loss 48890.6015625

Recall on (sampled) validation set: 0.2254079486420684

Training loss 48890.82421875

Recall on (sampled) validation set: 0.23105066894858184

Training loss 48890.7265625

Recall on (sampled) validation set: 0.23328082767874056

Training loss 48890.828125

Recall on (sampled) validation set: 0.22471841786633073

Training loss 48890.9140625

Recall on (sampled) validation set: 0.2259370555001226

Training loss 48890.890625

Recall on (sampled) validation set: 0.23038438594745306

Training loss 48891.01171875

Recall on (sampled) validation set: 0.2313337440606043

Training loss 48890.46484375

Recall on (sampled) validation set: 0.22763035287626934

Training loss 48890.625

Recall on (sampled) validation set: 0.2264388592519264

Training loss 48890.8359375

Recall on (sampled) validation set: 0.23023892367631021

Training loss 48890.87890625

Recall on (sampled) validation set: 0.2296321985301114

Training loss 48890.8984375

Recall on (sampled) validation set: 0.23454381469172755

Training loss 48890.8984375

Recall on (sampled) validation set: 0.22743196702134993

Training loss 48890.99609375

Recall on (sampled) validation set: 0.22854812863751153

Training loss 48890.64453125

Recall on (sampled) validation set: 0.23614993225837144

Training loss 48890.8046875

Recall on (sampled) validation set: 0.22837879988197596

Training loss 48890.57421875

Recall on (sampled) validation set: 0.23259238701071733

Training loss 48890.984375

Recall on (sampled) validation set: 0.22308629615662284

Training loss 48891.01953125

Recall on (sampled) validation set: 0.23545732953945295

Training loss 48891.23828125

Recall on (sampled) validation set: 0.24049680322366346

Training loss 48890.26953125

Recall on (sampled) validation set: 0.23301913177230782

Training loss 48890.78125

Recall on (sampled) validation set: 0.24043515681401345

Training loss 48890.55859375

Recall on (sampled) validation set: 0.23562678727470016

Training loss 48890.50390625

Recall on (sampled) validation set: 0.2300456564172535

Training loss 48890.81640625

Recall on (sampled) validation set: 0.23698299977564952

Training loss 48890.78125

Recall on (sampled) validation set: 0.23654606692628471

Training loss 48890.62109375

Recall on (sampled) validation set: 0.2359072421998919

Training loss 48891.01953125

Recall on (sampled) validation set: 0.23520271966052367

Training loss 48890.50390625

Recall on (sampled) validation set: 0.23576425607732324

Training loss 48890.5546875

Recall on (sampled) validation set: 0.23437502149661857

Training loss 48891.546875

Recall on (sampled) validation set: 0.23657233688540402

Training loss 48890.30078125

Recall on (sampled) validation set: 0.22897468353049116

Training loss 48890.53515625

Recall on (sampled) validation set: 0.23572010769696794

Training loss 48890.64453125

Recall on (sampled) validation set: 0.23812850002051453

Training loss 48890.41015625

Recall on (sampled) validation set: 0.23512209752001043

Training loss 48890.58984375

Recall on (sampled) validation set: 0.24008424164730882

Training loss 48890.9453125

Recall on (sampled) validation set: 0.23341346989033013

Training loss 48890.68359375

Recall on (sampled) validation set: 0.22546143462976492

Training loss 48890.98046875

Recall on (sampled) validation set: 0.2207517437358635

Training loss 48891.12109375

Recall on (sampled) validation set: 0.23123702499020102

Training loss 48890.92578125

Recall on (sampled) validation set: 0.22394186703261112

Training loss 48890.8359375

Recall on (sampled) validation set: 0.23268352001564344

Training loss 48890.83984375

Recall on (sampled) validation set: 0.22518052401990693

Training loss 48890.546875

Recall on (sampled) validation set: 0.2348906974419679

Training loss 48890.89453125

Recall on (sampled) validation set: 0.23529929796626714

Training loss 48890.86328125

Recall on (sampled) validation set: 0.2298339679746213

Training loss 48890.84375

Recall on (sampled) validation set: 0.2314731305361977

Training loss 48890.640625

Recall on (sampled) validation set: 0.23575090831397547

Training loss 48890.640625

Recall on (sampled) validation set: 0.23024324547872643

Training loss 48890.96875

Recall on (sampled) validation set: 0.2326517739838974

Training loss 48890.69140625

Recall on (sampled) validation set: 0.22499370836530544

Training loss 48890.6953125

Recall on (sampled) validation set: 0.2280929415580051

Training loss 48890.58984375

Recall on (sampled) validation set: 0.24002478265500046

Training loss 48890.7734375

Recall on (sampled) validation set: 0.2415413542564178

Training loss 48890.80078125

Recall on (sampled) validation set: 0.23736995593302307

Training loss 48890.89453125

Recall on (sampled) validation set: 0.23677458100144128

Training loss 48891.015625

Recall on (sampled) validation set: 0.23857630513937228

Training loss 48890.203125

Recall on (sampled) validation set: 0.23291346989033013

Training loss 48890.68359375

Recall on (sampled) validation set: 0.23136668626459916

Training loss 48890.42578125

Recall on (sampled) validation set: 0.23406029528715555

Training loss 48890.51171875

Recall on (sampled) validation set: 0.23397696195382223

Training loss 48890.94921875

Recall on (sampled) validation set: 0.23905235877921902

Training loss 48890.43359375

Recall on (sampled) validation set: 0.240000634641288

Training loss 48890.92578125

Recall on (sampled) validation set: 0.2386514931092971

Training loss 48890.609375

Recall on (sampled) validation set: 0.24256029528715553

Training loss 48890.703125

Recall on (sampled) validation set: 0.23594068591890732

Training loss 48890.5703125

Recall on (sampled) validation set: 0.22615977530904938

Training loss 48890.984375

Recall on (sampled) validation set: 0.237503296730157

Training loss 48891.375

Recall on (sampled) validation set: 0.24429839052525076

Training loss 48890.92578125

Recall on (sampled) validation set: 0.24354455910762624

Training loss 48890.7734375

Recall on (sampled) validation set: 0.23908374406060431

Training loss 48890.94921875

Recall on (sampled) validation set: 0.2314493210123882

Training loss 48890.76171875

Recall on (sampled) validation set: 0.2392148483364454

Training loss 48890.75390625

Recall on (sampled) validation set: 0.23761188258874286

Training loss 48890.9765625

Recall on (sampled) validation set: 0.23512938061803762

Training loss 48891.171875

Recall on (sampled) validation set: 0.236346211226429

Training loss 48890.734375

Recall on (sampled) validation set: 0.24284217815524528

Training loss 48890.64453125

Recall on (sampled) validation set: 0.23847948720634748

Training loss 48890.90625

Recall on (sampled) validation set: 0.23881802293962

Training loss 48890.55078125

Recall on (sampled) validation set: 0.23994138450445168

Training loss 48891.0234375

Recall on (sampled) validation set: 0.23526246738406448

Training loss 48890.71875

Recall on (sampled) validation set: 0.23043165930325643

Training loss 48890.6796875

Recall on (sampled) validation set: 0.24167521555543336

Training loss 48891.01953125

Recall on (sampled) validation set: 0.23850834723520747

Training loss 48890.64453125

Recall on (sampled) validation set: 0.23956558629244654

Training loss 48890.67578125

Recall on (sampled) validation set: 0.2389174381442984

Training loss 48891.03125

Recall on (sampled) validation set: 0.2508659876790548

Training loss 48890.7265625

Recall on (sampled) validation set: 0.2418975968744571

Training loss 48890.7734375

Recall on (sampled) validation set: 0.24238000718445363

Training loss 48890.6953125

Recall on (sampled) validation set: 0.2394174547305219

Training loss 48890.3359375

Recall on (sampled) validation set: 0.2444718243710984

Training loss 48890.9140625

Recall on (sampled) validation set: 0.23707068502848902

Training loss 48891.125

Recall on (sampled) validation set: 0.23765409038095062

Training loss 48890.546875

Recall on (sampled) validation set: 0.23919774117460146

Training loss 48890.515625

Recall on (sampled) validation set: 0.23786816723976434

Training loss 48890.828125

Recall on (sampled) validation set: 0.24041605996007084

Training loss 48890.36328125

Recall on (sampled) validation set: 0.2307094370810342

Training loss 48890.80078125

Recall on (sampled) validation set: 0.23513028085714108

Training loss 48890.67578125

Recall on (sampled) validation set: 0.23450343356650072

Training loss 48890.55859375

Recall on (sampled) validation set: 0.2325866948807058

Training loss 48890.671875

Recall on (sampled) validation set: 0.23543186815872844

Training loss 48890.30078125

Recall on (sampled) validation set: 0.2326701002331674

Training loss 48890.76171875

Recall on (sampled) validation set: 0.22461489517070277

Training loss 48890.69921875

Recall on (sampled) validation set: 0.23119404659332066

Training loss 48890.609375

Recall on (sampled) validation set: 0.23098742371428396

Training loss 48890.83984375

Recall on (sampled) validation set: 0.23840409038095065

Training loss 48890.8203125

Recall on (sampled) validation set: 0.23600726498412522

Training loss 48890.62890625

Recall on (sampled) validation set: 0.23539713093252113

Training loss 48890.98828125

Recall on (sampled) validation set: 0.22973874646560669

Training loss 48890.734375

Recall on (sampled) validation set: 0.22686277257057658

Training loss 48890.7109375

Recall on (sampled) validation set: 0.22895170942856968

Training loss 48890.5546875

Recall on (sampled) validation set: 0.2322524778944924

Training loss 48890.7265625

Recall on (sampled) validation set: 0.2282727772496375

Training loss 48890.05859375

Recall on (sampled) validation set: 0.24020539680793765

Training loss 48890.703125

Recall on (sampled) validation set: 0.233258378879976

Training loss 48890.64453125

Recall on (sampled) validation set: 0.23911155348315058

Training loss 48890.3984375

Recall on (sampled) validation set: 0.23135887633573654

Training loss 48890.5

Recall on (sampled) validation set: 0.23637421444590226

Training loss 48890.890625

Recall on (sampled) validation set: 0.22474668297354322

Training loss 48890.390625

Recall on (sampled) validation set: 0.22615889165616934

Training loss 48890.484375

Recall on (sampled) validation set: 0.22471958937748412

Training loss 48891.33984375

Recall on (sampled) validation set: 0.22737366710052734

Training loss 48890.328125

Recall on (sampled) validation set: 0.23490821205748613

Training loss 48890.734375

Recall on (sampled) validation set: 0.228258378879976

Training loss 48890.90625

Recall on (sampled) validation set: 0.2294356275572247

Training loss 48890.37109375

Recall on (sampled) validation set: 0.22666626881554283

Training loss 48890.63671875

Recall on (sampled) validation set: 0.23116434328594038

Training loss 48890.375

Recall on (sampled) validation set: 0.22548303054745883

Training loss 48890.765625

Recall on (sampled) validation set: 0.22919760433825767

Training loss 48890.67578125

Recall on (sampled) validation set: 0.22857082186483277

Training loss 48890.8203125

Recall on (sampled) validation set: 0.23263738194318961

Training loss 48890.78515625

Recall on (sampled) validation set: 0.22551977732558498

Training loss 48890.50390625

Recall on (sampled) validation set: 0.2237486298906444

Training loss 48890.78515625

Recall on (sampled) validation set: 0.2295260137456145

Training loss 48890.5

Recall on (sampled) validation set: 0.22628095425781453

Training loss 48890.73828125

Recall on (sampled) validation set: 0.22435572451679528

Training loss 48890.6015625

Recall on (sampled) validation set: 0.22670421569423382

Training loss 48890.890625

Recall on (sampled) validation set: 0.22197935037000371

Training loss 48890.625

Recall on (sampled) validation set: 0.21962332839238466

Training loss 48890.0

Recall on (sampled) validation set: 0.2235839529160763

Training loss 48890.4453125

Recall on (sampled) validation set: 0.22587340761342575

Training loss 48890.53125

Recall on (sampled) validation set: 0.22950895481476247

Training loss 48890.953125

Recall on (sampled) validation set: 0.23429870937357322

Training loss 48890.60546875

Recall on (sampled) validation set: 0.23296868128174844

Training loss 48890.6953125

Recall on (sampled) validation set: 0.23592069755545259

Training loss 48890.68359375

Recall on (sampled) validation set: 0.22674043629624394

Training loss 48890.64453125

Recall on (sampled) validation set: 0.22919170335277414

Training loss 48890.42578125

Recall on (sampled) validation set: 0.2286404665442778

Training loss 48890.69140625

Recall on (sampled) validation set: 0.22713259485355677

Training loss 48890.4140625

Recall on (sampled) validation set: 0.22372267877984758

Training loss 48890.64453125

Recall on (sampled) validation set: 0.222350152636904

Training loss 48890.4765625

Recall on (sampled) validation set: 0.22430727004728818

Training loss 48890.5

Recall on (sampled) validation set: 0.22726090413250125

Training loss 48890.69921875

Recall on (sampled) validation set: 0.22527719485931827

Training loss 48890.5859375

Recall on (sampled) validation set: 0.22812507845720187

Training loss 48890.56640625

Recall on (sampled) validation set: 0.23276208764684264

Training loss 48890.640625

Recall on (sampled) validation set: 0.2244436985008673

Training loss 48890.6015625

Recall on (sampled) validation set: 0.23003879975976166

Training loss 48890.265625

Recall on (sampled) validation set: 0.2268563589398435

Training loss 48890.12109375

Recall on (sampled) validation set: 0.23178613767089265

Training loss 48890.28125

Recall on (sampled) validation set: 0.2291013313499702

Training loss 48890.71484375

Recall on (sampled) validation set: 0.2221468500579208

Training loss 48890.39453125

Recall on (sampled) validation set: 0.23104118817594316

Training loss 48890.23828125

Recall on (sampled) validation set: 0.2299716851341171

Training loss 48890.36328125

Recall on (sampled) validation set: 0.22551062325790094

Training loss 48890.9453125

Recall on (sampled) validation set: 0.22783779699160828

Training loss 48890.3046875

Recall on (sampled) validation set: 0.22546797876788807

Training loss 48890.5703125

Recall on (sampled) validation set: 0.22430221954223767

Training loss 48890.703125

Recall on (sampled) validation set: 0.2241832819160405

Training loss 48890.03515625

Recall on (sampled) validation set: 0.2290517029686721

Training loss 48890.7265625

Recall on (sampled) validation set: 0.2314000738959904

Training loss 48890.515625

Recall on (sampled) validation set: 0.23237403177920424

Training loss 48890.765625

Recall on (sampled) validation set: 0.22695339685856927

Training loss 48890.3515625

Recall on (sampled) validation set: 0.22144991833467334

Training loss 48890.421875

Recall on (sampled) validation set: 0.22251737865213367

Training loss 48890.1953125

Recall on (sampled) validation set: 0.218670568575741

Training loss 48890.28515625

Recall on (sampled) validation set: 0.2203139534223926

Training loss 48890.25

Recall on (sampled) validation set: 0.22299697563309176

Training loss 48890.609375

Recall on (sampled) validation set: 0.23035289940280868

Training loss 48890.76953125

Recall on (sampled) validation set: 0.2290288997485005

Training loss 48890.296875

Recall on (sampled) validation set: 0.22456701663598214

Training loss 48890.48046875

Recall on (sampled) validation set: 0.2267234454562041

Training loss 48890.44140625

Recall on (sampled) validation set: 0.23462294952812196

Training loss 48890.78515625

Recall on (sampled) validation set: 0.22663429494146375

Training loss 48890.37890625

Recall on (sampled) validation set: 0.22846216878839382

Training loss 48890.51953125

Recall on (sampled) validation set: 0.23286275358371544

Training loss 48890.6015625

Recall on (sampled) validation set: 0.22506304838201394

Training loss 48890.265625

Recall on (sampled) validation set: 0.22498000377991303

Training loss 48890.390625

Recall on (sampled) validation set: 0.22293483796569097

Training loss 48890.3203125

Recall on (sampled) validation set: 0.21958577565474116

Training loss 48890.953125

Recall on (sampled) validation set: 0.2237248013799738

Training loss 48890.38671875

Recall on (sampled) validation set: 0.2210168889220613

Training loss 48890.2734375

Recall on (sampled) validation set: 0.2263637068550862

Training loss 48890.51953125

Recall on (sampled) validation set: 0.2254719153770878

Training loss 48890.46875

Recall on (sampled) validation set: 0.22642871393914948

Training loss 48890.18359375

Recall on (sampled) validation set: 0.22486487618384168

Training loss 48890.34375

Recall on (sampled) validation set: 0.23000244232140782

Training loss 48890.5234375

Recall on (sampled) validation set: 0.23438252283442845

Training loss 48890.40625

Recall on (sampled) validation set: 0.22694128324119248

Training loss 48890.3984375

Recall on (sampled) validation set: 0.22397723322587207

Training loss 48890.37890625

Recall on (sampled) validation set: 0.2240139649454531

Training loss 48890.28125

Recall on (sampled) validation set: 0.2224007273058997

Training loss 48890.6015625

Recall on (sampled) validation set: 0.22399478428743397

Training loss 48890.51953125

Recall on (sampled) validation set: 0.21963506314549874

Training loss 48890.6796875

Recall on (sampled) validation set: 0.2201065939840894

Training loss 48889.921875

Recall on (sampled) validation set: 0.22899186031082583

Training loss 48890.3984375

Recall on (sampled) validation set: 0.2273514564013657

Training loss 48890.50390625

Recall on (sampled) validation set: 0.22473768320138557

Training loss 48889.94140625

Recall on (sampled) validation set: 0.22332512162503088

Training loss 48889.89453125

Recall on (sampled) validation set: 0.22582895304265538

Training loss 48890.19921875

Recall on (sampled) validation set: 0.2268217151202632

Training loss 48890.46875

Recall on (sampled) validation set: 0.22617362938869293

Training loss 48890.3515625

Recall on (sampled) validation set: 0.2301748897234378

Training loss 48890.25

Recall on (sampled) validation set: 0.22398597831220332

Training loss 48889.82421875

Recall on (sampled) validation set: 0.22590462354073965

Training loss 48890.21875

Recall on (sampled) validation set: 0.22442945049841598

Training loss 48890.5546875

Recall on (sampled) validation set: 0.22713884938748824

Training loss 48890.1796875

Recall on (sampled) validation set: 0.22291001820992748

Training loss 48890.2109375

Recall on (sampled) validation set: 0.2300383971073626

Training loss 48890.24609375

Recall on (sampled) validation set: 0.22791969518013075

Training loss 48890.125

Recall on (sampled) validation set: 0.2225996297343847

Training loss 48890.0703125

Recall on (sampled) validation set: 0.2286040805165125

Training loss 48889.82421875

Recall on (sampled) validation set: 0.22937444949014824

Training loss 48890.66015625

Recall on (sampled) validation set: 0.23427305179528407

Training loss 48890.09375

Recall on (sampled) validation set: 0.22582170791835035

Training loss 48890.28515625

Recall on (sampled) validation set: 0.22673398862010477

Training loss 48890.4140625

Recall on (sampled) validation set: 0.21890205245786007

Training loss 48890.7265625

Recall on (sampled) validation set: 0.21866450456513978

Training loss 48890.3515625

Recall on (sampled) validation set: 0.2244582005344256

Training loss 48890.26171875

Recall on (sampled) validation set: 0.22181105628927766

Training loss 48890.23046875

Recall on (sampled) validation set: 0.22300226903902037

Training loss 48890.76953125

Recall on (sampled) validation set: 0.21963276573530657

Training loss 48890.44140625

Recall on (sampled) validation set: 0.21779525529253296

Training loss 48890.1796875

Recall on (sampled) validation set: 0.2212315543735689

Training loss 48890.1953125

Recall on (sampled) validation set: 0.22483985935755446

Training loss 48889.94140625

Recall on (sampled) validation set: 0.22202651133231896

Training loss 48890.06640625

Recall on (sampled) validation set: 0.22095930962900107

Training loss 48890.05078125

Recall on (sampled) validation set: 0.2147363770362863

Training loss 48890.26953125

Recall on (sampled) validation set: 0.21814438962261107

Training loss 48890.1953125

Recall on (sampled) validation set: 0.22038392786214928

Training loss 48890.37109375

Recall on (sampled) validation set: 0.21580371950426397

Training loss 48890.359375

Recall on (sampled) validation set: 0.2180619851177927

Training loss 48890.484375

Recall on (sampled) validation set: 0.2199802482084696

Training loss 48890.28125

Recall on (sampled) validation set: 0.21727946848137406

Training loss 48890.3984375

Recall on (sampled) validation set: 0.2169933871163454

Training loss 48890.0390625

Recall on (sampled) validation set: 0.2185285302685484

Training loss 48890.05078125

Recall on (sampled) validation set: 0.225078444325722

Training loss 48890.234375

Recall on (sampled) validation set: 0.22167730498311258

Training loss 48890.24609375

Recall on (sampled) validation set: 0.22438295560391752

Training loss 48890.23046875

Recall on (sampled) validation set: 0.22390471454672906

Training loss 48890.00390625

Recall on (sampled) validation set: 0.22147496200445385

Training loss 48890.125

Recall on (sampled) validation set: 0.2202896351816497

Training loss 48889.9765625

Recall on (sampled) validation set: 0.21977699386047844

Training loss 48889.86328125

Recall on (sampled) validation set: 0.21475371204046334

Training loss 48889.94140625

Recall on (sampled) validation set: 0.21751725207305972

Training loss 48889.99609375

Recall on (sampled) validation set: 0.21468036099478932

Training loss 48889.89453125

Recall on (sampled) validation set: 0.22030800660655467

Training loss 48889.98828125

Recall on (sampled) validation set: 0.216341013627765

Training loss 48890.23046875

Recall on (sampled) validation set: 0.2151967855025931

Training loss 48890.05859375

Recall on (sampled) validation set: 0.2180323330967614

Training loss 48889.81640625

Recall on (sampled) validation set: 0.21392024187078632

Training loss 48889.734375

Recall on (sampled) validation set: 0.21157521263102028

Training loss 48890.1640625

Recall on (sampled) validation set: 0.21659122248323703

Training loss 48889.55859375

Recall on (sampled) validation set: 0.21388884153085602

Training loss 48890.0546875

Recall on (sampled) validation set: 0.21596951277532042

Training loss 48889.94140625

Recall on (sampled) validation set: 0.2197259342626856

Training loss 48889.80859375

Recall on (sampled) validation set: 0.21591251421832183

Training loss 48890.03515625

Recall on (sampled) validation set: 0.22323700360270238

Training loss 48890.11328125

Recall on (sampled) validation set: 0.22257451404547596

Training loss 48889.85546875

Recall on (sampled) validation set: 0.22392856204426076

Training loss 48889.984375

Recall on (sampled) validation set: 0.21821030807600683

Training loss 48889.78125

Recall on (sampled) validation set: 0.210114933144425

Training loss 48889.94140625

Recall on (sampled) validation set: 0.21140457771038532

Training loss 48889.59375

Recall on (sampled) validation set: 0.21210145880200326

Training loss 48889.9453125

Recall on (sampled) validation set: 0.21399828419882866

Training loss 48889.43359375

Recall on (sampled) validation set: 0.21610831458653598

Training loss 48890.12109375

Recall on (sampled) validation set: 0.21831334584283765

Training loss 48889.671875

Recall on (sampled) validation set: 0.2202710129992344

Training loss 48889.7734375

Recall on (sampled) validation set: 0.21931028502988578

Training loss 48890.0703125

Recall on (sampled) validation set: 0.22095637386744466

Training loss 48890.05859375

Recall on (sampled) validation set: 0.21780116260697024

Training loss 48890.08984375

Recall on (sampled) validation set: 0.21758819964400725

Training loss 48889.98828125

Recall on (sampled) validation set: 0.21871915202495965

Training loss 48890.07421875

Recall on (sampled) validation set: 0.2191662736168181

Training loss 48890.03515625

Recall on (sampled) validation set: 0.21645368951811786

Training loss 48889.9140625

Recall on (sampled) validation set: 0.21013978694559454

Training loss 48889.94921875

Recall on (sampled) validation set: 0.21672576578157343

Training loss 48890.25

Recall on (sampled) validation set: 0.21658290863871626

Training loss 48889.73828125

Recall on (sampled) validation set: 0.2178291808849885

Training loss 48889.87109375

Recall on (sampled) validation set: 0.22553090362618491

Training loss 48889.578125

Recall on (sampled) validation set: 0.22615830546411309

Training loss 48890.0546875

Recall on (sampled) validation set: 0.21361026870555

Training loss 48889.86328125

Recall on (sampled) validation set: 0.21955122742418567

Training loss 48889.63671875

Recall on (sampled) validation set: 0.2272574397941911

Training loss 48889.6953125

Recall on (sampled) validation set: 0.2180267913339601

Training loss 48889.9140625

Recall on (sampled) validation set: 0.23023293168483733

Training loss 48889.6640625

Recall on (sampled) validation set: 0.22065447404648855

Training loss 48890.06640625

Recall on (sampled) validation set: 0.21846016643838784

Training loss 48889.8203125

Recall on (sampled) validation set: 0.22503041389611259

Training loss 48889.7109375

Recall on (sampled) validation set: 0.21569798800379564

Training loss 48890.15625

Recall on (sampled) validation set: 0.21261862292443057

Training loss 48889.921875

Recall on (sampled) validation set: 0.21418860849441615

Training loss 48889.625

Recall on (sampled) validation set: 0.2143961918467363

Training loss 48889.359375

Recall on (sampled) validation set: 0.21012635057689502

Training loss 48889.8984375

Recall on (sampled) validation set: 0.20903904898959344

Training loss 48890.05078125

Recall on (sampled) validation set: 0.2142655851575997

Training loss 48889.875

Recall on (sampled) validation set: 0.21631696360371497

Training loss 48890.125

Recall on (sampled) validation set: 0.2077457438877584

Training loss 48889.73828125

Recall on (sampled) validation set: 0.20423752650522162

Training loss 48889.921875

Recall on (sampled) validation set: 0.20661465467046228

Training loss 48889.48828125

Recall on (sampled) validation set: 0.21388449594030354

Training loss 48889.82421875

Recall on (sampled) validation set: 0.21460630045158174

Training loss 48889.98828125

Recall on (sampled) validation set: 0.2070697459427042

Training loss 48889.30078125

Recall on (sampled) validation set: 0.2068050588418102

Training loss 48889.7890625

Recall on (sampled) validation set: 0.20539229561189634

Training loss 48889.76171875

Recall on (sampled) validation set: 0.20687561401762855

Training loss 48889.86328125

Recall on (sampled) validation set: 0.2160276267558482

Training loss 48889.796875

Recall on (sampled) validation set: 0.21105780800835247

Training loss 48889.57421875

Recall on (sampled) validation set: 0.20828124931800066

Training loss 48889.55859375

Recall on (sampled) validation set: 0.2146900514958591

Training loss 48889.8515625

Recall on (sampled) validation set: 0.20763366051841547

Training loss 48889.2890625

Recall on (sampled) validation set: 0.211103023581245

Training loss 48889.75

Recall on (sampled) validation set: 0.22063052768633531

Training loss 48889.55078125

Recall on (sampled) validation set: 0.21713873786695928

Training loss 48889.8515625

Recall on (sampled) validation set: 0.21751558515759967

Training loss 48889.9296875

Recall on (sampled) validation set: 0.21531744613187442

Training loss 48889.82421875

Recall on (sampled) validation set: 0.21316624197204959

Training loss 48889.421875

Recall on (sampled) validation set: 0.20647878862080313

Training loss 48889.68359375

Recall on (sampled) validation set: 0.21062217346745477

Training loss 48889.5546875

Recall on (sampled) validation set: 0.21420968391022835

Training loss 48889.75

Recall on (sampled) validation set: 0.2164719343639489

Training loss 48889.4765625

Recall on (sampled) validation set: 0.20927338482919244

Training loss 48889.546875

Recall on (sampled) validation set: 0.21958004947932352

Training loss 48889.76171875

Recall on (sampled) validation set: 0.21488929961615985

Training loss 48889.625

Recall on (sampled) validation set: 0.2148166179118992

Training loss 48889.73046875

Recall on (sampled) validation set: 0.21101256231836993

Training loss 48889.11328125

Recall on (sampled) validation set: 0.22515521060575508

Training loss 48889.78515625

Recall on (sampled) validation set: 0.2184574172718456

Training loss 48889.91015625

Recall on (sampled) validation set: 0.22036013186920628

Training loss 48889.3046875

Recall on (sampled) validation set: 0.21637791535613676

Training loss 48889.625

Recall on (sampled) validation set: 0.2156662419720496

Training loss 48889.68359375

Recall on (sampled) validation set: 0.22150771346687861

Training loss 48889.5234375

Recall on (sampled) validation set: 0.22173753370713448

Training loss 48889.69140625

Recall on (sampled) validation set: 0.21326414215615666

Training loss 48889.74609375

Recall on (sampled) validation set: 0.21604719435300201

Training loss 48889.875

Recall on (sampled) validation set: 0.21920195625776387

Training loss 48889.93359375

Recall on (sampled) validation set: 0.22126558515759967

Training loss 48889.640625

Recall on (sampled) validation set: 0.2139094145586886

Training loss 48889.8359375

Recall on (sampled) validation set: 0.2206981320420522

Training loss 48889.94140625

Recall on (sampled) validation set: 0.2223223598005812

Training loss 48890.25

Recall on (sampled) validation set: 0.2155344541692092

Training loss 48890.21484375

Recall on (sampled) validation set: 0.2184360112227626

Training loss 48889.62890625

Recall on (sampled) validation set: 0.22377818850504874

Training loss 48889.578125

Recall on (sampled) validation set: 0.21835780041360806

Training loss 48889.44140625

Recall on (sampled) validation set: 0.21929911202597224

Training loss 48889.5234375

Recall on (sampled) validation set: 0.2200849631480303

Training loss 48889.7890625

Recall on (sampled) validation set: 0.21615569313391453

Training loss 48889.78515625

Recall on (sampled) validation set: 0.21850086641193717

Training loss 48889.51171875

Recall on (sampled) validation set: 0.21643347091169232

Training loss 48889.421875

Recall on (sampled) validation set: 0.2189649432707509

Training loss 48889.515625

Recall on (sampled) validation set: 0.21434495023696476

Training loss 48889.4765625

Recall on (sampled) validation set: 0.21803667235836022

Training loss 48889.3046875

Recall on (sampled) validation set: 0.21789038186724213

Training loss 48889.4140625

Recall on (sampled) validation set: 0.21688271903199308

Training loss 48889.390625

Recall on (sampled) validation set: 0.22219854975299622

Training loss 48889.546875

Recall on (sampled) validation set: 0.2101365504496176

Training loss 48889.85546875

Recall on (sampled) validation set: 0.21939295535075934

Training loss 48889.46875

Recall on (sampled) validation set: 0.21609269080049476

Training loss 48889.37890625

Recall on (sampled) validation set: 0.2123865504496176

Training loss 48889.78515625

Recall on (sampled) validation set: 0.21158374406060432

Training loss 48889.4609375

Recall on (sampled) validation set: 0.2146314999445671

Training loss 48889.7265625

Recall on (sampled) validation set: 0.2159965793096465

Training loss 48889.3203125

Recall on (sampled) validation set: 0.2081353313621916

Training loss 48889.38671875

Recall on (sampled) validation set: 0.21784118298183633

Training loss 48889.13671875

Recall on (sampled) validation set: 0.21335090818303157

Training loss 48889.80859375

Recall on (sampled) validation set: 0.21626757484969825

Training loss 48889.31640625

Recall on (sampled) validation set: 0.20981706246633652

Training loss 48889.7734375

Recall on (sampled) validation set: 0.21723317458571542

Training loss 48889.55859375

Recall on (sampled) validation set: 0.21343997947673082

Training loss 48889.8046875

Recall on (sampled) validation set: 0.2120006575564652

Training loss 48889.55078125

Recall on (sampled) validation set: 0.22005137146244227

Training loss 48889.5

Recall on (sampled) validation set: 0.21270606134807588

Training loss 48889.64453125

Recall on (sampled) validation set: 0.21334495023696476

Training loss 48889.73828125

Recall on (sampled) validation set: 0.21667828357029809

Training loss 48889.6484375

Recall on (sampled) validation set: 0.20948286686762183

Training loss 48889.671875

Recall on (sampled) validation set: 0.20890050579252034

Training loss 48889.421875

Recall on (sampled) validation set: 0.21567212789898813

Training loss 48889.19140625

Recall on (sampled) validation set: 0.2139055831410641

Training loss 48889.28125

Recall on (sampled) validation set: 0.21080213486520202

Training loss 48890.08984375

Recall on (sampled) validation set: 0.20778188308632953

Training loss 48889.859375

Recall on (sampled) validation set: 0.2074926110556782

Training loss 48889.8515625

Recall on (sampled) validation set: 0.20427839015860794

Training loss 48889.78515625

Recall on (sampled) validation set: 0.21781101678787707

Training loss 48889.56640625

Recall on (sampled) validation set: 0.21675546123232148

Training loss 48889.1953125

Recall on (sampled) validation set: 0.2173587726718398

Training loss 48889.21484375

Recall on (sampled) validation set: 0.21720728043550186

Training loss 48889.5703125

Recall on (sampled) validation set: 0.21534787421357293

Training loss 48889.58984375

Recall on (sampled) validation set: 0.21636152183838211

Training loss 48889.51171875

Recall on (sampled) validation set: 0.21538052768633528

Training loss 48889.62890625

Recall on (sampled) validation set: 0.21207935809569203

Training loss 48889.234375

Recall on (sampled) validation set: 0.21062443683224083

Training loss 48889.42578125

Recall on (sampled) validation set: 0.21601777650325743

Training loss 48889.453125

Recall on (sampled) validation set: 0.21174198448926218

Training loss 48889.5546875

Recall on (sampled) validation set: 0.21491310913996942

Training loss 48889.86328125

Recall on (sampled) validation set: 0.2128937503982876

Training loss 48889.32421875

Recall on (sampled) validation set: 0.2135998907491648

Training loss 48889.71875

Recall on (sampled) validation set: 0.20896494327075088

Training loss 48889.6015625

Recall on (sampled) validation set: 0.21129859545240667

Training loss 48889.76953125

Recall on (sampled) validation set: 0.21106839154661297

Training loss 48889.671875

Recall on (sampled) validation set: 0.21060170563119746

Training loss 48889.73046875

Recall on (sampled) validation set: 0.2067915212098515

Training loss 48889.58984375

Recall on (sampled) validation set: 0.21189758181591212

Training loss 48889.546875

Recall on (sampled) validation set: 0.21121201929414268

Training loss 48889.30859375

Recall on (sampled) validation set: 0.2079523399233018

Training loss 48889.265625

Recall on (sampled) validation set: 0.20885553704882198

Training loss 48889.859375

Recall on (sampled) validation set: 0.21139556528032027

Training loss 48889.59375

Recall on (sampled) validation set: 0.21677718220141087

Training loss 48889.53125

Recall on (sampled) validation set: 0.21098115805012355

Training loss 48889.49609375

Recall on (sampled) validation set: 0.2100381755939832

Training loss 48889.3984375

Recall on (sampled) validation set: 0.21092041908148984

Training loss 48889.1796875

Recall on (sampled) validation set: 0.2122445627740546

Training loss 48889.5390625

Recall on (sampled) validation set: 0.2215672824520374

Training loss 48889.4140625

Recall on (sampled) validation set: 0.21866725220400354

Training loss 48889.26171875

Recall on (sampled) validation set: 0.21716887241615013

Training loss 48889.5859375

Recall on (sampled) validation set: 0.21143211498792258

Training loss 48889.9296875

Recall on (sampled) validation set: 0.22084111881934027

Training loss 48889.6015625

Recall on (sampled) validation set: 0.2207531978675354

Training loss 48889.6015625

Recall on (sampled) validation set: 0.2159489982357496

Training loss 48889.671875

Recall on (sampled) validation set: 0.21696372418332488

Training loss 48889.63671875

Recall on (sampled) validation set: 0.2145065663985809

Training loss 48889.26953125

Recall on (sampled) validation set: 0.21317316824803212

Training loss 48889.625

Recall on (sampled) validation set: 0.2127143887234631

Training loss 48889.59375

Recall on (sampled) validation set: 0.21522336230684685

Training loss 48889.53125

Recall on (sampled) validation set: 0.21750900457343286

Training loss 48889.88671875

Recall on (sampled) validation set: 0.220595614777103

Training loss 48889.2734375

Recall on (sampled) validation set: 0.2213373973945662

Training loss 48889.17578125

Recall on (sampled) validation set: 0.21574929443078267

Training loss 48889.5859375

Recall on (sampled) validation set: 0.2152173395435646

Training loss 48889.65625

Recall on (sampled) validation set: 0.22369788914117408

Training loss 48889.43359375

Recall on (sampled) validation set: 0.21881836470311966

Training loss 48889.32421875

Recall on (sampled) validation set: 0.21497889861365357

Training loss 48890.03125

Recall on (sampled) validation set: 0.21698422279139157

Training loss 48889.7265625

Recall on (sampled) validation set: 0.2116744973283086

Training loss 48889.60546875

Recall on (sampled) validation set: 0.21634630616073447

Training loss 48889.5546875

Recall on (sampled) validation set: 0.2123223598005812

Training loss 48889.3359375

Recall on (sampled) validation set: 0.21377446708027467

Training loss 48889.25390625

Recall on (sampled) validation set: 0.22518238866061008

Training loss 48889.80078125

Recall on (sampled) validation set: 0.21848011770107958

Training loss 48889.484375

Recall on (sampled) validation set: 0.21424299472121613

Training loss 48889.6640625

Recall on (sampled) validation set: 0.2162665305723382

Training loss 48889.375

Recall on (sampled) validation set: 0.2164691131782783

Training loss 48889.71484375

Recall on (sampled) validation set: 0.21546508010709464

Training loss 48889.765625

Recall on (sampled) validation set: 0.21135007276114354

Training loss 48889.75390625

Recall on (sampled) validation set: 0.2150080323152011

Training loss 48889.41015625

Recall on (sampled) validation set: 0.22046013959489458

Training loss 48889.51953125

Recall on (sampled) validation set: 0.21838420786379042

Training loss 48889.4609375

Recall on (sampled) validation set: 0.2132150801070946

Training loss 48889.37890625

Recall on (sampled) validation set: 0.219843977978733

Training loss 48889.56640625

Recall on (sampled) validation set: 0.21250173980754744

Training loss 48889.76171875

Recall on (sampled) validation set: 0.2198410540021248

Training loss 48889.48046875

Recall on (sampled) validation set: 0.21921883950559087

Training loss 48889.61328125

Recall on (sampled) validation set: 0.21854841344042797

Training loss 48889.46875

Recall on (sampled) validation set: 0.21771904836106287

Training loss 48889.7109375

Recall on (sampled) validation set: 0.21890458403933902

Training loss 48889.359375

Recall on (sampled) validation set: 0.21896183968280156

Training loss 48889.63671875

Recall on (sampled) validation set: 0.22290458403933902

Training loss 48889.59375

Recall on (sampled) validation set: 0.20962669626871078

Training loss 48889.6640625

Recall on (sampled) validation set: 0.21446386101966866

Training loss 48889.546875

Recall on (sampled) validation set: 0.2168210038768115

Training loss 48889.34375

Recall on (sampled) validation set: 0.21777815445964266

Training loss 48889.609375

Recall on (sampled) validation set: 0.22002843533424296

Training loss 48889.60546875

Recall on (sampled) validation set: 0.22265788775316905

Training loss 48888.98828125

Recall on (sampled) validation set: 0.2195839908897985

Training loss 48889.703125

Recall on (sampled) validation set: 0.21701148006728768

Training loss 48889.31640625

Recall on (sampled) validation set: 0.22175667639143137

Training loss 48889.61328125

Recall on (sampled) validation set: 0.2150675561247249

Training loss 48889.3359375

Recall on (sampled) validation set: 0.2216470580404337

Training loss 48889.66015625

Recall on (sampled) validation set: 0.22071410784886283

Training loss 48889.86328125

Recall on (sampled) validation set: 0.21712791535613676

Training loss 48889.3984375

Recall on (sampled) validation set: 0.21740938771519533

Training loss 48889.73046875

Recall on (sampled) validation set: 0.21649935139136592

Training loss 48889.38671875

Recall on (sampled) validation set: 0.21940821838643979

Training loss 48889.38671875

Recall on (sampled) validation set: 0.21952063566265015

Training loss 48889.4453125

Recall on (sampled) validation set: 0.21765355154692723

Training loss 48889.3359375

Recall on (sampled) validation set: 0.2172775278932266

Training loss 48889.60546875

Recall on (sampled) validation set: 0.21365848027417902

Training loss 48889.484375

Recall on (sampled) validation set: 0.21846494327075086

Training loss 48889.33984375

Recall on (sampled) validation set: 0.21943566553094684

Training loss 48889.99609375

Recall on (sampled) validation set: 0.21789357951653773

Training loss 48889.8046875

Recall on (sampled) validation set: 0.21654471885914717

Training loss 48889.5234375

Recall on (sampled) validation set: 0.21573047059480813

Training loss 48889.58984375

Recall on (sampled) validation set: 0.2190741367088917

Training loss 48889.46875

Recall on (sampled) validation set: 0.21579855027677175

Training loss 48889.609375

Recall on (sampled) validation set: 0.21148457568512014

Training loss 48889.546875

Recall on (sampled) validation set: 0.2202429947212161

Training loss 48889.578125

Recall on (sampled) validation set: 0.2231196331563845

Training loss 48889.21484375

Recall on (sampled) validation set: 0.20962394710216853

Training loss 48889.61328125

Recall on (sampled) validation set: 0.21874272104852868

Training loss 48889.609375

Recall on (sampled) validation set: 0.2222553702263321

Training loss 48889.578125

Recall on (sampled) validation set: 0.22890050579252033

Training loss 48889.25390625

Recall on (sampled) validation set: 0.22551955341156793

Training loss 48889.453125

Recall on (sampled) validation set: 0.22469654500235264

Training loss 48889.69140625

Recall on (sampled) validation set: 0.21873636437837887

Training loss 48890.03125

Recall on (sampled) validation set: 0.22434758548234043

Training loss 48889.609375

Recall on (sampled) validation set: 0.22360635741216503

Training loss 48889.87109375

Recall on (sampled) validation set: 0.22444501492323637

Training loss 48889.51171875

Recall on (sampled) validation set: 0.22827274320423138

Training loss 48889.3515625

Recall on (sampled) validation set: 0.22411805331859777

Training loss 48889.23046875

Recall on (sampled) validation set: 0.2172304555362631

Training loss 48889.80078125

Recall on (sampled) validation set: 0.2232628359910574

Training loss 48889.0859375

Recall on (sampled) validation set: 0.22021785218881404

Training loss 48889.421875

Recall on (sampled) validation set: 0.21457774421249923

Training loss 48889.546875

Recall on (sampled) validation set: 0.21855448203406458

Training loss 48889.55859375

Recall on (sampled) validation set: 0.2249269505617055

Training loss 48889.2734375

Recall on (sampled) validation set: 0.22238041376516876

Training loss 48889.4453125

Recall on (sampled) validation set: 0.21928781484362248

Training loss 48889.80078125

Recall on (sampled) validation set: 0.21956159032202588

Training loss 48889.19921875

Recall on (sampled) validation set: 0.22596767017683533

Training loss 48889.984375

Recall on (sampled) validation set: 0.22753135450957596

Training loss 48889.546875

Recall on (sampled) validation set: 0.22630669564018022

Training loss 48889.640625

Recall on (sampled) validation set: 0.2294226634594148

Training loss 48889.18359375

Recall on (sampled) validation set: 0.2284858818502194

Training loss 48889.609375

Recall on (sampled) validation set: 0.22917294433401508

Training loss 48889.5234375

Recall on (sampled) validation set: 0.2294548272021049

Training loss 48889.07421875

Recall on (sampled) validation set: 0.22555762446869523

Training loss 48889.359375

Recall on (sampled) validation set: 0.2297874540932617

Training loss 48889.5703125

Recall on (sampled) validation set: 0.22856166234115421

Training loss 48889.64453125

Recall on (sampled) validation set: 0.2315077704274619

Training loss 48889.46484375

Recall on (sampled) validation set: 0.2292604207313826

Training loss 48889.38671875

Recall on (sampled) validation set: 0.22622916442970886

Training loss 48889.64453125

Recall on (sampled) validation set: 0.22744098185205264

Training loss 48889.46875

Recall on (sampled) validation set: 0.22201254725982494

Training loss 48889.76171875

Recall on (sampled) validation set: 0.22551835723931912

Training loss 48889.67578125

Recall on (sampled) validation set: 0.2275340213997201

Training loss 48889.46875

Recall on (sampled) validation set: 0.2205076067476249

Training loss 48889.7890625

Recall on (sampled) validation set: 0.22480922089270544

Training loss 48889.3046875

Recall on (sampled) validation set: 0.22645124261367455

Training loss 48889.73828125

Recall on (sampled) validation set: 0.2260700165600347

Training loss 48889.44140625

Recall on (sampled) validation set: 0.22509779433781252

Training loss 48889.4453125

Recall on (sampled) validation set: 0.23152643058359937

Training loss 48889.4765625

Recall on (sampled) validation set: 0.22308588957590772

Training loss 48889.23828125

Recall on (sampled) validation set: 0.22696889646617413

Training loss 48889.36328125

Recall on (sampled) validation set: 0.23446329141383587

Training loss 48889.5859375

Recall on (sampled) validation set: 0.22842799483906562

Training loss 48889.5234375

Recall on (sampled) validation set: 0.227092743832762

Training loss 48889.71875

Recall on (sampled) validation set: 0.2321514361487138

Training loss 48889.53125

Recall on (sampled) validation set: 0.22811955328062405

Training loss 48889.546875

Recall on (sampled) validation set: 0.23044420634484156

Training loss 48889.328125

Recall on (sampled) validation set: 0.22366567236621682

Training loss 48889.80078125

Recall on (sampled) validation set: 0.21995159550740312

Training loss 48889.25

Recall on (sampled) validation set: 0.23417100374586766

Training loss 48889.42578125

Recall on (sampled) validation set: 0.22778485682160815

Training loss 48889.8046875

Recall on (sampled) validation set: 0.22902006605681738

Training loss 48889.140625

Recall on (sampled) validation set: 0.22566525465527282

Training loss 48889.44921875

Recall on (sampled) validation set: 0.22691469290607216

Training loss 48889.44921875

Recall on (sampled) validation set: 0.2209793732851809

Training loss 48889.31640625

Recall on (sampled) validation set: 0.22111826217406977

Training loss 48889.53125

Recall on (sampled) validation set: 0.22018495908877034

Training loss 48889.35546875

Recall on (sampled) validation set: 0.22304505276601466

Training loss 48889.85546875

Recall on (sampled) validation set: 0.2224199863120008

Training loss 48889.7109375

Recall on (sampled) validation set: 0.22091560034708854

Training loss 48889.21484375

Recall on (sampled) validation set: 0.2296898996009704

Training loss 48889.6640625

Recall on (sampled) validation set: 0.22352699233279993

Training loss 48889.94140625

Recall on (sampled) validation set: 0.22576940151667918

Training loss 48889.44921875

Recall on (sampled) validation set: 0.2253088752008897

Training loss 48889.6953125

Recall on (sampled) validation set: 0.22309458948660396

Training loss 48889.62109375

Recall on (sampled) validation set: 0.22899065148066963

Training loss 48889.703125

Recall on (sampled) validation set: 0.23015334989336803

Training loss 48889.6484375

Recall on (sampled) validation set: 0.22478374052511982

Training loss 48889.4609375

Recall on (sampled) validation set: 0.2273718506908162

Training loss 48890.03515625

Recall on (sampled) validation set: 0.22357012655288513

Training loss 48889.1640625

Recall on (sampled) validation set: 0.22213726802202302

Training loss 48889.50390625

Recall on (sampled) validation set: 0.22569282357757856

Training loss 48889.89453125

Recall on (sampled) validation set: 0.21540519554721005

Training loss 48889.39453125

Recall on (sampled) validation set: 0.2226978740826291

Training loss 48889.515625

Recall on (sampled) validation set: 0.21908383899490977

Training loss 48889.4296875

Recall on (sampled) validation set: 0.2243149660549842

Training loss 48889.40625

Recall on (sampled) validation set: 0.2274301822564073

Training loss 48889.68359375

Recall on (sampled) validation set: 0.2176208332569494

Training loss 48889.28125

Recall on (sampled) validation set: 0.22283937530171646

Training loss 48889.8515625

Recall on (sampled) validation set: 0.2214983791331341

Training loss 48889.765625

Recall on (sampled) validation set: 0.22341121438217626

Training loss 48889.61328125

Recall on (sampled) validation set: 0.21816384962755198

Training loss 48889.56640625

Recall on (sampled) validation set: 0.22150837015038466

Training loss 48889.3515625

Recall on (sampled) validation set: 0.2249150457998008

Training loss 48889.38671875

Recall on (sampled) validation set: 0.22660854482950674

Training loss 48889.4140625

Recall on (sampled) validation set: 0.22764098944679706

Training loss 48889.3046875

Recall on (sampled) validation set: 0.22495076008551507

Training loss 48889.28125

Recall on (sampled) validation set: 0.21714316180559373

Training loss 48889.4296875

Recall on (sampled) validation set: 0.2250576561134637

Training loss 48889.46875

Recall on (sampled) validation set: 0.22513593894174658

Training loss 48889.7265625

Recall on (sampled) validation set: 0.22758891241513746

Training loss 48889.14453125

Recall on (sampled) validation set: 0.22073072528063453

Training loss 48889.25390625

Recall on (sampled) validation set: 0.22140233245950122

Training loss 48889.44140625

Recall on (sampled) validation set: 0.22878718827720643

Training loss 48889.8984375

Recall on (sampled) validation set: 0.22079888418363916

Training loss 48889.7734375

Recall on (sampled) validation set: 0.22205132235849115

Training loss 48889.3046875

Recall on (sampled) validation set: 0.22528156816632314

Training loss 48889.49609375

Recall on (sampled) validation set: 0.22421182942553178

Training loss 48889.609375

Recall on (sampled) validation set: 0.2226599952947503

Training loss 48889.80859375

Recall on (sampled) validation set: 0.22578109742311195

Training loss 48889.38671875

Recall on (sampled) validation set: 0.22096555085030584

Training loss 48889.67578125

Recall on (sampled) validation set: 0.22503492884073648

Training loss 48889.73828125

Recall on (sampled) validation set: 0.23368394165490353

Training loss 48889.59375

Recall on (sampled) validation set: 0.22604627185344062

Training loss 48889.18359375

Recall on (sampled) validation set: 0.23558459846935345

Training loss 48889.3203125

Recall on (sampled) validation set: 0.22805309926680162

Training loss 48889.3984375

Recall on (sampled) validation set: 0.22285071831442063

Training loss 48889.10546875

Recall on (sampled) validation set: 0.2277495982205601

Training loss 48889.359375

Recall on (sampled) validation set: 0.23062849609219843

Training loss 48889.1015625

Recall on (sampled) validation set: 0.2295600903599996

Training loss 48889.24609375

Recall on (sampled) validation set: 0.22368969074549833

Training loss 48889.69921875

Recall on (sampled) validation set: 0.22460565882662073

Training loss 48889.13671875

Recall on (sampled) validation set: 0.22644307040677275

Training loss 48889.8359375

Recall on (sampled) validation set: 0.23106798103758175

Training loss 48889.8203125

Recall on (sampled) validation set: 0.2312951627588651

Training loss 48889.14453125

Recall on (sampled) validation set: 0.23187971517962444

Training loss 48889.18359375

Recall on (sampled) validation set: 0.23548960720330958

Training loss 48889.55078125

Recall on (sampled) validation set: 0.22734566780937016

Training loss 48889.75

Recall on (sampled) validation set: 0.23607690879061113

Training loss 48889.24609375

Recall on (sampled) validation set: 0.23002135323505557

Training loss 48889.67578125

Recall on (sampled) validation set: 0.23919487415857651

Training loss 48889.36328125

Recall on (sampled) validation set: 0.23368777307252808

Training loss 48889.12890625

Recall on (sampled) validation set: 0.22613343660439847

Training loss 48889.078125

Recall on (sampled) validation set: 0.22938726802202297

Training loss 48889.3984375

Recall on (sampled) validation set: 0.23382415962406886

Training loss 48889.453125

Recall on (sampled) validation set: 0.228352844842863

Training loss 48889.32421875

Recall on (sampled) validation set: 0.2347761569109119

Training loss 48889.2734375

Recall on (sampled) validation set: 0.23336237624713127

Training loss 48889.56640625

Recall on (sampled) validation set: 0.23615738296455177

Training loss 48889.53515625

Recall on (sampled) validation set: 0.24004516275886512

Training loss 48889.265625

Recall on (sampled) validation set: 0.23840585615903218

Training loss 48889.265625

Recall on (sampled) validation set: 0.230934051647754

Training loss 48889.390625

Recall on (sampled) validation set: 0.2332942173441266

Training loss 48889.296875

Recall on (sampled) validation set: 0.22862344558714795

Training loss 48889.12109375

Recall on (sampled) validation set: 0.23420966492336726

Training loss 48889.2109375

Recall on (sampled) validation set: 0.23742527971792943

Training loss 48889.16015625

Recall on (sampled) validation set: 0.23255395760386685

Training loss 48889.265625

Recall on (sampled) validation set: 0.23290271612503916

Training loss 48889.765625

Recall on (sampled) validation set: 0.2263496360633384

Training loss 48889.5

Recall on (sampled) validation set: 0.22685360431730667

Training loss 48889.2734375

Recall on (sampled) validation set: 0.23342422431034046

Training loss 48889.5

Recall on (sampled) validation set: 0.23902458492975734

Training loss 48889.37890625

Recall on (sampled) validation set: 0.23117900114270346

Training loss 48889.44140625

Recall on (sampled) validation set: 0.22925850305841228

Training loss 48889.48828125

Recall on (sampled) validation set: 0.23383811496697157

Training loss 48889.21484375

Recall on (sampled) validation set: 0.23489750194015163

Training loss 48889.3359375

Recall on (sampled) validation set: 0.23928134032399007

Training loss 48889.328125

Recall on (sampled) validation set: 0.23708814181046486

Training loss 48889.17578125

Recall on (sampled) validation set: 0.2504115561456759

Training loss 48889.46875

Recall on (sampled) validation set: 0.23981056110321083

Training loss 48889.73828125

Recall on (sampled) validation set: 0.23667011922002842

Training loss 48889.578125

Recall on (sampled) validation set: 0.23142516972507896

Training loss 48889.4453125

Recall on (sampled) validation set: 0.23418801990172228

Training loss 48889.640625

Recall on (sampled) validation set: 0.23677653664813372

Training loss 48889.578125

Recall on (sampled) validation set: 0.23754430442179986

Training loss 48888.9296875

Recall on (sampled) validation set: 0.23581139652509886

Training loss 48889.28515625

Recall on (sampled) validation set: 0.23556863444749107

Training loss 48889.2734375

Recall on (sampled) validation set: 0.23561708891699815

Training loss 48889.55859375

Recall on (sampled) validation set: 0.24138801243792168

Training loss 48889.640625

Recall on (sampled) validation set: 0.23924105020475253

Training loss 48889.49609375

Recall on (sampled) validation set: 0.2336994499920997

Training loss 48889.7734375

Recall on (sampled) validation set: 0.23791892304777965

Training loss 48889.48046875

Recall on (sampled) validation set: 0.23992476707267996

Training loss 48889.55078125

Recall on (sampled) validation set: 0.2371121484047981

Training loss 48889.109375

Recall on (sampled) validation set: 0.23611325749937365

Training loss 48889.4765625

Recall on (sampled) validation set: 0.22972294066758678

Training loss 48889.21875

Recall on (sampled) validation set: 0.23623017858997894

Training loss 48889.7265625

Recall on (sampled) validation set: 0.23799407304398226

Training loss 48889.23828125

Recall on (sampled) validation set: 0.23864395925375959

Training loss 48889.703125

Recall on (sampled) validation set: 0.23167974555860216

Training loss 48889.25

Recall on (sampled) validation set: 0.23652498365384025

Training loss 48889.0390625

Recall on (sampled) validation set: 0.2302445287286485

Training loss 48889.515625

Recall on (sampled) validation set: 0.2318841162030817

Training loss 48889.328125

Recall on (sampled) validation set: 0.23379447923186575

Training loss 48889.66015625

Recall on (sampled) validation set: 0.23214862609327222

Training loss 48889.578125

Recall on (sampled) validation set: 0.23494426265070548

Training loss 48889.23828125

Recall on (sampled) validation set: 0.23790219169484136

Training loss 48889.0546875

Recall on (sampled) validation set: 0.2295289519078085

Training loss 48889.015625

Recall on (sampled) validation set: 0.2314917946206512

Training loss 48889.36328125

Recall on (sampled) validation set: 0.23968804281689945

Training loss 48889.19921875

Recall on (sampled) validation set: 0.2353865275344404

Training loss 48889.390625

Recall on (sampled) validation set: 0.23669460114060836

Training loss 48889.046875

Recall on (sampled) validation set: 0.23447160765899422

Training loss 48889.43359375

Recall on (sampled) validation set: 0.23530398051904403

Training loss 48889.55859375

Recall on (sampled) validation set: 0.23188355445388112

Training loss 48889.1796875

Recall on (sampled) validation set: 0.24146482542126824

Training loss 48889.06640625

Recall on (sampled) validation set: 0.23973241511127175

Training loss 48888.93359375

Recall on (sampled) validation set: 0.2386818871455895

Training loss 48889.390625

Recall on (sampled) validation set: 0.23383103679610032

Training loss 48889.13671875

Recall on (sampled) validation set: 0.23518270358061646

Training loss 48889.48828125

Recall on (sampled) validation set: 0.23458861255367605

Training loss 48889.375

Recall on (sampled) validation set: 0.22856063312233915

Training loss 48889.13671875

Recall on (sampled) validation set: 0.23174056047468022

Training loss 48889.5234375

Recall on (sampled) validation set: 0.22958327331739306

Training loss 48889.10546875

Recall on (sampled) validation set: 0.22870348306328345

Training loss 48889.01953125

Recall on (sampled) validation set: 0.23710927746045712

Training loss 48889.44140625

Recall on (sampled) validation set: 0.22845767523126873

Training loss 48888.86328125

Recall on (sampled) validation set: 0.22979195397934055

Training loss 48889.25

Recall on (sampled) validation set: 0.2297789669663535

Training loss 48889.0703125

Recall on (sampled) validation set: 0.22922990491729148

Training loss 48889.453125

Recall on (sampled) validation set: 0.2300444792318658

Training loss 48888.953125

Recall on (sampled) validation set: 0.22898509225868574

Training loss 48889.37890625

Recall on (sampled) validation set: 0.2315951211187146

Training loss 48888.99609375

Recall on (sampled) validation set: 0.22970486124751097

Training loss 48889.30859375

Recall on (sampled) validation set: 0.22621403190141848

Training loss 48889.375

Recall on (sampled) validation set: 0.22540129603877337

Training loss 48889.26953125

Recall on (sampled) validation set: 0.22003429114409148

Training loss 48889.21484375

Recall on (sampled) validation set: 0.2251021691724959

Training loss 48888.890625

Recall on (sampled) validation set: 0.2267208710997277

Training loss 48889.49609375

Recall on (sampled) validation set: 0.22444280459071744

Training loss 48889.12109375

Recall on (sampled) validation set: 0.22454064781424127

Training loss 48888.87890625

Recall on (sampled) validation set: 0.22753307205666554

Training loss 48889.2890625

Recall on (sampled) validation set: 0.23127766080125425

Training loss 48889.63671875

Recall on (sampled) validation set: 0.23456468125206784

Training loss 48889.1796875

Recall on (sampled) validation set: 0.22910571971552007

Training loss 48889.3515625

Recall on (sampled) validation set: 0.23242543161281815

Training loss 48889.2734375

Recall on (sampled) validation set: 0.22432007744893406

Training loss 48889.4140625

Recall on (sampled) validation set: 0.2293397818824316

Training loss 48889.546875

Recall on (sampled) validation set: 0.22714012783613508

Training loss 48889.30078125

Recall on (sampled) validation set: 0.2243556548983046

Training loss 48889.26171875

Recall on (sampled) validation set: 0.220724630498224

Training loss 48889.10546875

Recall on (sampled) validation set: 0.220486398423785

Training loss 48889.37109375

Recall on (sampled) validation set: 0.21794309332194994

Training loss 48889.25390625

Recall on (sampled) validation set: 0.22739116032854692

Training loss 48889.0703125

Recall on (sampled) validation set: 0.22007273953780304

Training loss 48889.48046875

Recall on (sampled) validation set: 0.2249390530488534

Training loss 48889.08984375

Recall on (sampled) validation set: 0.2210687712838348

Training loss 48889.4140625

Recall on (sampled) validation set: 0.2227547966921833

Training loss 48889.36328125

Recall on (sampled) validation set: 0.23062946442211413

Training loss 48889.37890625

Recall on (sampled) validation set: 0.2296954097190032

Training loss 48889.34375

Recall on (sampled) validation set: 0.22428509972248628

Training loss 48889.40625

Recall on (sampled) validation set: 0.2245895730269596

Training loss 48889.53125

Recall on (sampled) validation set: 0.22474363634617717

Training loss 48888.81640625

Recall on (sampled) validation set: 0.22904389456748803

Training loss 48889.12890625

Recall on (sampled) validation set: 0.22497954416693072

Training loss 48889.01171875

Recall on (sampled) validation set: 0.22172449366188024

Training loss 48888.8984375

Recall on (sampled) validation set: 0.22512966607567336

Training loss 48888.68359375

Recall on (sampled) validation set: 0.22075240827600173

Training loss 48889.15625

Recall on (sampled) validation set: 0.22448351242089898

Training loss 48889.26953125

Recall on (sampled) validation set: 0.21528401747140402

Training loss 48889.5390625

Recall on (sampled) validation set: 0.21817412544771894

Training loss 48888.91015625

Recall on (sampled) validation set: 0.2251334326760824

Training loss 48889.12890625

Recall on (sampled) validation set: 0.21653798572537228

Training loss 48889.21875

Recall on (sampled) validation set: 0.22061783333289686

Training loss 48889.51953125

Recall on (sampled) validation set: 0.2246283101519036

Training loss 48889.26171875

Recall on (sampled) validation set: 0.2298117952491818

Training loss 48889.078125

Recall on (sampled) validation set: 0.22426925355010652

Training loss 48889.21484375

Recall on (sampled) validation set: 0.21980023617909278

Training loss 48888.84375

Recall on (sampled) validation set: 0.22095190322549668

Training loss 48889.046875

Recall on (sampled) validation set: 0.21953272636484977

Training loss 48889.14453125

Recall on (sampled) validation set: 0.22239116032854686

Training loss 48889.109375

Recall on (sampled) validation set: 0.22302752396491055

Training loss 48888.953125

Recall on (sampled) validation set: 0.2225975095348961

Training loss 48889.05078125

Recall on (sampled) validation set: 0.22114116032854686

Training loss 48889.10546875

Recall on (sampled) validation set: 0.22455810066790102

Training loss 48889.23046875

Recall on (sampled) validation set: 0.2194744936618802

Training loss 48889.37890625

Recall on (sampled) validation set: 0.22971299940900664

Training loss 48888.9140625

Recall on (sampled) validation set: 0.23043508479488517

Training loss 48888.984375

Recall on (sampled) validation set: 0.21950227143965806

Training loss 48888.671875

Recall on (sampled) validation set: 0.22321944315682973

Training loss 48888.9609375

Recall on (sampled) validation set: 0.22248796167534826

Training loss 48889.3984375

Recall on (sampled) validation set: 0.22362831015190363

Training loss 48889.0546875

Recall on (sampled) validation set: 0.22600947138832803

Training loss 48889.046875

Recall on (sampled) validation set: 0.22389116032854692

Training loss 48889.31640625

Recall on (sampled) validation set: 0.229752271439658

Training loss 48889.39453125

Recall on (sampled) validation set: 0.22138732891092236

Training loss 48889.10546875

Recall on (sampled) validation set: 0.22259437670281584

Training loss 48888.82421875

Recall on (sampled) validation set: 0.22705782699521354

Training loss 48889.28515625

Recall on (sampled) validation set: 0.22687215448059367

Training loss 48888.88671875

Recall on (sampled) validation set: 0.2231963171600195

Training loss 48889.5390625

Recall on (sampled) validation set: 0.21964213258677867

Training loss 48889.28125

Recall on (sampled) validation set: 0.22329633274233998

Training loss 48889.0

Recall on (sampled) validation set: 0.21845931923155154

Training loss 48888.87890625

Recall on (sampled) validation set: 0.21739993225837148

Training loss 48889.375

Recall on (sampled) validation set: 0.21539848925692848

Training loss 48888.9296875

Recall on (sampled) validation set: 0.22187215448059366

Training loss 48889.12890625

Recall on (sampled) validation set: 0.22220548781392704

Training loss 48889.3359375

Recall on (sampled) validation set: 0.22181646208869438

Training loss 48888.9140625

Recall on (sampled) validation set: 0.21584437670281587

Training loss 48889.35546875

Recall on (sampled) validation set: 0.2219048727705715

Training loss 48889.36328125

Recall on (sampled) validation set: 0.21429387165231087

Training loss 48889.62890625

Recall on (sampled) validation set: 0.2189832655917048

Training loss 48889.17578125

Recall on (sampled) validation set: 0.21972943417408028

Training loss 48888.86328125

Recall on (sampled) validation set: 0.21623326559170475

Training loss 48889.32421875

Recall on (sampled) validation set: 0.2185070751155143

Training loss 48889.06640625

Recall on (sampled) validation set: 0.21635813497519488

Training loss 48888.8984375

Recall on (sampled) validation set: 0.22258788319632242

Training loss 48889.41015625

Recall on (sampled) validation set: 0.21766032199970492

Training loss 48889.1796875

Recall on (sampled) validation set: 0.2232507904644928

Training loss 48888.6953125

Recall on (sampled) validation set: 0.22116510668870015

Training loss 48889.2734375

Recall on (sampled) validation set: 0.22721470822650494

Training loss 48889.03515625

Recall on (sampled) validation set: 0.22193023528867448

Training loss 48889.359375

Recall on (sampled) validation set: 0.221754933528527

Training loss 48889.12109375

Recall on (sampled) validation set: 0.21737071147915066

Training loss 48889.17578125

Recall on (sampled) validation set: 0.21962864798708723

Training loss 48889.3046875

Recall on (sampled) validation set: 0.21510093502652486

Training loss 48889.17578125

Recall on (sampled) validation set: 0.21173469353460278

Training loss 48889.1015625

Recall on (sampled) validation set: 0.21349509833448124

Training loss 48889.19140625

Recall on (sampled) validation set: 0.20947560275645577

Training loss 48888.96875

Recall on (sampled) validation set: 0.21461266497836373

Training loss 48889.37109375

Recall on (sampled) validation set: 0.2155768138563057

Training loss 48889.18359375

Recall on (sampled) validation set: 0.21390870418819602

Training loss 48889.24609375

Recall on (sampled) validation set: 0.2195982081204404

Training loss 48889.65625

Recall on (sampled) validation set: 0.22412046464995644

Training loss 48889.21484375

Recall on (sampled) validation set: 0.2183253708548627

Training loss 48889.2734375

Recall on (sampled) validation set: 0.21522704575789875

Training loss 48889.01171875

Recall on (sampled) validation set: 0.21929531465375385

Training loss 48889.46484375

Recall on (sampled) validation set: 0.2135423186580174

Training loss 48889.21484375

Recall on (sampled) validation set: 0.21564044275614147

Training loss 48889.3203125

Recall on (sampled) validation set: 0.21262060148630021

Training loss 48888.8515625

Recall on (sampled) validation set: 0.21880613716457636

Training loss 48889.36328125

Recall on (sampled) validation set: 0.21526503061031194

Training loss 48888.796875

Recall on (sampled) validation set: 0.21624431594486046

Training loss 48889.484375

Recall on (sampled) validation set: 0.2177824644771106

Training loss 48888.8203125

Recall on (sampled) validation set: 0.21575468669933276

Training loss 48888.7265625

Recall on (sampled) validation set: 0.22141957645768898

Training loss 48888.953125

Recall on (sampled) validation set: 0.22069913114377726

Training loss 48888.875

Recall on (sampled) validation set: 0.21622774434344308

Training loss 48889.4296875

Recall on (sampled) validation set: 0.20966111944787083

Training loss 48889.0234375

Recall on (sampled) validation set: 0.21649768927718108

Training loss 48889.1953125

Recall on (sampled) validation set: 0.2176006233801152

Training loss 48888.734375

Recall on (sampled) validation set: 0.2194693102488021

Training loss 48888.78515625

Recall on (sampled) validation set: 0.21807406468976342

Training loss 48889.2734375

Recall on (sampled) validation set: 0.2136582334449848

Training loss 48889.140625

Recall on (sampled) validation set: 0.21338730992406132

Training loss 48889.11328125

Recall on (sampled) validation set: 0.2130094903751891

Training loss 48889.15625

Recall on (sampled) validation set: 0.21626106235634368

Training loss 48888.75

Recall on (sampled) validation set: 0.21516452595263846

Training loss 48888.8984375

Recall on (sampled) validation set: 0.2129705064210509

Training loss 48889.171875

Recall on (sampled) validation set: 0.2144080966086411

Training loss 48888.91015625

Recall on (sampled) validation set: 0.2168464082969528

Training loss 48889.1640625

Recall on (sampled) validation set: 0.21301168172084686

Training loss 48889.03125

Recall on (sampled) validation set: 0.205168357370263

Training loss 48888.953125

Recall on (sampled) validation set: 0.21030492200546647

Training loss 48888.96875

Recall on (sampled) validation set: 0.2090509537514982

Training loss 48888.6953125

Recall on (sampled) validation set: 0.21013730992406132

Training loss 48888.82421875

Recall on (sampled) validation set: 0.21499664019854584

Training loss 48889.4140625

Recall on (sampled) validation set: 0.21352598995747815

Training loss 48889.38671875

Recall on (sampled) validation set: 0.21514935152230977

Training loss 48889.3046875

Recall on (sampled) validation set: 0.21225663121579633

Training loss 48889.109375

Recall on (sampled) validation set: 0.21084042743570874

Training loss 48888.6796875

Recall on (sampled) validation set: 0.2115977373772292

Training loss 48889.12890625

Recall on (sampled) validation set: 0.21041206486260933

Training loss 48889.09375

Recall on (sampled) validation set: 0.21804315407990543

Training loss 48889.18359375

Recall on (sampled) validation set: 0.21201812546866994

Training loss 48889.01171875

Recall on (sampled) validation set: 0.2184903476908922

Training loss 48888.84375

Recall on (sampled) validation set: 0.2181216837373825

Training loss 48888.87109375

Recall on (sampled) validation set: 0.21543096071771206

Training loss 48888.75

Recall on (sampled) validation set: 0.21313045566720704

Training loss 48889.21875

Recall on (sampled) validation set: 0.21293723031018857

Training loss 48888.859375

Recall on (sampled) validation set: 0.21483558578613024

Training loss 48889.203125

Recall on (sampled) validation set: 0.21140715119390252

Training loss 48888.96875

Recall on (sampled) validation set: 0.21320751940806387

Training loss 48888.5234375

Recall on (sampled) validation set: 0.21823651627326762

Training loss 48888.859375

Recall on (sampled) validation set: 0.21204488581258094

Training loss 48888.8359375

Recall on (sampled) validation set: 0.20995368799043934

Training loss 48889.1015625

Recall on (sampled) validation set: 0.2079538248267831

Training loss 48888.89453125

Recall on (sampled) validation set: 0.20666206486260932

Training loss 48889.171875

Recall on (sampled) validation set: 0.2026570143575588

Training loss 48888.93359375

Recall on (sampled) validation set: 0.207371573744532

Training loss 48889.140625

Recall on (sampled) validation set: 0.2033666600758252

Training loss 48888.6953125

Recall on (sampled) validation set: 0.2080092435459949

Training loss 48888.9140625

Recall on (sampled) validation set: 0.21654468415902173

Training loss 48889.19140625

Recall on (sampled) validation set: 0.2075899645491297

Training loss 48888.046875

Recall on (sampled) validation set: 0.20660445479773973

Training loss 48889.26171875

Recall on (sampled) validation set: 0.21324417910851667

Training loss 48888.98046875

Recall on (sampled) validation set: 0.20978037592239043

Training loss 48888.671875

Recall on (sampled) validation set: 0.20994286547961682

Training loss 48889.03125

Recall on (sampled) validation set: 0.2154347921353366

Training loss 48889.13671875

Recall on (sampled) validation set: 0.2138476273843787

Training loss 48889.015625

Recall on (sampled) validation set: 0.2104347921353366

Training loss 48888.625

Recall on (sampled) validation set: 0.21205411342707167

Training loss 48889.14453125

Recall on (sampled) validation set: 0.20715329293278478

Training loss 48888.890625

Recall on (sampled) validation set: 0.20677223055898192

Training loss 48888.734375

Recall on (sampled) validation set: 0.2070063575431089

Training loss 48888.84375

Recall on (sampled) validation set: 0.2083488464718047

Training loss 48888.7734375

Recall on (sampled) validation set: 0.20495463340517786

Training loss 48889.078125

Recall on (sampled) validation set: 0.20893997947673082

Training loss 48888.62109375

Recall on (sampled) validation set: 0.20968876038930484

Training loss 48888.94921875

Recall on (sampled) validation set: 0.20685650930705377

Training loss 48888.83984375

Recall on (sampled) validation set: 0.21185772839447978

Training loss 48888.87109375

Recall on (sampled) validation set: 0.21052822647877095

Training loss 48889.00390625

Recall on (sampled) validation set: 0.20915837028132853

Training loss 48888.7265625

Recall on (sampled) validation set: 0.20800339952109462

Training loss 48888.8203125

Recall on (sampled) validation set: 0.20841342078637906

Training loss 48888.73828125

Recall on (sampled) validation set: 0.21146883950559087

Training loss 48888.92578125

Recall on (sampled) validation set: 0.21284554995988753

Training loss 48888.9609375

Recall on (sampled) validation set: 0.21107764927819375

Training loss 48889.125

Recall on (sampled) validation set: 0.21315715119390258

Training loss 48888.796875

Recall on (sampled) validation set: 0.2104799356891008

Training loss 48888.640625

Recall on (sampled) validation set: 0.212549871500416

Training loss 48888.828125

Recall on (sampled) validation set: 0.21268190613245058

Training loss 48889.18359375

Recall on (sampled) validation set: 0.2130520360025805

Training loss 48889.203125

Recall on (sampled) validation set: 0.21245860165914612

Training loss 48888.94140625

Recall on (sampled) validation set: 0.21032764927819372

Training loss 48889.12109375

Recall on (sampled) validation set: 0.21320598932894758

Training loss 48889.10546875

Recall on (sampled) validation set: 0.2144598207465721

Training loss 48888.7890625

Recall on (sampled) validation set: 0.2163250369479952

Training loss 48888.859375

Recall on (sampled) validation set: 0.21204220866516693

Training loss 48888.76953125

Recall on (sampled) validation set: 0.21317438013354528

Training loss 48888.75390625

Recall on (sampled) validation set: 0.21563573008627457

Training loss 48888.80859375

Recall on (sampled) validation set: 0.21346653816708264

Training loss 48888.90625

Recall on (sampled) validation set: 0.21218492897168031

Training loss 48888.64453125

Recall on (sampled) validation set: 0.215607591558136

Training loss 48888.90625

Recall on (sampled) validation set: 0.2143448782178365

Training loss 48889.046875

Recall on (sampled) validation set: 0.21027671931483183

Training loss 48889.078125

Recall on (sampled) validation set: 0.2133768710787767

Training loss 48888.83984375

Recall on (sampled) validation set: 0.21158993770563642

Training loss 48888.69140625

Recall on (sampled) validation set: 0.21254109957059142

Training loss 48888.734375

Recall on (sampled) validation set: 0.20855710942280814

Training loss 48889.19140625

Recall on (sampled) validation set: 0.2113348872005859

Training loss 48889.234375

Recall on (sampled) validation set: 0.20901537630212766

Training loss 48889.08984375

Recall on (sampled) validation set: 0.21518120754690628

Training loss 48888.921875

Recall on (sampled) validation set: 0.21523254801929936

Training loss 48888.88671875

Recall on (sampled) validation set: 0.21399539819594268

Training loss 48888.85546875

Recall on (sampled) validation set: 0.2131353693359138

Training loss 48888.94140625

Recall on (sampled) validation set: 0.21369495796265306

Training loss 48888.51171875

Recall on (sampled) validation set: 0.2197464804470249

Training loss 48888.625

Recall on (sampled) validation set: 0.21470056148731287

Training loss 48888.89453125

Recall on (sampled) validation set: 0.2154282115511698

Training loss 48889.01171875

Recall on (sampled) validation set: 0.21730109058784194

Training loss 48889.01171875

Recall on (sampled) validation set: 0.21752626363016564

Training loss 48888.8984375

Recall on (sampled) validation set: 0.21101070946261508

Training loss 48889.171875

Recall on (sampled) validation set: 0.21153595413123544

Training loss 48888.87109375

Recall on (sampled) validation set: 0.21479820458495597

Training loss 48888.7734375

Recall on (sampled) validation set: 0.20838083933274498

Training loss 48888.65625

Recall on (sampled) validation set: 0.2132096498648223

Training loss 48888.7265625

Recall on (sampled) validation set: 0.20966231169180352

Training loss 48888.64453125

Recall on (sampled) validation set: 0.21382476327530772

Training loss 48888.68359375

Recall on (sampled) validation set: 0.21751885482602362

Training loss 48888.890625

Recall on (sampled) validation set: 0.20924142994197442

Training loss 48888.94921875

Recall on (sampled) validation set: 0.2104271024565943

Training loss 48888.94140625

Recall on (sampled) validation set: 0.20829698549752998

Training loss 48889.05859375

Recall on (sampled) validation set: 0.20829109957059141

Training loss 48888.828125

Recall on (sampled) validation set: 0.21104193499247945

Training loss 48888.69140625

Recall on (sampled) validation set: 0.2124625430696211

Training loss 48889.01953125

Recall on (sampled) validation set: 0.2119599307394226

Training loss 48889.30078125

Recall on (sampled) validation set: 0.2135948782178365

Training loss 48888.69921875

Recall on (sampled) validation set: 0.21479073882023064

Training loss 48889.12109375

Recall on (sampled) validation set: 0.219130455667207

Training loss 48888.43359375

Recall on (sampled) validation set: 0.2160738558342914

Training loss 48888.48828125

Recall on (sampled) validation set: 0.21292832154402028

Training loss 48889.140625

Recall on (sampled) validation set: 0.21282093185768322

Training loss 48888.9453125

Recall on (sampled) validation set: 0.22091168752602508

Training loss 48889.30859375

Recall on (sampled) validation set: 0.22055000833675972

Training loss 48888.71484375

Recall on (sampled) validation set: 0.2158667622120435

Training loss 48889.0

Recall on (sampled) validation set: 0.21336862292443054

Training loss 48888.80859375

Recall on (sampled) validation set: 0.21927213169636037

Training loss 48889.12890625

Recall on (sampled) validation set: 0.21776708119130983

Training loss 48888.8359375

Recall on (sampled) validation set: 0.21401043578992765

Training loss 48888.84375

Recall on (sampled) validation set: 0.21697760750709932

Training loss 48888.9296875

Recall on (sampled) validation set: 0.21393587438641884

Training loss 48888.91015625

Recall on (sampled) validation set: 0.21464932467881653

Training loss 48889.03515625

Recall on (sampled) validation set: 0.21890304610359057

Training loss 48889.0859375

Recall on (sampled) validation set: 0.2189425197878011

Training loss 48889.12890625

Recall on (sampled) validation set: 0.22178316306265491

Training loss 48889.109375

Recall on (sampled) validation set: 0.21989877013152873

Training loss 48888.82421875

Recall on (sampled) validation set: 0.21847760750709933

Training loss 48888.9609375

Recall on (sampled) validation set: 0.21031599134548318

Training loss 48888.40625

Recall on (sampled) validation set: 0.2125354912446564

Training loss 48888.9296875

Recall on (sampled) validation set: 0.21989549326119198

Training loss 48888.65625

Recall on (sampled) validation set: 0.21116314711369158

Training loss 48889.12890625

Recall on (sampled) validation set: 0.21937032781361276

Training loss 48888.88671875

Recall on (sampled) validation set: 0.21798164057828306

Training loss 48888.734375

Recall on (sampled) validation set: 0.2218399377056364

Training loss 48888.75390625

Recall on (sampled) validation set: 0.21517907621718876

Training loss 48888.9453125

Recall on (sampled) validation set: 0.21377933164503038

Training loss 48889.1640625

Recall on (sampled) validation set: 0.21142716727380975

Training loss 48889.421875

Recall on (sampled) validation set: 0.21714141501437326

Training loss 48888.875

Recall on (sampled) validation set: 0.2170059470340777

Training loss 48889.109375

Recall on (sampled) validation set: 0.21253055073245636

Training loss 48888.80859375

Recall on (sampled) validation set: 0.2135393226622809

Training loss 48889.0390625

Recall on (sampled) validation set: 0.2157522184073908

Training loss 48889.0390625

Recall on (sampled) validation set: 0.21356599134548318

Training loss 48888.640625

Recall on (sampled) validation set: 0.21401523946578388

Training loss 48888.625

Recall on (sampled) validation set: 0.21763661133851697

Training loss 48888.61328125

Recall on (sampled) validation set: 0.21439932467881648

Training loss 48888.9453125

Recall on (sampled) validation set: 0.21858488720058594

Training loss 48888.953125

Recall on (sampled) validation set: 0.2161408454085405

Training loss 48889.2265625

Recall on (sampled) validation set: 0.21220898532468405

Training loss 48888.65625

Recall on (sampled) validation set: 0.21569168436591302

Training loss 48888.86328125

Recall on (sampled) validation set: 0.213144274173766

Training loss 48888.875

Recall on (sampled) validation set: 0.21614166184356748

Training loss 48888.9609375

Recall on (sampled) validation set: 0.21516943962134524

Training loss 48888.73046875

Recall on (sampled) validation set: 0.21478316306265488

Training loss 48888.62109375

Recall on (sampled) validation set: 0.2144825480192994

Training loss 48888.85546875

Recall on (sampled) validation set: 0.2212604626334209

Training loss 48889.43359375

Recall on (sampled) validation set: 0.21747760750709935

Training loss 48888.7734375

Recall on (sampled) validation set: 0.2151694396213453

Training loss 48889.1484375

Recall on (sampled) validation set: 0.2158110776767764

Training loss 48888.94921875

Recall on (sampled) validation set: 0.22156094084043265

Training loss 48889.140625

Recall on (sampled) validation set: 0.2229866262661181

Training loss 48889.12109375

Recall on (sampled) validation set: 0.21725660437230307

Training loss 48889.140625

Recall on (sampled) validation set: 0.21611649639598823

Training loss 48889.13671875

Recall on (sampled) validation set: 0.2137604357899276

Training loss 48888.94140625

Recall on (sampled) validation set: 0.2212871961338386

Training loss 48888.98046875

Recall on (sampled) validation set: 0.21332757725906548

Training loss 48889.33984375

Recall on (sampled) validation set: 0.21890304610359057

Training loss 48889.046875

Recall on (sampled) validation set: 0.21785759155813603

Training loss 48888.9453125

Recall on (sampled) validation set: 0.22020860165914613

Training loss 48888.73046875

Recall on (sampled) validation set: 0.22170995758291587

Training loss 48889.2109375

Recall on (sampled) validation set: 0.21584268687217872

Training loss 48889.1953125

Recall on (sampled) validation set: 0.21839296800866673

Training loss 48889.3203125

Recall on (sampled) validation set: 0.21783885545455414

Training loss 48889.3515625

Recall on (sampled) validation set: 0.21687305471969717

Training loss 48889.16015625

Recall on (sampled) validation set: 0.22243496694540255

Training loss 48888.5703125

Recall on (sampled) validation set: 0.22232945935895118

Training loss 48888.91015625

Recall on (sampled) validation set: 0.223176020205512

Training loss 48888.7734375

Recall on (sampled) validation set: 0.21882728852783298

Training loss 48888.9765625

Recall on (sampled) validation set: 0.22225024770215332

Training loss 48888.82421875

Recall on (sampled) validation set: 0.217206323235815

Training loss 48889.2109375

Recall on (sampled) validation set: 0.2183855022439414

Training loss 48888.93359375

Recall on (sampled) validation set: 0.21672896343086903

Training loss 48888.78515625

Recall on (sampled) validation set: 0.21818864646813832

Training loss 48889.0234375

Recall on (sampled) validation set: 0.22119001745045305

Training loss 48888.83984375

Recall on (sampled) validation set: 0.22448037958881878

Training loss 48888.98046875

Recall on (sampled) validation set: 0.22331382291500257

Training loss 48889.265625

Recall on (sampled) validation set: 0.22240012605529846

Training loss 48889.00390625

Recall on (sampled) validation set: 0.2230130978787966

Training loss 48888.8046875

Recall on (sampled) validation set: 0.22068359596308776

Training loss 48889.16015625

Recall on (sampled) validation set: 0.22365444785771463

Training loss 48888.81640625

Recall on (sampled) validation set: 0.22461915848485722

Training loss 48888.73828125

Recall on (sampled) validation set: 0.22484762738437875

Training loss 48888.69921875

Recall on (sampled) validation set: 0.22059884647180478

Training loss 48888.89453125

Recall on (sampled) validation set: 0.2213136029293017

Training loss 48889.05078125

Recall on (sampled) validation set: 0.22250901963197792

Training loss 48888.6953125

Recall on (sampled) validation set: 0.22473890468944915

Training loss 48888.71875

Recall on (sampled) validation set: 0.22073507327182465

Training loss 48888.859375

Recall on (sampled) validation set: 0.22042991644035198

Training loss 48888.6953125

Recall on (sampled) validation set: 0.2173387186182105

Training loss 48889.30078125

Recall on (sampled) validation set: 0.21726591186255434

Training loss 48888.8515625

Recall on (sampled) validation set: 0.22051584704533886

Training loss 48889.078125

Recall on (sampled) validation set: 0.21396939732647535

Training loss 48888.9140625

Recall on (sampled) validation set: 0.2222556321140713

Training loss 48889.109375

Recall on (sampled) validation set: 0.22309324141946646

Training loss 48888.94140625

Recall on (sampled) validation set: 0.2178891365910422

Training loss 48888.96484375

Recall on (sampled) validation set: 0.21929506782455965

Training loss 48889.12109375

Recall on (sampled) validation set: 0.21481699044720823

Training loss 48888.84375

Recall on (sampled) validation set: 0.22209268687217873

Training loss 48888.71875

Recall on (sampled) validation set: 0.21564427417376603

Training loss 48888.80859375

Recall on (sampled) validation set: 0.22206971277025725

Training loss 48888.8203125

Recall on (sampled) validation set: 0.218048428498973

Training loss 48888.9453125

Recall on (sampled) validation set: 0.21850352457249006

Training loss 48888.8203125

Recall on (sampled) validation set: 0.2186580966086411

Training loss 48888.93359375

Recall on (sampled) validation set: 0.2177023549818468

Training loss 48889.0390625

Recall on (sampled) validation set: 0.22006074376990892

Training loss 48888.84375

Recall on (sampled) validation set: 0.21859124387073572

Training loss 48889.0546875

Recall on (sampled) validation set: 0.22063313281462105

Training loss 48889.4296875

Recall on (sampled) validation set: 0.22178104046252864

Training loss 48888.875

Recall on (sampled) validation set: 0.22291122944072128

Training loss 48888.671875

Recall on (sampled) validation set: 0.21775674120864683

Training loss 48888.55859375

Recall on (sampled) validation set: 0.2207692077197522

Training loss 48888.6796875

Recall on (sampled) validation set: 0.21920840458862234

Training loss 48888.9453125

Recall on (sampled) validation set: 0.21858165550588418

Training loss 48888.78515625

Recall on (sampled) validation set: 0.22081215992785866

Training loss 48888.76171875

Recall on (sampled) validation set: 0.22172039249988434

Training loss 48888.73828125

Recall on (sampled) validation set: 0.21916206486260933

Training loss 48888.82421875

Recall on (sampled) validation set: 0.2190056321140713

Training loss 48889.12890625

Recall on (sampled) validation set: 0.2149879370142528

Training loss 48888.6953125

Recall on (sampled) validation set: 0.21875674120864688

Training loss 48888.80078125

Recall on (sampled) validation set: 0.22126043578992763

Training loss 48888.7109375

Recall on (sampled) validation set: 0.21695404481248404

Training loss 48888.94921875

Recall on (sampled) validation set: 0.21838818331967152

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21737817724387598

Training loss 48888.8515625

Recall on (sampled) validation set: 0.21953690740260612

Training loss 48888.83984375

Recall on (sampled) validation set: 0.21908993770563645

Training loss 48888.78515625

Recall on (sampled) validation set: 0.2137380692675611

Training loss 48888.87890625

Recall on (sampled) validation set: 0.21936435480900093

Training loss 48889.359375

Recall on (sampled) validation set: 0.21503737814581736

Training loss 48888.94921875

Recall on (sampled) validation set: 0.21194290345333902

Training loss 48888.53515625

Recall on (sampled) validation set: 0.21004723232672415

Training loss 48889.31640625

Recall on (sampled) validation set: 0.21276325130136384

Training loss 48889.16015625

Recall on (sampled) validation set: 0.21523676310246184

Training loss 48888.73046875

Recall on (sampled) validation set: 0.21473410101359283

Training loss 48888.953125

Recall on (sampled) validation set: 0.2127580473737461

Training loss 48888.81640625

Recall on (sampled) validation set: 0.21445754232324105

Training loss 48889.328125

Recall on (sampled) validation set: 0.2170357380738506

Training loss 48888.58984375

Recall on (sampled) validation set: 0.21618747081042908

Training loss 48888.6484375

Recall on (sampled) validation set: 0.21591749270424407

Training loss 48888.359375

Recall on (sampled) validation set: 0.21948725283253415

Training loss 48889.18359375

Recall on (sampled) validation set: 0.21498481618536067

Training loss 48888.46484375

Recall on (sampled) validation set: 0.21292354471165723

Training loss 48889.19140625

Recall on (sampled) validation set: 0.21751440404389588

Training loss 48888.8359375

Recall on (sampled) validation set: 0.21802018477925916

Training loss 48888.578125

Recall on (sampled) validation set: 0.2167499906156893

Training loss 48889.08984375

Recall on (sampled) validation set: 0.2148333239490227

Training loss 48889.0859375

Recall on (sampled) validation set: 0.21894910189964634

Training loss 48888.94921875

Recall on (sampled) validation set: 0.21902763155712335

Training loss 48889.421875

Recall on (sampled) validation set: 0.21946044491235053

Training loss 48888.91015625

Recall on (sampled) validation set: 0.21668120754690628

Training loss 48888.703125

Recall on (sampled) validation set: 0.2136069966364885

Training loss 48888.93359375

Recall on (sampled) validation set: 0.21367737612928175

Training loss 48888.6953125

Recall on (sampled) validation set: 0.21743503896453079

Training loss 48889.05859375

Recall on (sampled) validation set: 0.2168147382126511

Training loss 48888.69140625

Recall on (sampled) validation set: 0.21188957809012257

Training loss 48888.8046875

Recall on (sampled) validation set: 0.2184398426403871

Training loss 48888.5

Recall on (sampled) validation set: 0.2159173558679003

Training loss 48888.76953125

Recall on (sampled) validation set: 0.2214403299698218

Training loss 48889.24609375

Recall on (sampled) validation set: 0.21894805762228628

Training loss 48888.94921875

Recall on (sampled) validation set: 0.22140148285202732

Training loss 48888.69921875

Recall on (sampled) validation set: 0.22394621589676034

Training loss 48888.8515625

Recall on (sampled) validation set: 0.21766338761393209

Training loss 48888.75390625

Recall on (sampled) validation set: 0.21673459227134365

Training loss 48888.96875

Recall on (sampled) validation set: 0.2213141812647257

Training loss 48888.6015625

Recall on (sampled) validation set: 0.21793034288088733

Training loss 48888.7109375

Recall on (sampled) validation set: 0.2199681077475996

Training loss 48889.0859375

Recall on (sampled) validation set: 0.21653111248165696

Training loss 48888.51171875

Recall on (sampled) validation set: 0.22134209587884726

Training loss 48888.96484375

Recall on (sampled) validation set: 0.21621981656509784

Training loss 48888.51171875

Recall on (sampled) validation set: 0.21977140386668517

Training loss 48889.05078125

Recall on (sampled) validation set: 0.21817281688198203

Training loss 48888.9453125

Recall on (sampled) validation set: 0.21686854064803252

Training loss 48888.84375

Recall on (sampled) validation set: 0.21698151247153064

Training loss 48888.69140625

Recall on (sampled) validation set: 0.21815858393807577

Training loss 48888.7890625

Recall on (sampled) validation set: 0.21836267370795506

Training loss 48888.89453125

Recall on (sampled) validation set: 0.22029555908231047

Training loss 48888.734375

Recall on (sampled) validation set: 0.22170703840758288

Training loss 48888.609375

Recall on (sampled) validation set: 0.21663863267538402

Training loss 48888.953125

Recall on (sampled) validation set: 0.21418614805910632

Training loss 48889.06640625

Recall on (sampled) validation set: 0.21998808585378454

Training loss 48888.828125

Recall on (sampled) validation set: 0.22041510428806257

Training loss 48888.38671875

Recall on (sampled) validation set: 0.21808812762487897

Training loss 48888.23046875

Recall on (sampled) validation set: 0.2195919590425035

Training loss 48888.61328125

Recall on (sampled) validation set: 0.2216165051255795

Training loss 48889.14453125

Recall on (sampled) validation set: 0.21712349621877755

Training loss 48888.86328125

Recall on (sampled) validation set: 0.22191776637693153

Training loss 48889.015625

Recall on (sampled) validation set: 0.21697604425553607

Training loss 48888.7109375

Recall on (sampled) validation set: 0.21786102970767218

Training loss 48889.0234375

Recall on (sampled) validation set: 0.21419527048202183

Training loss 48888.86328125

Recall on (sampled) validation set: 0.21845703840758285

Training loss 48889.125

Recall on (sampled) validation set: 0.21835057973215868

Training loss 48888.71484375

Recall on (sampled) validation set: 0.2150126587803539

Training loss 48888.91015625

Recall on (sampled) validation set: 0.21728640348694797

Training loss 48888.48828125

Recall on (sampled) validation set: 0.2159160331165776

Training loss 48888.62890625

Recall on (sampled) validation set: 0.21608690853745297

Training loss 48888.8046875

Recall on (sampled) validation set: 0.2158962084329598

Training loss 48888.93359375

Recall on (sampled) validation set: 0.22063985176281004

Training loss 48888.859375

Recall on (sampled) validation set: 0.2126992387359901

Training loss 48888.640625

Recall on (sampled) validation set: 0.21324713145629662

Training loss 48888.58984375

Recall on (sampled) validation set: 0.21751203941585065

Training loss 48888.6796875

Recall on (sampled) validation set: 0.22249446936742762

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21568302002830134

Training loss 48888.859375

Recall on (sampled) validation set: 0.21500718270772717

Training loss 48888.92578125

Recall on (sampled) validation set: 0.2122508260375774

Training loss 48888.87890625

Recall on (sampled) validation set: 0.21143302002830133

Training loss 48888.640625

Recall on (sampled) validation set: 0.2153884958390403

Training loss 48888.3984375

Recall on (sampled) validation set: 0.21540861078156903

Training loss 48888.7265625

Recall on (sampled) validation set: 0.21287081907136354

Training loss 48888.828125

Recall on (sampled) validation set: 0.2128985968491413

Training loss 48888.8984375

Recall on (sampled) validation set: 0.2099620168935051

Training loss 48889.328125

Recall on (sampled) validation set: 0.21149316320232836

Training loss 48888.96484375

Recall on (sampled) validation set: 0.21570293331727092

Training loss 48888.58984375

Recall on (sampled) validation set: 0.21416206486260933

Training loss 48888.46875

Recall on (sampled) validation set: 0.2115815470407122

Training loss 48888.8359375

Recall on (sampled) validation set: 0.20857730511405648

Training loss 48888.8046875

Recall on (sampled) validation set: 0.21352490923407438

Training loss 48888.7265625

Recall on (sampled) validation set: 0.21375465745520192

Training loss 48888.50390625

Recall on (sampled) validation set: 0.2125324352329797

Training loss 48888.609375

Recall on (sampled) validation set: 0.21364859684914128

Training loss 48888.71875

Recall on (sampled) validation set: 0.21343395038449486

Training loss 48888.36328125

Recall on (sampled) validation set: 0.2145170179017729

Training loss 48889.01953125

Recall on (sampled) validation set: 0.21103591375687564

Training loss 48888.87890625

Recall on (sampled) validation set: 0.21181143209818346

Training loss 48888.7265625

Recall on (sampled) validation set: 0.21732291194723136

Training loss 48888.96484375

Recall on (sampled) validation set: 0.21656156893452716

Training loss 48888.59375

Recall on (sampled) validation set: 0.21604042149958663

Training loss 48888.86328125

Recall on (sampled) validation set: 0.2114470513186484

Training loss 48888.19921875

Recall on (sampled) validation set: 0.21728365432040572

Training loss 48888.73828125

Recall on (sampled) validation set: 0.20832428227482672

Training loss 48888.3984375

Recall on (sampled) validation set: 0.22038272383326832

Training loss 48888.69140625

Recall on (sampled) validation set: 0.2203985968491413

Training loss 48888.96875

Recall on (sampled) validation set: 0.21955614109289248

Training loss 48888.85546875

Recall on (sampled) validation set: 0.21331929658699167

Training loss 48888.484375

Recall on (sampled) validation set: 0.21792198866200682

Training loss 48888.8203125

Recall on (sampled) validation set: 0.21196605716660163

Training loss 48888.51953125

Recall on (sampled) validation set: 0.21056287509962646

Training loss 48889.09375

Recall on (sampled) validation set: 0.20903953631902814

Training loss 48888.6796875

Recall on (sampled) validation set: 0.21328379115674942

Training loss 48889.10546875

Recall on (sampled) validation set: 0.2071488705218288

Training loss 48888.96875

Recall on (sampled) validation set: 0.21309448429502878

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21072557351232485

Training loss 48888.69140625

Recall on (sampled) validation set: 0.2049420387873201

Training loss 48888.765625

Recall on (sampled) validation set: 0.21519203878732004

Training loss 48888.36328125

Recall on (sampled) validation set: 0.21823961986121693

Training loss 48888.69140625

Recall on (sampled) validation set: 0.21688355925515632

Training loss 48888.578125

Recall on (sampled) validation set: 0.21457295319455028

Training loss 48888.671875

Recall on (sampled) validation set: 0.21231418126472573

Training loss 48888.86328125

Recall on (sampled) validation set: 0.20595362470090237

Training loss 48889.0390625

Recall on (sampled) validation set: 0.2096765114632628

Training loss 48888.73828125

Recall on (sampled) validation set: 0.21477174955850092

Training loss 48888.59375

Recall on (sampled) validation set: 0.21567146095821235

Training loss 48888.69140625

Recall on (sampled) validation set: 0.2195909907125878

Training loss 48888.8046875

Recall on (sampled) validation set: 0.2126800960516931

Training loss 48888.74609375

Recall on (sampled) validation set: 0.21811260168882673

Training loss 48888.75390625

Recall on (sampled) validation set: 0.21391050161104605

Training loss 48889.13671875

Recall on (sampled) validation set: 0.2171714609582123

Training loss 48888.421875

Recall on (sampled) validation set: 0.21593827938882384

Training loss 48888.40625

Recall on (sampled) validation set: 0.2131287824227933

Training loss 48889.07421875

Recall on (sampled) validation set: 0.22017529237583683

Training loss 48888.75

Recall on (sampled) validation set: 0.21972318509614336

Training loss 48888.65625

Recall on (sampled) validation set: 0.21610673474874925

Training loss 48888.671875

Recall on (sampled) validation set: 0.21401656221710672

Training loss 48889.1640625

Recall on (sampled) validation set: 0.21759195904250353

Training loss 48888.16015625

Recall on (sampled) validation set: 0.21517640147041234

Training loss 48888.78515625

Recall on (sampled) validation set: 0.22118754282955735

Training loss 48888.23828125

Recall on (sampled) validation set: 0.21731287509962646

Training loss 48888.68359375

Recall on (sampled) validation set: 0.21490256510310957

Training loss 48888.88671875

Recall on (sampled) validation set: 0.2165859402075373

Training loss 48888.43359375

Recall on (sampled) validation set: 0.2186007309723281

Training loss 48888.62109375

Recall on (sampled) validation set: 0.22422894924528317

Training loss 48888.58984375

Recall on (sampled) validation set: 0.219800225921823

Training loss 48888.5546875

Recall on (sampled) validation set: 0.21746044884066662

Training loss 48889.23828125

Recall on (sampled) validation set: 0.22496436733596445

Training loss 48888.74609375

Recall on (sampled) validation set: 0.22175731954407088

Training loss 48888.83984375

Recall on (sampled) validation set: 0.22269410115326632

Training loss 48888.84375

Recall on (sampled) validation set: 0.21881540035215172

Training loss 48888.55078125

Recall on (sampled) validation set: 0.21422832267886713

Training loss 48888.68359375

Recall on (sampled) validation set: 0.2120953995926773

Training loss 48888.546875

Recall on (sampled) validation set: 0.21758801763202854

Training loss 48888.43359375

Recall on (sampled) validation set: 0.21593311889092287

Training loss 48888.81640625

Recall on (sampled) validation set: 0.2185013157676497

Training loss 48889.0390625

Recall on (sampled) validation set: 0.22131414329100352

Training loss 48888.87890625

Recall on (sampled) validation set: 0.21558753510386902

Training loss 48888.80078125

Recall on (sampled) validation set: 0.2142041792481901

Training loss 48888.88671875

Recall on (sampled) validation set: 0.2194381693959734

Training loss 48888.6953125

Recall on (sampled) validation set: 0.2184542892410406

Training loss 48888.46875

Recall on (sampled) validation set: 0.2152623471339442

Training loss 48888.93359375

Recall on (sampled) validation set: 0.2181369277862018

Training loss 48888.859375

Recall on (sampled) validation set: 0.2137117550057659

Training loss 48888.15625

Recall on (sampled) validation set: 0.21806919379605405

Training loss 48888.453125

Recall on (sampled) validation set: 0.2167636382404985

Training loss 48888.48046875

Recall on (sampled) validation set: 0.21882211777266225

Training loss 48888.12890625

Recall on (sampled) validation set: 0.21901363824049846

Training loss 48888.6796875

Recall on (sampled) validation set: 0.22043030490716517

Training loss 48888.796875

Recall on (sampled) validation set: 0.22096100666155113

Training loss 48888.68359375

Recall on (sampled) validation set: 0.2224157838867458

Training loss 48888.25

Recall on (sampled) validation set: 0.2215890730396175

Training loss 48888.578125

Recall on (sampled) validation set: 0.2231485588754191

Training loss 48888.37109375

Recall on (sampled) validation set: 0.21661694968001682

Training loss 48888.21484375

Recall on (sampled) validation set: 0.21476616349302374

Training loss 48889.09375

Recall on (sampled) validation set: 0.2148945906214509

Training loss 48888.43359375

Recall on (sampled) validation set: 0.2159412642543314

Training loss 48888.390625

Recall on (sampled) validation set: 0.21555753586334347

Training loss 48888.51953125

Recall on (sampled) validation set: 0.2145265532343572

Training loss 48888.3359375

Recall on (sampled) validation set: 0.21375461948147972

Training loss 48888.39453125

Recall on (sampled) validation set: 0.21148044920730943

Training loss 48888.8203125

Recall on (sampled) validation set: 0.2136247493516096

Training loss 48888.60546875

Recall on (sampled) validation set: 0.2139504198496939

Training loss 48888.6640625

Recall on (sampled) validation set: 0.2172299025166539

Training loss 48888.7890625

Recall on (sampled) validation set: 0.21364055034835436

Training loss 48888.98046875

Recall on (sampled) validation set: 0.21587589489222883

Training loss 48888.1015625

Recall on (sampled) validation set: 0.2142189431694876

Training loss 48888.734375

Recall on (sampled) validation set: 0.20818876191698332

Training loss 48888.9765625

Recall on (sampled) validation set: 0.2206088043166083

Training loss 48888.36328125

Recall on (sampled) validation set: 0.21632081160756295

Training loss 48888.48046875

Recall on (sampled) validation set: 0.21885361697521408

Training loss 48888.44140625

Recall on (sampled) validation set: 0.2158495118849021

Training loss 48888.921875

Recall on (sampled) validation set: 0.21517135096536186

Training loss 48888.78125

Recall on (sampled) validation set: 0.2149517410733382

Training loss 48888.75390625

Recall on (sampled) validation set: 0.21699118071214257

Training loss 48888.81640625

Recall on (sampled) validation set: 0.2236099094828678

Training loss 48888.5703125

Recall on (sampled) validation set: 0.21886464834150862

Training loss 48888.56640625

Recall on (sampled) validation set: 0.22162251283031684

Training loss 48888.34375

Recall on (sampled) validation set: 0.21104928050708452

Training loss 48888.203125

Recall on (sampled) validation set: 0.20589643234697683

Training loss 48888.203125

Recall on (sampled) validation set: 0.21321472808632522

Training loss 48888.82421875

Recall on (sampled) validation set: 0.21983405570701392

Training loss 48888.73046875

Recall on (sampled) validation set: 0.21720303217989245

Training loss 48888.78515625

Recall on (sampled) validation set: 0.22185073097232808

Training loss 48888.46484375

Recall on (sampled) validation set: 0.22054854394781798

Training loss 48888.50390625

Recall on (sampled) validation set: 0.21284595413996504

Training loss 48888.62890625

Recall on (sampled) validation set: 0.2169837339342784

Training loss 48888.609375

Recall on (sampled) validation set: 0.21063187728115135

Training loss 48888.49609375

Recall on (sampled) validation set: 0.2159122673891276

Training loss 48888.51953125

Recall on (sampled) validation set: 0.2202850744066715

Training loss 48888.43359375

Recall on (sampled) validation set: 0.2205006512275115

Training loss 48888.578125

Recall on (sampled) validation set: 0.2150564804557545

Training loss 48888.55078125

Recall on (sampled) validation set: 0.2108421227223405

Training loss 48888.43359375

Recall on (sampled) validation set: 0.20579544908945996

Training loss 48888.42578125

Recall on (sampled) validation set: 0.21621089666870064

Training loss 48888.3515625

Recall on (sampled) validation set: 0.21192539123845838

Training loss 48888.3359375

Recall on (sampled) validation set: 0.21045194992881017

Training loss 48888.46484375

Recall on (sampled) validation set: 0.21012599135421278

Training loss 48888.76953125

Recall on (sampled) validation set: 0.21231797470862807

Training loss 48888.46484375

Recall on (sampled) validation set: 0.21740903569442588

Training loss 48888.34375

Recall on (sampled) validation set: 0.21343200499507214

Training loss 48888.87890625

Recall on (sampled) validation set: 0.2159362785664964

Training loss 48888.671875

Recall on (sampled) validation set: 0.21723456935616647

Training loss 48888.4765625

Recall on (sampled) validation set: 0.2140503208561285

Training loss 48888.4609375

Recall on (sampled) validation set: 0.21711861659547685

Training loss 48888.296875

Recall on (sampled) validation set: 0.21723327104769935

Training loss 48888.296875

Recall on (sampled) validation set: 0.21752365217292624

Training loss 48888.5390625

Recall on (sampled) validation set: 0.21440593210647657

Training loss 48888.56640625

Recall on (sampled) validation set: 0.211848213576435

Training loss 48888.38671875

Recall on (sampled) validation set: 0.21257138121339575

Training loss 48888.859375

Recall on (sampled) validation set: 0.21560409950337353

Training loss 48888.62109375

Recall on (sampled) validation set: 0.21296239270241085

Training loss 48888.71484375

Recall on (sampled) validation set: 0.2118836541894618

Training loss 48888.484375

Recall on (sampled) validation set: 0.2198884578653181

Training loss 48888.34375

Recall on (sampled) validation set: 0.2134914236130207

Training loss 48888.39453125

Recall on (sampled) validation set: 0.2152692013907985

Training loss 48888.48046875

Recall on (sampled) validation set: 0.21720104248779384

Training loss 48888.46875

Recall on (sampled) validation set: 0.22018214663269112

Training loss 48888.46875

Recall on (sampled) validation set: 0.21353834407509542

Training loss 48888.125

Recall on (sampled) validation set: 0.21299469328144463

Training loss 48888.39453125

Recall on (sampled) validation set: 0.21738768726064553

Training loss 48888.51953125

Recall on (sampled) validation set: 0.20869324281620108

Training loss 48888.48828125

Recall on (sampled) validation set: 0.21449852469906916

Training loss 48888.7265625

Recall on (sampled) validation set: 0.21820212473887612

Training loss 48888.80078125

Recall on (sampled) validation set: 0.21442051554347383

Training loss 48888.62890625

Recall on (sampled) validation set: 0.21369721107016934

Training loss 48888.75

Recall on (sampled) validation set: 0.21700673487969316

Training loss 48888.7890625

Recall on (sampled) validation set: 0.21369693739748186

Training loss 48888.953125

Recall on (sampled) validation set: 0.21642013187793585

Training loss 48888.51953125

Recall on (sampled) validation set: 0.21439535009589458

Training loss 48888.50390625

Recall on (sampled) validation set: 0.21401102438262148

Training loss 48888.48828125

Recall on (sampled) validation set: 0.21388358217033357

Training loss 48888.6640625

Recall on (sampled) validation set: 0.21494178322853458

Training loss 48888.85546875

Recall on (sampled) validation set: 0.21278559490855317

Training loss 48888.171875

Recall on (sampled) validation set: 0.21432016212596977

Training loss 48888.32421875

Recall on (sampled) validation set: 0.21689883102042815

Training loss 48888.703125

Recall on (sampled) validation set: 0.21267264054423762

Training loss 48888.4609375

Recall on (sampled) validation set: 0.21303548491570268

Training loss 48888.6953125

Recall on (sampled) validation set: 0.21498745535905242

Training loss 48888.5390625

Recall on (sampled) validation set: 0.21205202967362677

Training loss 48888.57421875

Recall on (sampled) validation set: 0.2112882072387517

Training loss 48888.61328125

Recall on (sampled) validation set: 0.21198313421135562

Training loss 48888.63671875

Recall on (sampled) validation set: 0.21068398355694182

Training loss 48888.21484375

Recall on (sampled) validation set: 0.20783888229804745

Training loss 48888.4453125

Recall on (sampled) validation set: 0.2108506502236085

Training loss 48888.359375

Recall on (sampled) validation set: 0.20906514479336621

Training loss 48888.65625

Recall on (sampled) validation set: 0.21474323369377818

Training loss 48888.671875

Recall on (sampled) validation set: 0.2156837819033826

Training loss 48888.18359375

Recall on (sampled) validation set: 0.2130760860266305

Training loss 48888.4765625

Recall on (sampled) validation set: 0.21266010921591683

Training loss 48888.17578125

Recall on (sampled) validation set: 0.21259108564689327

Training loss 48888.49609375

Recall on (sampled) validation set: 0.21430700423123294

Training loss 48888.23046875

Recall on (sampled) validation set: 0.20953367243430765

Training loss 48888.0859375

Recall on (sampled) validation set: 0.21193983631143343

Training loss 48888.609375

Recall on (sampled) validation set: 0.21711600426527827

Training loss 48888.453125

Recall on (sampled) validation set: 0.21322192803499518

Training loss 48888.4453125

Recall on (sampled) validation set: 0.21289364520671236

Training loss 48888.3203125

Recall on (sampled) validation set: 0.21449176930483646

Training loss 48888.28515625

Recall on (sampled) validation set: 0.2138673318178763

Training loss 48888.703125

Recall on (sampled) validation set: 0.21245860165914612

Training loss 48888.33984375

Recall on (sampled) validation set: 0.20789450987273128

Training loss 48888.421875

Recall on (sampled) validation set: 0.2114606522401441

Training loss 48888.5859375

Recall on (sampled) validation set: 0.21699733878409017

Training loss 48888.73046875

Recall on (sampled) validation set: 0.2211878869936946

Training loss 48888.44921875

Recall on (sampled) validation set: 0.2132550016193392

Training loss 48888.3984375

Recall on (sampled) validation set: 0.22012418607473053

Training loss 48888.39453125

Recall on (sampled) validation set: 0.22158847178901625

Training loss 48888.32421875

Recall on (sampled) validation set: 0.2180185028052542

Training loss 48888.48828125

Recall on (sampled) validation set: 0.2160767758825835

Training loss 48888.55078125

Recall on (sampled) validation set: 0.21547179119865148

Training loss 48888.3046875

Recall on (sampled) validation set: 0.2168477310482755

Training loss 48888.1484375

Recall on (sampled) validation set: 0.21472811687875207

Training loss 48888.56640625

Recall on (sampled) validation set: 0.21474476530057293

Training loss 48888.85546875

Recall on (sampled) validation set: 0.21267351153921027

Training loss 48888.3984375

Recall on (sampled) validation set: 0.21410695866276627

Training loss 48888.375

Recall on (sampled) validation set: 0.21980672575727023

Training loss 48888.140625

Recall on (sampled) validation set: 0.2168409756540428

Training loss 48888.515625

Recall on (sampled) validation set: 0.22088870469451233

Training loss 48888.328125

Recall on (sampled) validation set: 0.21227020442083963

Training loss 48888.15625

Recall on (sampled) validation set: 0.21347095577676337

Training loss 48888.296875

Recall on (sampled) validation set: 0.21108964264545027

Training loss 48888.3203125

Recall on (sampled) validation set: 0.21510612324087824

Training loss 48888.49609375

Recall on (sampled) validation set: 0.21378423898478346

Training loss 48888.62890625

Recall on (sampled) validation set: 0.21092410013190413

Training loss 48888.36328125

Recall on (sampled) validation set: 0.21555153994355444

Training loss 48888.5390625

Recall on (sampled) validation set: 0.20876993074815214

Training loss 48888.125

Recall on (sampled) validation set: 0.21794293749874513

Training loss 48888.4296875

Recall on (sampled) validation set: 0.21540722321303082

Training loss 48888.11328125

Recall on (sampled) validation set: 0.21276916974603002

Training loss 48888.14453125

Recall on (sampled) validation set: 0.21596500175901265

Training loss 48888.48046875

Recall on (sampled) validation set: 0.21486597742178504

Training loss 48887.953125

Recall on (sampled) validation set: 0.21065771054246554

Training loss 48888.44140625

Recall on (sampled) validation set: 0.20993141007342458

Training loss 48888.44921875

Recall on (sampled) validation set: 0.20744836534037986

Training loss 48888.76953125

Recall on (sampled) validation set: 0.21781838521765925

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21403156183736943

Training loss 48888.84375

Recall on (sampled) validation set: 0.21122832267886715

Training loss 48888.28125

Recall on (sampled) validation set: 0.21675546275999996

Training loss 48888.3046875

Recall on (sampled) validation set: 0.2132807098292579

Training loss 48888.25

Recall on (sampled) validation set: 0.21357253548360627

Training loss 48888.0859375

Recall on (sampled) validation set: 0.21566351964900055

Training loss 48888.1796875

Recall on (sampled) validation set: 0.21140793838479863

Training loss 48888.44140625

Recall on (sampled) validation set: 0.21382451644611356

Training loss 48888.2265625

Recall on (sampled) validation set: 0.21316227371808136

Training loss 48888.03515625

Recall on (sampled) validation set: 0.21267153297734062

Training loss 48888.13671875

Recall on (sampled) validation set: 0.21168670740766926

Training loss 48888.7265625

Recall on (sampled) validation set: 0.208304394301672

Training loss 48888.18359375

Recall on (sampled) validation set: 0.20881576110251246

Training loss 48888.11328125

Recall on (sampled) validation set: 0.21439664120244883

Training loss 48888.34375

Recall on (sampled) validation set: 0.21010891430945877

Training loss 48888.25

Recall on (sampled) validation set: 0.20976569515045015

Training loss 48888.48046875

Recall on (sampled) validation set: 0.2158007045216664

Training loss 48888.33984375

Recall on (sampled) validation set: 0.2127370756218306

Training loss 48888.015625

Recall on (sampled) validation set: 0.21718786015020133

Training loss 48888.2734375

Recall on (sampled) validation set: 0.21276837229786413

Training loss 48888.05078125

Recall on (sampled) validation set: 0.21282831381833198

Training loss 48888.37109375

Recall on (sampled) validation set: 0.2155950870733085

Training loss 48887.6640625

Recall on (sampled) validation set: 0.2160534410303013

Training loss 48888.06640625

Recall on (sampled) validation set: 0.20766120805322255

Training loss 48888.53125

Recall on (sampled) validation set: 0.21211670525146023

Training loss 48888.55078125

Recall on (sampled) validation set: 0.21352187766525332

Training loss 48888.2265625

Recall on (sampled) validation set: 0.20994742625459503

Training loss 48887.8984375

Recall on (sampled) validation set: 0.21478980519044039

Training loss 48888.58984375

Recall on (sampled) validation set: 0.22055373128921224

Training loss 48888.69921875

Recall on (sampled) validation set: 0.2114881578729129

Training loss 48888.14453125

Recall on (sampled) validation set: 0.21232497213077975

Training loss 48888.4453125

Recall on (sampled) validation set: 0.21465239029304367

Training loss 48888.0234375

Recall on (sampled) validation set: 0.21406478404300544

Training loss 48887.9140625

Recall on (sampled) validation set: 0.21383704537379675

Training loss 48888.73046875

Recall on (sampled) validation set: 0.21607390646592098

Training loss 48888.50390625

Recall on (sampled) validation set: 0.21043884899465662

Training loss 48888.13671875

Recall on (sampled) validation set: 0.21974440455021219

Training loss 48888.23046875

Recall on (sampled) validation set: 0.21461289762197203

Training loss 48888.6015625

Recall on (sampled) validation set: 0.21326064464539962

Training loss 48888.13671875

Recall on (sampled) validation set: 0.21577004074100264

Training loss 48888.03125

Recall on (sampled) validation set: 0.2171763366531969

Training loss 48888.453125

Recall on (sampled) validation set: 0.21817633665319694

Training loss 48888.3046875

Recall on (sampled) validation set: 0.21586681284367312

Training loss 48888.36328125

Recall on (sampled) validation set: 0.2154578548426098

Training loss 48887.78515625

Recall on (sampled) validation set: 0.2130987816545893

Training loss 48888.21484375

Recall on (sampled) validation set: 0.21832767764936553

Training loss 48888.3984375

Recall on (sampled) validation set: 0.21058170613751376

Training loss 48888.30078125

Recall on (sampled) validation set: 0.2158052842835057

Training loss 48887.88671875

Recall on (sampled) validation set: 0.21480157791727664

Training loss 48888.484375

Recall on (sampled) validation set: 0.21500641450369215

Training loss 48888.11328125

Recall on (sampled) validation set: 0.21460551566132324

Training loss 48888.28515625

Recall on (sampled) validation set: 0.21959887025994107

Training loss 48888.1015625

Recall on (sampled) validation set: 0.21446007303176087

Training loss 48888.40625

Recall on (sampled) validation set: 0.21616853698160413

Training loss 48888.234375

Recall on (sampled) validation set: 0.21499816394870844

Training loss 48888.53125

Recall on (sampled) validation set: 0.210345148835167

Training loss 48887.7734375

Recall on (sampled) validation set: 0.216556814362622

Training loss 48888.28125

Recall on (sampled) validation set: 0.21543884899465662

Training loss 48887.859375

Recall on (sampled) validation set: 0.21331127234666256

Training loss 48887.94921875

Recall on (sampled) validation set: 0.21414498934553383

Training loss 48888.19140625

Recall on (sampled) validation set: 0.21683772890079608

Training loss 48887.8984375

Recall on (sampled) validation set: 0.22025787256368015

Training loss 48887.60546875

Recall on (sampled) validation set: 0.2131774647346335

Training loss 48888.265625

Recall on (sampled) validation set: 0.21410941189616323

Training loss 48888.32421875

Recall on (sampled) validation set: 0.21400142881585713

Training loss 48888.18359375

Recall on (sampled) validation set: 0.2147293669562272

Training loss 48888.73046875

Recall on (sampled) validation set: 0.2186143975839983

Training loss 48888.2734375

Recall on (sampled) validation set: 0.21510954873250696

Training loss 48888.44140625

Recall on (sampled) validation set: 0.2152042663258634

Training loss 48888.58984375

Recall on (sampled) validation set: 0.21210290333112475

Training loss 48888.109375

Recall on (sampled) validation set: 0.21607466986868076

Training loss 48887.6484375

Recall on (sampled) validation set: 0.21225946898769038

Training loss 48888.3515625

Recall on (sampled) validation set: 0.21853759965919675

Training loss 48888.63671875

Recall on (sampled) validation set: 0.21997539870225893

Training loss 48888.0703125

Recall on (sampled) validation set: 0.21645736751317515

Training loss 48888.44140625

Recall on (sampled) validation set: 0.21960251966558683

Training loss 48887.92578125

Recall on (sampled) validation set: 0.21960551566132325

Training loss 48888.234375

Recall on (sampled) validation set: 0.21473831369611768

Training loss 48888.046875

Recall on (sampled) validation set: 0.21235673474874928

Training loss 48887.94140625

Recall on (sampled) validation set: 0.21478095425781446

Training loss 48888.1640625

Recall on (sampled) validation set: 0.21636796776860298

Training loss 48888.2890625

Recall on (sampled) validation set: 0.21548044920730944

Training loss 48888.01953125

Recall on (sampled) validation set: 0.2198883439441516

Training loss 48888.4453125

Recall on (sampled) validation set: 0.21761049414724548

Training loss 48888.0234375

Recall on (sampled) validation set: 0.21870772193458218

Training loss 48888.48046875

Recall on (sampled) validation set: 0.21508577958305722

Training loss 48888.2265625

Recall on (sampled) validation set: 0.2165386502655105

Training loss 48888.28515625

Recall on (sampled) validation set: 0.21728339090498802

Training loss 48888.3203125

Recall on (sampled) validation set: 0.21830452328138356

Training loss 48888.09375

Recall on (sampled) validation set: 0.2238045232813835

Training loss 48888.28125

Recall on (sampled) validation set: 0.21737946202147654

Training loss 48888.03125

Recall on (sampled) validation set: 0.21574495909749994

Training loss 48888.015625

Recall on (sampled) validation set: 0.2180144094998904

Training loss 48888.21875

Recall on (sampled) validation set: 0.2161118081689769

Training loss 48888.1796875

Recall on (sampled) validation set: 0.2112177358670099

Training loss 48887.9140625

Recall on (sampled) validation set: 0.2170338402607005

Training loss 48888.25

Recall on (sampled) validation set: 0.22128463443526963

Training loss 48887.68359375

Recall on (sampled) validation set: 0.22026992289152

Training loss 48888.39453125

Recall on (sampled) validation set: 0.22175599046379446

Training loss 48888.2109375

Recall on (sampled) validation set: 0.21699415772101796

Training loss 48888.4140625

Recall on (sampled) validation set: 0.20966145728305438

Training loss 48888.171875

Recall on (sampled) validation set: 0.21700683221463615

Training loss 48888.35546875

Recall on (sampled) validation set: 0.21700167651801044

Training loss 48888.43359375

Recall on (sampled) validation set: 0.21723288585448292

Training loss 48888.1953125

Recall on (sampled) validation set: 0.2154049803627843

Training loss 48888.24609375

Recall on (sampled) validation set: 0.21521613944299967

Training loss 48888.1953125

Recall on (sampled) validation set: 0.21669212106371816

Training loss 48888.1484375

Recall on (sampled) validation set: 0.21612514327441734

Training loss 48887.88671875

Recall on (sampled) validation set: 0.21336428759114787

Training loss 48888.19140625

Recall on (sampled) validation set: 0.2122142383562529

Training loss 48888.3359375

Recall on (sampled) validation set: 0.21991984314670343

Training loss 48888.25390625

Recall on (sampled) validation set: 0.21144540251709038

Training loss 48888.10546875

Recall on (sampled) validation set: 0.21441855836910284

Training loss 48888.19921875

Recall on (sampled) validation set: 0.21566722928882637

Training loss 48887.9765625

Recall on (sampled) validation set: 0.21059614640921356

Training loss 48888.203125

Recall on (sampled) validation set: 0.21244500706660416

Training loss 48888.3046875

Recall on (sampled) validation set: 0.21217662538442936

Training loss 48888.80859375

Recall on (sampled) validation set: 0.21597553553860271

Training loss 48887.80859375

Recall on (sampled) validation set: 0.2169666267724344

Training loss 48888.2109375

Recall on (sampled) validation set: 0.21527360154129663

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21365657525911605

Training loss 48888.0546875

Recall on (sampled) validation set: 0.22301664449350472

Training loss 48888.23828125

Recall on (sampled) validation set: 0.2135144094998904

Training loss 48888.11328125

Recall on (sampled) validation set: 0.2094856326203876

Training loss 48888.359375

Recall on (sampled) validation set: 0.20942133437913835

Training loss 48887.91015625

Recall on (sampled) validation set: 0.21124008580315293

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21420333902502686

Training loss 48887.875

Recall on (sampled) validation set: 0.2160999778268381

Training loss 48888.4140625

Recall on (sampled) validation set: 0.217540590853658

Training loss 48888.62109375

Recall on (sampled) validation set: 0.21866736612517013

Training loss 48887.98828125

Recall on (sampled) validation set: 0.21579059085365798

Training loss 48888.88671875

Recall on (sampled) validation set: 0.2284615762673839

Training loss 48888.109375

Recall on (sampled) validation set: 0.2204554854132894

Training loss 48887.9140625

Recall on (sampled) validation set: 0.21957871014177727

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21664104793505884

Training loss 48887.6640625

Recall on (sampled) validation set: 0.21495426632586345

Training loss 48888.5

Recall on (sampled) validation set: 0.21428565034145797

Training loss 48888.8203125

Recall on (sampled) validation set: 0.21446651677958395

Training loss 48887.9296875

Recall on (sampled) validation set: 0.2207215672846344

Training loss 48888.1484375

Recall on (sampled) validation set: 0.21036710157490557

Training loss 48888.078125

Recall on (sampled) validation set: 0.21037287990963127

Training loss 48888.0859375

Recall on (sampled) validation set: 0.2150005143911678

Training loss 48888.2890625

Recall on (sampled) validation set: 0.21131993821195272

Training loss 48888.39453125

Recall on (sampled) validation set: 0.22029802977489002

Training loss 48888.31640625

Recall on (sampled) validation set: 0.21558367204147605

Training loss 48888.1953125

Recall on (sampled) validation set: 0.21807580755266778

Training loss 48888.3359375

Recall on (sampled) validation set: 0.2186165874019776

Training loss 48888.0703125

Recall on (sampled) validation set: 0.21500623249171344

Training loss 48888.01171875

Recall on (sampled) validation set: 0.22243590122991214

Training loss 48888.31640625

Recall on (sampled) validation set: 0.21884002871162578

Training loss 48887.94140625

Recall on (sampled) validation set: 0.21259497708045802

Training loss 48888.05859375

Recall on (sampled) validation set: 0.2211114498192538

Training loss 48888.171875

Recall on (sampled) validation set: 0.22204632095739177

Training loss 48888.06640625

Recall on (sampled) validation set: 0.2176830152270261

Training loss 48888.4296875

Recall on (sampled) validation set: 0.2157885782463822

Training loss 48888.00390625

Recall on (sampled) validation set: 0.22390783472090187

Training loss 48888.01171875

Recall on (sampled) validation set: 0.22015036895617654

Training loss 48888.13671875

Recall on (sampled) validation set: 0.21910250307936333

Training loss 48888.50390625

Recall on (sampled) validation set: 0.22073334153914914

Training loss 48887.80859375

Recall on (sampled) validation set: 0.21842092539778568

Training loss 48888.28125

Recall on (sampled) validation set: 0.22157197613504329

Training loss 48888.03515625

Recall on (sampled) validation set: 0.21784722866029577

Training loss 48888.015625

Recall on (sampled) validation set: 0.2161127559843531

Training loss 48888.23828125

Recall on (sampled) validation set: 0.21294861457021166

Training loss 48888.30078125

Recall on (sampled) validation set: 0.22089053376213083

Training loss 48887.96875

Recall on (sampled) validation set: 0.21385398405452852

Training loss 48887.89453125

Recall on (sampled) validation set: 0.2090390607745417

Training loss 48888.30859375

Recall on (sampled) validation set: 0.21412631260317283

Training loss 48888.41015625

Recall on (sampled) validation set: 0.21224910456217172

Training loss 48888.4765625

Recall on (sampled) validation set: 0.21408367204147605

Training loss 48888.49609375

Recall on (sampled) validation set: 0.21075164487324197

Training loss 48888.16015625

Recall on (sampled) validation set: 0.2074318681587284

Training loss 48887.9296875

Recall on (sampled) validation set: 0.21034975391282104

Training loss 48888.2890625

Recall on (sampled) validation set: 0.21586275598435306

Training loss 48887.75

Recall on (sampled) validation set: 0.2168035510231517

Training loss 48887.8984375

Recall on (sampled) validation set: 0.21721722169408195

Training loss 48888.1953125

Recall on (sampled) validation set: 0.21307833280519303

Training loss 48888.015625

Recall on (sampled) validation set: 0.2159369186637789

Training loss 48887.765625

Recall on (sampled) validation set: 0.21894779093327182

Training loss 48888.16015625

Recall on (sampled) validation set: 0.21684733865314626

Training loss 48887.96875

Recall on (sampled) validation set: 0.21232833280519306

Training loss 48888.31640625

Recall on (sampled) validation set: 0.21485611058297083

Training loss 48888.1015625

Recall on (sampled) validation set: 0.21236734360282455

Training loss 48888.13671875

Recall on (sampled) validation set: 0.2182597902366505

Training loss 48887.88671875

Recall on (sampled) validation set: 0.21509312989893753

Training loss 48888.38671875

Recall on (sampled) validation set: 0.2200378796608379

Training loss 48888.17578125

Recall on (sampled) validation set: 0.2218271137177671

Training loss 48888.109375

Recall on (sampled) validation set: 0.21723719980026696

Training loss 48888.48046875

Recall on (sampled) validation set: 0.214562250933848

Training loss 48888.203125

Recall on (sampled) validation set: 0.22490372963058983

Training loss 48888.1640625

Recall on (sampled) validation set: 0.2225227772496375

Training loss 48888.140625

Recall on (sampled) validation set: 0.22677963150649172

Training loss 48887.96875

Recall on (sampled) validation set: 0.217319450882518

Training loss 48887.78515625

Recall on (sampled) validation set: 0.21917645690331716

Training loss 48888.14453125

Recall on (sampled) validation set: 0.21457328230014255

Training loss 48888.234375

Recall on (sampled) validation set: 0.21938388836074865

Training loss 48888.19921875

Recall on (sampled) validation set: 0.22741166613852642

Training loss 48888.25390625

Recall on (sampled) validation set: 0.22225595881902596

Training loss 48888.0859375

Recall on (sampled) validation set: 0.221339220133231

Training loss 48888.078125

Recall on (sampled) validation set: 0.21359652221811928

Training loss 48888.4140625

Recall on (sampled) validation set: 0.2149924742193345

Training loss 48888.19921875

Recall on (sampled) validation set: 0.21854795775576175

Training loss 48887.9296875

Recall on (sampled) validation set: 0.2239251507382179

Training loss 48887.640625

Recall on (sampled) validation set: 0.22342645690331717

Training loss 48888.28515625

Recall on (sampled) validation set: 0.22138764775924485

Training loss 48887.62890625

Recall on (sampled) validation set: 0.21817214295753312

Training loss 48888.51953125

Recall on (sampled) validation set: 0.2208472286602958

Training loss 48888.10546875

Recall on (sampled) validation set: 0.2264937083653054

Training loss 48888.48828125

Recall on (sampled) validation set: 0.22265661563347589

Training loss 48887.98828125

Recall on (sampled) validation set: 0.22198577185736895

Training loss 48888.24609375

Recall on (sampled) validation set: 0.2181889090105969

Training loss 48888.16015625

Recall on (sampled) validation set: 0.2246764569033171

Training loss 48888.2109375

Recall on (sampled) validation set: 0.22780344103030126

Training loss 48888.2734375

Recall on (sampled) validation set: 0.22026389532696247

Training loss 48888.08984375

Recall on (sampled) validation set: 0.22239074261760283

Training loss 48888.37890625

Recall on (sampled) validation set: 0.2244882971098942

Training loss 48888.375

Recall on (sampled) validation set: 0.22158929215235929

Training loss 48888.1484375

Recall on (sampled) validation set: 0.22052148614308323

Training loss 48888.13671875

Recall on (sampled) validation set: 0.2194781810412482

Training loss 48888.23828125

Recall on (sampled) validation set: 0.22123187562252894

Training loss 48888.18359375

Recall on (sampled) validation set: 0.2143988159618831

Training loss 48888.0234375

Recall on (sampled) validation set: 0.21329789293854626

Training loss 48888.3359375

Recall on (sampled) validation set: 0.2199898769476809

Training loss 48888.25390625

Recall on (sampled) validation set: 0.22129782091941802

Training loss 48887.94140625

Recall on (sampled) validation set: 0.2227662117240157

Training loss 48888.05859375

Recall on (sampled) validation set: 0.21919198422737443

Training loss 48887.82421875

Recall on (sampled) validation set: 0.2277715509602987

Training loss 48888.08984375

Recall on (sampled) validation set: 0.22577085957666715

Training loss 48888.19921875

Recall on (sampled) validation set: 0.22391434328594034

Training loss 48888.1015625

Recall on (sampled) validation set: 0.2239582029350632

Training loss 48888.390625

Recall on (sampled) validation set: 0.2276958804622144

Training loss 48888.10546875

Recall on (sampled) validation set: 0.223811579191797

Training loss 48888.08984375

Recall on (sampled) validation set: 0.23092638488418885

Training loss 48888.44140625

Recall on (sampled) validation set: 0.2239582029350632

Training loss 48888.36328125

Recall on (sampled) validation set: 0.22485495631276034

Training loss 48888.23828125

Recall on (sampled) validation set: 0.221788923938198

Training loss 48887.87890625

Recall on (sampled) validation set: 0.22531548262854972

Training loss 48887.94140625

Recall on (sampled) validation set: 0.22104227282766303

Training loss 48887.81640625

Recall on (sampled) validation set: 0.22196304458464164

Training loss 48887.89453125

Recall on (sampled) validation set: 0.22810590172749878

Training loss 48888.06640625

Recall on (sampled) validation set: 0.22276100932407644

Training loss 48888.1953125

Recall on (sampled) validation set: 0.2241061754001863

Training loss 48888.0546875

Recall on (sampled) validation set: 0.22423417696103723

Training loss 48887.9140625

Recall on (sampled) validation set: 0.22395693474368608

Training loss 48887.89453125

Recall on (sampled) validation set: 0.22517129247710008

Training loss 48888.24609375

Recall on (sampled) validation set: 0.22545310332606155

Training loss 48888.23828125

Recall on (sampled) validation set: 0.2246555713561158

Training loss 48887.9453125

Recall on (sampled) validation set: 0.2291930664784567

Training loss 48887.85546875

Recall on (sampled) validation set: 0.22769306647845666

Training loss 48887.98046875

Recall on (sampled) validation set: 0.22295503605757688

Training loss 48888.109375

Recall on (sampled) validation set: 0.22751209157515873

Training loss 48888.0703125

Recall on (sampled) validation set: 0.22692862140548167

Training loss 48888.203125

Recall on (sampled) validation set: 0.22391876722457482

Training loss 48888.84375

Recall on (sampled) validation set: 0.22585383215963978

Training loss 48888.32421875

Recall on (sampled) validation set: 0.22780163727849753

Training loss 48888.19140625

Recall on (sampled) validation set: 0.2179079447137523

Training loss 48888.41015625

Recall on (sampled) validation set: 0.22064292217831238

Training loss 48887.984375

Recall on (sampled) validation set: 0.22387198359884383

Training loss 48888.140625

Recall on (sampled) validation set: 0.22125065755646517

Training loss 48888.125

Recall on (sampled) validation set: 0.22631259662566378

Training loss 48887.71875

Recall on (sampled) validation set: 0.22439340470647182

Training loss 48887.890625

Recall on (sampled) validation set: 0.2256550855543596

Training loss 48888.28125

Recall on (sampled) validation set: 0.22006764713071428

Training loss 48888.30078125

Recall on (sampled) validation set: 0.21998575679882398

Training loss 48888.015625

Recall on (sampled) validation set: 0.22051736599422625

Training loss 48888.60546875

Recall on (sampled) validation set: 0.2258190901321573

Training loss 48887.80078125

Recall on (sampled) validation set: 0.22383064920224632

Training loss 48887.91015625

Recall on (sampled) validation set: 0.21952701917629322

Training loss 48888.0546875

Recall on (sampled) validation set: 0.22467769104928814

Training loss 48888.08984375

Recall on (sampled) validation set: 0.22572673803980517

Training loss 48888.24609375

Recall on (sampled) validation set: 0.22580203600258045

Training loss 48888.13671875

Recall on (sampled) validation set: 0.22469854255108335

Training loss 48888.40625

Recall on (sampled) validation set: 0.22640809660864109

Training loss 48887.984375

Recall on (sampled) validation set: 0.22627042680717815

Training loss 48888.09375

Recall on (sampled) validation set: 0.22574439189230475

Training loss 48888.13671875

Recall on (sampled) validation set: 0.22204748701255056

Training loss 48888.06640625

Recall on (sampled) validation set: 0.22496065616846014

Training loss 48887.99609375

Recall on (sampled) validation set: 0.22649623361783072

Training loss 48888.13671875

Recall on (sampled) validation set: 0.2231622737180813

Training loss 48887.82421875

Recall on (sampled) validation set: 0.2209656418562952

Training loss 48888.21875

Recall on (sampled) validation set: 0.22479911202597228

Training loss 48888.3046875

Recall on (sampled) validation set: 0.23036301459849554

Training loss 48887.90625

Recall on (sampled) validation set: 0.22560849899915236

Training loss 48888.46484375

Recall on (sampled) validation set: 0.22447673803980517

Training loss 48888.12890625

Recall on (sampled) validation set: 0.23124637045417443

Training loss 48888.0703125

Recall on (sampled) validation set: 0.22850020187179892

Training loss 48888.31640625

Recall on (sampled) validation set: 0.23026224347004748

Training loss 48888.109375

Recall on (sampled) validation set: 0.22693684664465064

Training loss 48888.046875

Recall on (sampled) validation set: 0.2202260315976287

Training loss 48888.14453125

Recall on (sampled) validation set: 0.22311421077074434

Training loss 48888.0234375

Recall on (sampled) validation set: 0.22463620475780186

Training loss 48888.1953125

Recall on (sampled) validation set: 0.2270223713236417

Training loss 48888.43359375

Recall on (sampled) validation set: 0.22472831002095972

Training loss 48888.3359375

Recall on (sampled) validation set: 0.22825142095922493

Training loss 48887.9765625

Recall on (sampled) validation set: 0.22692302813809165

Training loss 48888.61328125

Recall on (sampled) validation set: 0.2285775543438883

Training loss 48888.265625

Recall on (sampled) validation set: 0.22588264701286476

Training loss 48888.0390625

Recall on (sampled) validation set: 0.22369677284468575

Training loss 48888.125

Recall on (sampled) validation set: 0.2228467310735913

Training loss 48887.984375

Recall on (sampled) validation set: 0.22729911202597228

Training loss 48888.0

Recall on (sampled) validation set: 0.22633064920224627

Training loss 48887.765625

Recall on (sampled) validation set: 0.22642315318948714

Training loss 48888.31640625

Recall on (sampled) validation set: 0.22816001428161134

Training loss 48888.296875

Recall on (sampled) validation set: 0.22355781193666857

Training loss 48887.984375

Recall on (sampled) validation set: 0.22216899506690793

Training loss 48888.34375

Recall on (sampled) validation set: 0.22079472606106

Training loss 48887.625

Recall on (sampled) validation set: 0.2206890379903084

Training loss 48888.0859375

Recall on (sampled) validation set: 0.2241643432859404

Training loss 48888.046875

Recall on (sampled) validation set: 0.2257705090835762

Training loss 48888.30078125

Recall on (sampled) validation set: 0.2279142712668121

Training loss 48887.94140625

Recall on (sampled) validation set: 0.22897084425623443

Training loss 48888.359375

Recall on (sampled) validation set: 0.23163244535930563

Training loss 48888.1484375

Recall on (sampled) validation set: 0.2293477563640903

Training loss 48888.26171875

Recall on (sampled) validation set: 0.2276971715687687

Training loss 48888.2109375

Recall on (sampled) validation set: 0.2234036576114616

Training loss 48888.18359375

Recall on (sampled) validation set: 0.22691434328594037

Training loss 48887.78515625

Recall on (sampled) validation set: 0.22939414126573837

Training loss 48888.4140625

Recall on (sampled) validation set: 0.2239897401113372

Training loss 48887.98828125

Recall on (sampled) validation set: 0.21962114817695577

Training loss 48887.87109375

Recall on (sampled) validation set: 0.22282250383883778

Training loss 48888.7265625

Recall on (sampled) validation set: 0.22417191904351616

Training loss 48887.83984375

Recall on (sampled) validation set: 0.22820463733349394

Training loss 48887.9609375

Recall on (sampled) validation set: 0.22381836077480358

Training loss 48888.0390625

Recall on (sampled) validation set: 0.2275499474478603

Training loss 48888.19921875

Recall on (sampled) validation set: 0.21722441444083912

Training loss 48888.21875

Recall on (sampled) validation set: 0.22657425455837435

Training loss 48887.98828125

Recall on (sampled) validation set: 0.22026375849061874

Training loss 48888.37890625

Recall on (sampled) validation set: 0.22212486960172986

Training loss 48887.9765625

Recall on (sampled) validation set: 0.22516939379099085

Training loss 48888.1953125

Recall on (sampled) validation set: 0.2227438452016492

Training loss 48888.046875

Recall on (sampled) validation set: 0.22587198359884383

Training loss 48888.24609375

Recall on (sampled) validation set: 0.22487261016525992

Training loss 48888.05859375

Recall on (sampled) validation set: 0.2276072844947618

Training loss 48888.26171875

Recall on (sampled) validation set: 0.22308701372902826

Training loss 48888.31640625

Recall on (sampled) validation set: 0.228318007881075

Training loss 48888.31640625

Recall on (sampled) validation set: 0.22978359976046003

Training loss 48888.19140625

Recall on (sampled) validation set: 0.22871448758608465

Training loss 48888.36328125

Recall on (sampled) validation set: 0.22398214929521648

Training loss 48888.2890625

Recall on (sampled) validation set: 0.22622926329233042

Training loss 48888.07421875

Recall on (sampled) validation set: 0.22372494934654644

Training loss 48888.03515625

Recall on (sampled) validation set: 0.22555720042879757

Training loss 48888.28125

Recall on (sampled) validation set: 0.2214543715174387

Training loss 48888.046875

Recall on (sampled) validation set: 0.21919212106371816

Training loss 48888.10546875

Recall on (sampled) validation set: 0.22400226423774516

Training loss 48888.19140625

Recall on (sampled) validation set: 0.22540264737950763

Training loss 48888.24609375

Recall on (sampled) validation set: 0.22538704803632204

Training loss 48888.4140625

Recall on (sampled) validation set: 0.2226968186750401

Training loss 48888.296875

Recall on (sampled) validation set: 0.22410214232900258

Training loss 48888.01953125

Recall on (sampled) validation set: 0.22445437151743866

Training loss 48887.9453125

Recall on (sampled) validation set: 0.22745040326347038

Training loss 48888.07421875

Recall on (sampled) validation set: 0.22843445822846908

Training loss 48888.2265625

Recall on (sampled) validation set: 0.22142659373966087

Training loss 48887.98828125

Recall on (sampled) validation set: 0.22224370836530544

Training loss 48888.125

Recall on (sampled) validation set: 0.2261576978845581

Training loss 48888.1484375

Recall on (sampled) validation set: 0.221280504902102

Training loss 48888.34375

Recall on (sampled) validation set: 0.22563273409053808

Training loss 48887.921875

Recall on (sampled) validation set: 0.2297826923194437

Training loss 48888.109375

Recall on (sampled) validation set: 0.22864004403205854

Training loss 48888.1796875

Recall on (sampled) validation set: 0.22776779156180244

Training loss 48887.87109375

Recall on (sampled) validation set: 0.22091037503197214

Training loss 48888.3046875

Recall on (sampled) validation set: 0.22831951569973352

Training loss 48888.12890625

Recall on (sampled) validation set: 0.22335481947641653

Training loss 48888.12890625

Recall on (sampled) validation set: 0.22721101691882092

Training loss 48887.56640625

Recall on (sampled) validation set: 0.22808410481096505

Training loss 48887.89453125

Recall on (sampled) validation set: 0.22433054706602798

Training loss 48888.28515625

Recall on (sampled) validation set: 0.22527040389200095

Training loss 48887.82421875

Recall on (sampled) validation set: 0.22615264737950763

Training loss 48888.421875

Recall on (sampled) validation set: 0.22226375849061872

Training loss 48888.01171875

Recall on (sampled) validation set: 0.22223186121870328

Training loss 48887.671875

Recall on (sampled) validation set: 0.22277942265101974

Training loss 48887.9609375

Recall on (sampled) validation set: 0.2172211899480502

Training loss 48888.31640625

Recall on (sampled) validation set: 0.22605323217482928

Training loss 48888.1015625

Recall on (sampled) validation set: 0.22268042515728542

Training loss 48888.171875

Recall on (sampled) validation set: 0.22232212802993204

Training loss 48887.83984375

Recall on (sampled) validation set: 0.22055201308740327

Training loss 48887.94921875

Recall on (sampled) validation set: 0.22129153626839654

Training loss 48888.2109375

Recall on (sampled) validation set: 0.2206675749806421

Training loss 48888.36328125

Recall on (sampled) validation set: 0.22665929278088986

Training loss 48888.14453125

Recall on (sampled) validation set: 0.22520315243001268

Training loss 48888.17578125

Recall on (sampled) validation set: 0.22414321090954484

Training loss 48887.93359375

Recall on (sampled) validation set: 0.21925870798556824

Training loss 48887.78515625

Recall on (sampled) validation set: 0.22298496327897416

Training loss 48888.296875

Recall on (sampled) validation set: 0.21997730044372513

Training loss 48888.66015625

Recall on (sampled) validation set: 0.21924391722077743

Training loss 48887.96875

Recall on (sampled) validation set: 0.21930166019367467

Training loss 48888.640625

Recall on (sampled) validation set: 0.21887486960172983

Training loss 48888.0703125

Recall on (sampled) validation set: 0.22018164424471137

Training loss 48888.171875

Recall on (sampled) validation set: 0.2190693140461743

Training loss 48887.88671875

Recall on (sampled) validation set: 0.21987841294284124

Training loss 48888.01171875

Recall on (sampled) validation set: 0.22351779156180243

Training loss 48887.64453125

Recall on (sampled) validation set: 0.21894943100523864

Training loss 48887.96875

Recall on (sampled) validation set: 0.21701779156180245

Training loss 48888.19140625

Recall on (sampled) validation set: 0.2186172067664808

Training loss 48888.3203125

Recall on (sampled) validation set: 0.21585843483665626

Training loss 48888.328125

Recall on (sampled) validation set: 0.21891058388744417

Training loss 48888.3515625

Recall on (sampled) validation set: 0.2139466818386963

Training loss 48887.91015625

Recall on (sampled) validation set: 0.2162438452016492

Training loss 48888.01171875

Recall on (sampled) validation set: 0.2154382896460936

Training loss 48888.30859375

Recall on (sampled) validation set: 0.21788189866865007

Training loss 48888.1796875

Recall on (sampled) validation set: 0.21753387343314748

Training loss 48888.4296875

Recall on (sampled) validation set: 0.22208435164015924

Training loss 48888.359375

Recall on (sampled) validation set: 0.22303276433857197

Training loss 48888.078125

Recall on (sampled) validation set: 0.2216488159618831

Training loss 48888.33984375

Recall on (sampled) validation set: 0.22295729549404683

Training loss 48888.14453125

Recall on (sampled) validation set: 0.2242272087830164

Training loss 48888.13671875

Recall on (sampled) validation set: 0.22383176615345401

Training loss 48888.28515625

Recall on (sampled) validation set: 0.22224823116656148

Training loss 48888.265625

Recall on (sampled) validation set: 0.2257599270729942

Training loss 48888.12109375

Recall on (sampled) validation set: 0.21992911899218612

Training loss 48887.9140625

Recall on (sampled) validation set: 0.21851375849061871

Training loss 48888.0390625

Recall on (sampled) validation set: 0.22154947277633302

Training loss 48888.14453125

Recall on (sampled) validation set: 0.22200498656079418

Training loss 48887.9296875

Recall on (sampled) validation set: 0.22074843282012063

Training loss 48888.26171875

Recall on (sampled) validation set: 0.22062020276221725

Training loss 48887.92578125

Recall on (sampled) validation set: 0.2240528792811007

Training loss 48888.37109375

Recall on (sampled) validation set: 0.22208435164015924

Training loss 48887.76171875

Recall on (sampled) validation set: 0.22174019579600346

Training loss 48888.0390625

Recall on (sampled) validation set: 0.22261334850536305

Training loss 48887.953125

Recall on (sampled) validation set: 0.22116015897458727

Training loss 48888.015625

Recall on (sampled) validation set: 0.22046954594776735

Training loss 48888.13671875

Recall on (sampled) validation set: 0.22720729549404686

Training loss 48887.69140625

Recall on (sampled) validation set: 0.22335200549265882

Training loss 48887.78125

Recall on (sampled) validation set: 0.22101305990507442

Training loss 48887.82421875

Recall on (sampled) validation set: 0.21404951075005518

Training loss 48888.1640625

Recall on (sampled) validation set: 0.22010732574208072

Training loss 48888.50390625

Recall on (sampled) validation set: 0.22008111994545748

Training loss 48888.30859375

Recall on (sampled) validation set: 0.21964256928458378

Training loss 48888.0546875

Recall on (sampled) validation set: 0.2231034943244562

Training loss 48888.39453125

Recall on (sampled) validation set: 0.21935985099460595

Training loss 48888.1015625

Recall on (sampled) validation set: 0.21807345711020842

Training loss 48887.87890625

Recall on (sampled) validation set: 0.2224847845405922

Training loss 48888.26171875

Recall on (sampled) validation set: 0.21877016099112287

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21963127210223396

Training loss 48887.859375

Recall on (sampled) validation set: 0.22411348534170675

Training loss 48887.921875

Recall on (sampled) validation set: 0.22380923595125043

Training loss 48888.37890625

Recall on (sampled) validation set: 0.21982954796430293

Training loss 48888.12890625

Recall on (sampled) validation set: 0.21936609767190526

Training loss 48888.171875

Recall on (sampled) validation set: 0.22360985099460598

Training loss 48888.06640625

Recall on (sampled) validation set: 0.22289535642484823

Training loss 48887.9296875

Recall on (sampled) validation set: 0.21636862292443054

Training loss 48887.90625

Recall on (sampled) validation set: 0.21722096210571712

Training loss 48888.01171875

Recall on (sampled) validation set: 0.21999873988349483

Training loss 48888.234375

Recall on (sampled) validation set: 0.2171931843279393

Training loss 48888.140625

Recall on (sampled) validation set: 0.21485480048955546

Training loss 48888.4453125

Recall on (sampled) validation set: 0.21578998567474064

Training loss 48888.328125

Recall on (sampled) validation set: 0.21562819230242097

Training loss 48887.859375

Recall on (sampled) validation set: 0.2158270227117777

Training loss 48888.1484375

Recall on (sampled) validation set: 0.21398669108333357

Training loss 48888.0859375

Recall on (sampled) validation set: 0.21291560820372069

Training loss 48888.1640625

Recall on (sampled) validation set: 0.2175871237218787

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21686107008203198

Training loss 48888.40625

Recall on (sampled) validation set: 0.21499873988349488

Training loss 48888.09375

Recall on (sampled) validation set: 0.21507946088662966

Training loss 48888.046875

Recall on (sampled) validation set: 0.21093674058011624

Training loss 48888.01953125

Recall on (sampled) validation set: 0.21086490149965648

Training loss 48888.39453125

Recall on (sampled) validation set: 0.212432354615204

Training loss 48887.8046875

Recall on (sampled) validation set: 0.2165432640727559

Training loss 48888.10546875

Recall on (sampled) validation set: 0.21706223194698693

Training loss 48888.10546875

Recall on (sampled) validation set: 0.22131728245203747

Training loss 48888.15625

Recall on (sampled) validation set: 0.223563067368875

Training loss 48888.0703125

Recall on (sampled) validation set: 0.22229034009614773

Training loss 48887.94140625

Recall on (sampled) validation set: 0.212859850994606

Training loss 48887.94921875

Recall on (sampled) validation set: 0.21442045705521204

Training loss 48888.26953125

Recall on (sampled) validation set: 0.20864267927743427

Training loss 48887.94921875

Recall on (sampled) validation set: 0.21453156816632316

Training loss 48887.93359375

Recall on (sampled) validation set: 0.21501734700736516

Training loss 48888.28125

Recall on (sampled) validation set: 0.21622973403554166

Training loss 48888.2890625

Recall on (sampled) validation set: 0.21611075843562227

Training loss 48887.68359375

Recall on (sampled) validation set: 0.2131866305872658

Training loss 48888.25

Recall on (sampled) validation set: 0.21649490846587033

Training loss 48887.94921875

Recall on (sampled) validation set: 0.21469701574556382

Training loss 48888.30078125

Recall on (sampled) validation set: 0.2177209621057171

Training loss 48887.71875

Recall on (sampled) validation set: 0.21110074515791394

Training loss 48888.3203125

Recall on (sampled) validation set: 0.21223984290227482

Training loss 48888.12109375

Recall on (sampled) validation set: 0.21331187119662617

Training loss 48888.0546875

Recall on (sampled) validation set: 0.21518310623301545

Training loss 48887.875

Recall on (sampled) validation set: 0.21820076008551506

Training loss 48888.3359375

Recall on (sampled) validation set: 0.218122838007593

Training loss 48888.296875

Recall on (sampled) validation set: 0.21279512478514293

Training loss 48888.640625

Recall on (sampled) validation set: 0.21186237624713122

Training loss 48887.8984375

Recall on (sampled) validation set: 0.2140554045336259

Training loss 48887.8203125

Recall on (sampled) validation set: 0.21154915785632664

Training loss 48888.3359375

Recall on (sampled) validation set: 0.2114709621057171

Training loss 48887.87890625

Recall on (sampled) validation set: 0.20997348735824234

Training loss 48887.8359375

Recall on (sampled) validation set: 0.20881851659800843

Training loss 48887.71875

Recall on (sampled) validation set: 0.21155046402142588

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21591979251507382

Training loss 48888.44921875

Recall on (sampled) validation set: 0.21720700676281435

Training loss 48887.953125

Recall on (sampled) validation set: 0.21717539756741208

Training loss 48888.12890625

Recall on (sampled) validation set: 0.20956667487248246

Training loss 48887.91015625

Recall on (sampled) validation set: 0.20983198613915494

Training loss 48888.21875

Recall on (sampled) validation set: 0.2070302620012239

Training loss 48887.875

Recall on (sampled) validation set: 0.21012236726438177

Training loss 48888.21875

Recall on (sampled) validation set: 0.21108507314088076

Training loss 48887.93359375

Recall on (sampled) validation set: 0.2174292289850366

Training loss 48888.0

Recall on (sampled) validation set: 0.21464256928458383

Training loss 48888.18359375

Recall on (sampled) validation set: 0.21427138007854885

Training loss 48887.6953125

Recall on (sampled) validation set: 0.21428903393104848

Training loss 48887.71484375

Recall on (sampled) validation set: 0.21567395456596908

Training loss 48888.328125

Recall on (sampled) validation set: 0.2141740914023128

Training loss 48888.0546875

Recall on (sampled) validation set: 0.21326125615327068

Training loss 48888.37109375

Recall on (sampled) validation set: 0.21100395406838235

Training loss 48887.96484375

Recall on (sampled) validation set: 0.21212619868200627

Training loss 48888.3203125

Recall on (sampled) validation set: 0.20933570756392897

Training loss 48887.984375

Recall on (sampled) validation set: 0.20875742473564615

Training loss 48888.14453125

Recall on (sampled) validation set: 0.20730803977900167

Training loss 48887.984375

Recall on (sampled) validation set: 0.20878520251342392

Training loss 48888.0390625

Recall on (sampled) validation set: 0.21036742675218173

Training loss 48888.0

Recall on (sampled) validation set: 0.21475753472849657

Training loss 48888.09375

Recall on (sampled) validation set: 0.21626912064207887

Training loss 48888.3203125

Recall on (sampled) validation set: 0.2102991578563266

Training loss 48887.9453125

Recall on (sampled) validation set: 0.21210471341188217

Training loss 48888.40625

Recall on (sampled) validation set: 0.2116883996389441

Training loss 48888.0234375

Recall on (sampled) validation set: 0.2120127639719291

Training loss 48888.078125

Recall on (sampled) validation set: 0.20892287231488682

Training loss 48887.75390625

Recall on (sampled) validation set: 0.21265623589625404

Training loss 48888.19921875

Recall on (sampled) validation set: 0.21295448151028912

Training loss 48888.08984375

Recall on (sampled) validation set: 0.2062322592880669

Training loss 48888.69921875

Recall on (sampled) validation set: 0.21480080185660946

Training loss 48887.921875

Recall on (sampled) validation set: 0.21232879634649143

Training loss 48887.96484375

Recall on (sampled) validation set: 0.2134712279217724

Training loss 48887.98828125

Recall on (sampled) validation set: 0.2109834783754929

Training loss 48887.734375

Recall on (sampled) validation set: 0.2118585448295067

Training loss 48888.14453125

Recall on (sampled) validation set: 0.21496234599909736

Training loss 48888.12890625

Recall on (sampled) validation set: 0.21413754169471047

Training loss 48887.89453125

Recall on (sampled) validation set: 0.21894345014399463

Training loss 48887.80859375

Recall on (sampled) validation set: 0.21623225928806689

Training loss 48887.7734375

Recall on (sampled) validation set: 0.21404140336036884

Training loss 48888.23828125

Recall on (sampled) validation set: 0.20984458948660398

Training loss 48888.23828125

Recall on (sampled) validation set: 0.21338284408338856

Training loss 48888.33984375

Recall on (sampled) validation set: 0.2100201380759457

Training loss 48888.12109375

Recall on (sampled) validation set: 0.21170953201533962

Training loss 48887.76953125

Recall on (sampled) validation set: 0.21247184728627558

Training loss 48888.1953125

Recall on (sampled) validation set: 0.2137373097931174

Training loss 48888.23828125

Recall on (sampled) validation set: 0.21946422809898308

Training loss 48888.0234375

Recall on (sampled) validation set: 0.22127228751956518

Training loss 48888.4765625

Recall on (sampled) validation set: 0.21667670373251136

Training loss 48887.609375

Recall on (sampled) validation set: 0.2159986528058216

Training loss 48887.90625

Recall on (sampled) validation set: 0.21689892595473356

Training loss 48887.60546875

Recall on (sampled) validation set: 0.2158007298374812

Training loss 48888.0390625

Recall on (sampled) validation set: 0.21278398342599794

Training loss 48888.3359375

Recall on (sampled) validation set: 0.21256122957166515

Training loss 48887.74609375

Recall on (sampled) validation set: 0.2117298440283921

Training loss 48888.1484375

Recall on (sampled) validation set: 0.2109696559406178

Training loss 48887.8359375

Recall on (sampled) validation set: 0.2168957590772473

Training loss 48887.5

Recall on (sampled) validation set: 0.21903398342599795

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21540809660864105

Training loss 48888.0234375

Recall on (sampled) validation set: 0.21984589565170323

Training loss 48888.03515625

Recall on (sampled) validation set: 0.21837367342948102

Training loss 48887.92578125

Recall on (sampled) validation set: 0.21344429342251484

Training loss 48888.23828125

Recall on (sampled) validation set: 0.21337619868200627

Training loss 48888.09375

Recall on (sampled) validation set: 0.22048095312296762

Training loss 48887.96484375

Recall on (sampled) validation set: 0.21341773473216302

Training loss 48887.87890625

Recall on (sampled) validation set: 0.2210759823627337

Training loss 48888.63671875

Recall on (sampled) validation set: 0.21767156614978755

Training loss 48888.11328125

Recall on (sampled) validation set: 0.2176350884613135

Training loss 48888.2109375

Recall on (sampled) validation set: 0.2163259823627337

Training loss 48887.7734375

Recall on (sampled) validation set: 0.22087619868200628

Training loss 48887.86328125

Recall on (sampled) validation set: 0.21780137146244224

Training loss 48887.9296875

Recall on (sampled) validation set: 0.21790650171230933

Training loss 48887.9140625

Recall on (sampled) validation set: 0.21660123488798622

Training loss 48888.35546875

Recall on (sampled) validation set: 0.21229286534867295

Training loss 48887.93359375

Recall on (sampled) validation set: 0.21579820458495594

Training loss 48888.12890625

Recall on (sampled) validation set: 0.21669092489146935

Training loss 48887.93359375

Recall on (sampled) validation set: 0.2165641496199572

Training loss 48887.76953125

Recall on (sampled) validation set: 0.2204371654929731

Training loss 48887.83984375

Recall on (sampled) validation set: 0.22144092489146933

Training loss 48887.6796875

Recall on (sampled) validation set: 0.2233298137803582

Training loss 48887.8359375

Recall on (sampled) validation set: 0.21699264902940038

Training loss 48887.953125

Recall on (sampled) validation set: 0.21694551250994082

Training loss 48888.19140625

Recall on (sampled) validation set: 0.2142853125062744

Training loss 48887.5234375

Recall on (sampled) validation set: 0.22072964695786837

Training loss 48887.68359375

Recall on (sampled) validation set: 0.21728903393104843

Training loss 48887.73828125

Recall on (sampled) validation set: 0.21948414291563112

Training loss 48887.83984375

Recall on (sampled) validation set: 0.21894214397889536

Training loss 48887.67578125

Recall on (sampled) validation set: 0.21999386811682636

Training loss 48887.87109375

Recall on (sampled) validation set: 0.21829326407275587

Training loss 48887.5703125

Recall on (sampled) validation set: 0.22254820458495592

Training loss 48887.73828125

Recall on (sampled) validation set: 0.2247943731673314

Training loss 48887.87109375

Recall on (sampled) validation set: 0.22346870266924715

Training loss 48887.99609375

Recall on (sampled) validation set: 0.22127173297227742

Training loss 48887.87890625

Recall on (sampled) validation set: 0.22101110033006582

Training loss 48887.62890625

Recall on (sampled) validation set: 0.22103240358821116

Training loss 48887.9453125

Recall on (sampled) validation set: 0.22078015200837342

Training loss 48887.8984375

Recall on (sampled) validation set: 0.21512367342948105

Training loss 48887.88671875

Recall on (sampled) validation set: 0.2196702599846883

Training loss 48887.9453125

Recall on (sampled) validation set: 0.22288153791828927

Training loss 48888.0234375

Recall on (sampled) validation set: 0.21865931569606706

Training loss 48887.875

Recall on (sampled) validation set: 0.220116010594232

Training loss 48887.421875

Recall on (sampled) validation set: 0.22151151804100985

Training loss 48887.55078125

Recall on (sampled) validation set: 0.2210681178739255

Training loss 48887.6796875

Recall on (sampled) validation set: 0.2153066615947741

Training loss 48887.625

Recall on (sampled) validation set: 0.21648368002905205

Training loss 48888.3046875

Recall on (sampled) validation set: 0.21666306003601826

Training loss 48887.85546875

Recall on (sampled) validation set: 0.21613789458843907

Training loss 48888.11328125

Recall on (sampled) validation set: 0.21944755523430662

Training loss 48888.13671875

Recall on (sampled) validation set: 0.22361731675933125

Training loss 48887.76953125

Recall on (sampled) validation set: 0.22165145120725882

Training loss 48888.125

Recall on (sampled) validation set: 0.22424723664787186

Training loss 48887.80859375

Recall on (sampled) validation set: 0.216617229681658

Training loss 48887.81640625

Recall on (sampled) validation set: 0.22172853786329283

Training loss 48887.85546875

Recall on (sampled) validation set: 0.2243594902442452

Training loss 48887.94921875

Recall on (sampled) validation set: 0.2223045612551057

Training loss 48888.0546875

Recall on (sampled) validation set: 0.21910376014051147

Training loss 48887.76953125

Recall on (sampled) validation set: 0.21916314711369153

Training loss 48888.15625

Recall on (sampled) validation set: 0.21670953201533963

Training loss 48887.99609375

Recall on (sampled) validation set: 0.21497122792177237

Training loss 48887.875

Recall on (sampled) validation set: 0.22344495796265307

Training loss 48887.76171875

Recall on (sampled) validation set: 0.22320317534518988

Training loss 48887.6796875

Recall on (sampled) validation set: 0.21913975530082605

Training loss 48887.69140625

Recall on (sampled) validation set: 0.22291753307860385

Training loss 48887.859375

Recall on (sampled) validation set: 0.2191955125099408

Training loss 48887.7109375

Recall on (sampled) validation set: 0.22157476327530773

Training loss 48887.66015625

Recall on (sampled) validation set: 0.220394452912148

Training loss 48887.81640625

Recall on (sampled) validation set: 0.21747601261076757

Training loss 48887.64453125

Recall on (sampled) validation set: 0.22211984201185653

Training loss 48887.89453125

Recall on (sampled) validation set: 0.22335073730128177

Training loss 48887.984375

Recall on (sampled) validation set: 0.22118824774405538

Training loss 48887.96875

Recall on (sampled) validation set: 0.21886155981210426

Training loss 48887.921875

Recall on (sampled) validation set: 0.21943386177914306

Training loss 48887.8515625

Recall on (sampled) validation set: 0.22014337066106576

Training loss 48887.62890625

Recall on (sampled) validation set: 0.2199371432325153

Training loss 48888.3046875

Recall on (sampled) validation set: 0.22566046996627756

Training loss 48887.58984375

Recall on (sampled) validation set: 0.22340548427844253

Training loss 48888.265625

Recall on (sampled) validation set: 0.22348492137693587

Training loss 48887.96484375

Recall on (sampled) validation set: 0.22590451202021075

Training loss 48887.671875

Recall on (sampled) validation set: 0.22006320420521874

Training loss 48887.875

Recall on (sampled) validation set: 0.2221418628424073

Training loss 48887.9296875

Recall on (sampled) validation set: 0.22602944556619695

Training loss 48887.92578125

Recall on (sampled) validation set: 0.22095296648971782

Training loss 48887.4609375

Recall on (sampled) validation set: 0.21892936582138028

Training loss 48887.78125

Recall on (sampled) validation set: 0.22127450505399687

Training loss 48887.78125

Recall on (sampled) validation set: 0.22081703562284322

Training loss 48887.7109375

Recall on (sampled) validation set: 0.21715541946122707

Training loss 48887.4609375

Recall on (sampled) validation set: 0.21907995061670196

Training loss 48887.78515625

Recall on (sampled) validation set: 0.22152056364352185

Training loss 48887.5546875

Recall on (sampled) validation set: 0.22438933758988203

Training loss 48887.921875

Recall on (sampled) validation set: 0.21826562313132186

Training loss 48887.34375

Recall on (sampled) validation set: 0.21873997188198638

Training loss 48887.51953125

Recall on (sampled) validation set: 0.21774914253589392

Training loss 48887.93359375

Recall on (sampled) validation set: 0.22040541946122705

Training loss 48887.3984375

Recall on (sampled) validation set: 0.22216991429287258

Training loss 48887.51953125

Recall on (sampled) validation set: 0.21562168373738244

Training loss 48887.5703125

Recall on (sampled) validation set: 0.21579291357966493

Training loss 48887.58984375

Recall on (sampled) validation set: 0.21579723232672415

Training loss 48887.64453125

Recall on (sampled) validation set: 0.21828451898642462

Training loss 48887.59375

Recall on (sampled) validation set: 0.21466206486260936

Training loss 48887.71875

Recall on (sampled) validation set: 0.21385560186603744

Training loss 48887.8984375

Recall on (sampled) validation set: 0.21393319723900486

Training loss 48887.9296875

Recall on (sampled) validation set: 0.21438727980697128

Training loss 48887.8046875

Recall on (sampled) validation set: 0.2190215810773887

Training loss 48887.96875

Recall on (sampled) validation set: 0.21723614046436188

Training loss 48887.515625

Recall on (sampled) validation set: 0.21583938708666475

Training loss 48888.01171875

Recall on (sampled) validation set: 0.2179057311076367

Training loss 48887.640625

Recall on (sampled) validation set: 0.2161288607708753

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21667216587271032

Training loss 48887.75390625

Recall on (sampled) validation set: 0.22251391824213965

Training loss 48887.80859375

Recall on (sampled) validation set: 0.21585491441072202

Training loss 48888.03515625

Recall on (sampled) validation set: 0.217823168378976

Training loss 48887.625

Recall on (sampled) validation set: 0.21859662500905694

Training loss 48887.734375

Recall on (sampled) validation set: 0.21717045705521207

Training loss 48888.00390625

Recall on (sampled) validation set: 0.21777295205970343

Training loss 48887.87109375

Recall on (sampled) validation set: 0.21854034009614773

Training loss 48887.890625

Recall on (sampled) validation set: 0.21771103983399812

Training loss 48888.0703125

Recall on (sampled) validation set: 0.21750476264677715

Training loss 48887.46875

Recall on (sampled) validation set: 0.21599995897092086

Training loss 48887.171875

Recall on (sampled) validation set: 0.21724200740443933

Training loss 48888.078125

Recall on (sampled) validation set: 0.21925228715292236

Training loss 48888.05859375

Recall on (sampled) validation set: 0.2157464804470249

Training loss 48887.48046875

Recall on (sampled) validation set: 0.21858850648914166

Training loss 48887.953125

Recall on (sampled) validation set: 0.220124892516907

Training loss 48887.43359375

Recall on (sampled) validation set: 0.21802144424104497

Training loss 48887.71875

Recall on (sampled) validation set: 0.2215116548773536

Training loss 48887.6640625

Recall on (sampled) validation set: 0.22017167614263802

Training loss 48887.609375

Recall on (sampled) validation set: 0.2170293087298532

Training loss 48887.69140625

Recall on (sampled) validation set: 0.21464761978963434

Training loss 48887.8984375

Recall on (sampled) validation set: 0.2137031753451899

Training loss 48887.671875

Recall on (sampled) validation set: 0.21754831457780643

Training loss 48887.57421875

Recall on (sampled) validation set: 0.21989445291214801

Training loss 48887.609375

Recall on (sampled) validation set: 0.22104820458495594

Training loss 48887.73828125

Recall on (sampled) validation set: 0.2184372034666953

Training loss 48887.9140625

Recall on (sampled) validation set: 0.22027930872985318

Training loss 48887.60546875

Recall on (sampled) validation set: 0.217823168378976

Training loss 48887.57421875

Recall on (sampled) validation set: 0.21871498124447308

Training loss 48887.203125

Recall on (sampled) validation set: 0.2199772316981936

Training loss 48887.24609375

Recall on (sampled) validation set: 0.21715267029468482

Training loss 48887.76171875

Recall on (sampled) validation set: 0.22126781447697966

Training loss 48887.26953125

Recall on (sampled) validation set: 0.21833778826201694

Training loss 48887.453125

Recall on (sampled) validation set: 0.2193465601918415

Training loss 48887.63671875

Recall on (sampled) validation set: 0.2167216266458553

Training loss 48887.234375

Recall on (sampled) validation set: 0.2165862162808624

Training loss 48887.3984375

Recall on (sampled) validation set: 0.21570620931464854

Training loss 48888.05859375

Recall on (sampled) validation set: 0.2185006235110591

Training loss 48887.5390625

Recall on (sampled) validation set: 0.22219384886807755

Training loss 48887.671875

Recall on (sampled) validation set: 0.21831253573676443

Training loss 48887.76953125

Recall on (sampled) validation set: 0.21998126476937727

Training loss 48887.8984375

Recall on (sampled) validation set: 0.21880203600258047

Training loss 48887.7265625

Recall on (sampled) validation set: 0.2206856314855407

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21971870266924715

Training loss 48887.48828125

Recall on (sampled) validation set: 0.21951269915471366

Training loss 48887.796875

Recall on (sampled) validation set: 0.21814348065391623

Training loss 48887.62109375

Recall on (sampled) validation set: 0.21474185158123452

Training loss 48887.390625

Recall on (sampled) validation set: 0.21596765839188706

Training loss 48887.421875

Recall on (sampled) validation set: 0.21319349597434897

Training loss 48887.96484375

Recall on (sampled) validation set: 0.21520115880959803

Training loss 48888.1015625

Recall on (sampled) validation set: 0.21836605576986703

Training loss 48887.69140625

Recall on (sampled) validation set: 0.21690183487279674

Training loss 48887.6953125

Recall on (sampled) validation set: 0.2142260126107676

Training loss 48887.765625

Recall on (sampled) validation set: 0.21637276598846475

Training loss 48887.17578125

Recall on (sampled) validation set: 0.21829326407275593

Training loss 48887.81640625

Recall on (sampled) validation set: 0.21940437518386702

Training loss 48887.85546875

Recall on (sampled) validation set: 0.21235354408312665

Training loss 48887.6015625

Recall on (sampled) validation set: 0.21910839293461795

Training loss 48887.49609375

Recall on (sampled) validation set: 0.22056001048423918

Training loss 48888.015625

Recall on (sampled) validation set: 0.22190437518386702

Training loss 48887.69921875

Recall on (sampled) validation set: 0.21294001745045302

Training loss 48887.640625

Recall on (sampled) validation set: 0.21954326407275587

Training loss 48887.4609375

Recall on (sampled) validation set: 0.21834881962831143

Training loss 48887.59375

Recall on (sampled) validation set: 0.21469147943875716

Training loss 48887.734375

Recall on (sampled) validation set: 0.21874258421218495

Training loss 48887.48046875

Recall on (sampled) validation set: 0.2174772316981936

Training loss 48887.953125

Recall on (sampled) validation set: 0.21654723232672418

Training loss 48887.625

Recall on (sampled) validation set: 0.21334634413445666

Training loss 48887.31640625

Recall on (sampled) validation set: 0.2122692306349294

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21472667715090585

Training loss 48888.15625

Recall on (sampled) validation set: 0.2156477297824848

Training loss 48887.8359375

Recall on (sampled) validation set: 0.2163149509964392

Training loss 48887.75390625

Recall on (sampled) validation set: 0.21606021933971117

Training loss 48887.80859375

Recall on (sampled) validation set: 0.21221737751728678

Training loss 48887.921875

Recall on (sampled) validation set: 0.2184760126107676

Training loss 48887.73828125

Recall on (sampled) validation set: 0.218627151953377

Training loss 48887.6015625

Recall on (sampled) validation set: 0.21761756358852546

Training loss 48887.984375

Recall on (sampled) validation set: 0.21586545604694427

Training loss 48887.53125

Recall on (sampled) validation set: 0.21736886975362477

Training loss 48887.13671875

Recall on (sampled) validation set: 0.21952665449761638

Training loss 48887.3984375

Recall on (sampled) validation set: 0.21156654589277094

Training loss 48887.51171875

Recall on (sampled) validation set: 0.2158890401290583

Training loss 48887.75390625

Recall on (sampled) validation set: 0.2130885667233217

Training loss 48887.5703125

Recall on (sampled) validation set: 0.21689706524234656

Training loss 48887.32421875

Recall on (sampled) validation set: 0.2157860909675792

Training loss 48887.703125

Recall on (sampled) validation set: 0.21402625577353349

Training loss 48888.01953125

Recall on (sampled) validation set: 0.22014917278392776

Training loss 48887.53515625

Recall on (sampled) validation set: 0.21897641133485052

Training loss 48887.46484375

Recall on (sampled) validation set: 0.21906583945059444

Training loss 48887.94921875

Recall on (sampled) validation set: 0.21423358836834333

Training loss 48887.66015625

Recall on (sampled) validation set: 0.21855224485805252

Training loss 48887.6796875

Recall on (sampled) validation set: 0.21345827168059472

Training loss 48887.60546875

Recall on (sampled) validation set: 0.21714534136630326

Training loss 48887.765625

Recall on (sampled) validation set: 0.21006734726925289

Training loss 48887.875

Recall on (sampled) validation set: 0.22270089692185882

Training loss 48887.4765625

Recall on (sampled) validation set: 0.2240620080329699

Training loss 48887.67578125

Recall on (sampled) validation set: 0.216805643506188

Training loss 48887.12109375

Recall on (sampled) validation set: 0.2187512651360201

Training loss 48887.359375

Recall on (sampled) validation set: 0.21884069325176403

Training loss 48887.86328125

Recall on (sampled) validation set: 0.21651905582486344

Training loss 48887.828125

Recall on (sampled) validation set: 0.2142135002693079

Training loss 48887.765625

Recall on (sampled) validation set: 0.22265794471375236

Training loss 48887.921875

Recall on (sampled) validation set: 0.2174386464681383

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21817976454546326

Training loss 48887.8359375

Recall on (sampled) validation set: 0.2172995107500552

Training loss 48887.3203125

Recall on (sampled) validation set: 0.2135553626315877

Training loss 48887.4765625

Recall on (sampled) validation set: 0.21642858736007553

Training loss 48887.53515625

Recall on (sampled) validation set: 0.21217025998468828

Training loss 48887.67578125

Recall on (sampled) validation set: 0.2200150875708952

Training loss 48887.953125

Recall on (sampled) validation set: 0.21854300218501674

Training loss 48887.64453125

Recall on (sampled) validation set: 0.21790205878681376

Training loss 48887.74609375

Recall on (sampled) validation set: 0.21719675385782466

Training loss 48887.8359375

Recall on (sampled) validation set: 0.21585192627161776

Training loss 48887.4453125

Recall on (sampled) validation set: 0.21997466847194616

Training loss 48887.5390625

Recall on (sampled) validation set: 0.21758961100068178

Training loss 48887.5

Recall on (sampled) validation set: 0.21988309091258273

Training loss 48888.171875

Recall on (sampled) validation set: 0.2174357224915301

Training loss 48887.92578125

Recall on (sampled) validation set: 0.21898744662946115

Training loss 48887.78125

Recall on (sampled) validation set: 0.2155140053198129

Training loss 48887.60546875

Recall on (sampled) validation set: 0.21414917278392778

Training loss 48887.8359375

Recall on (sampled) validation set: 0.2203207799627945

Training loss 48887.921875

Recall on (sampled) validation set: 0.2207959261616249

Training loss 48887.55859375

Recall on (sampled) validation set: 0.21465690043639227

Training loss 48887.96484375

Recall on (sampled) validation set: 0.21943200106675603

Training loss 48887.94140625

Recall on (sampled) validation set: 0.2173107889455439

Training loss 48887.671875

Recall on (sampled) validation set: 0.21854286534867298

Training loss 48887.828125

Recall on (sampled) validation set: 0.2166377577520953

Training loss 48887.55859375

Recall on (sampled) validation set: 0.22006667487248247

Training loss 48887.734375

Recall on (sampled) validation set: 0.21839241738969506

Training loss 48887.94140625

Recall on (sampled) validation set: 0.2120453264387021

Training loss 48887.25390625

Recall on (sampled) validation set: 0.21547867469963658

Training loss 48887.86328125

Recall on (sampled) validation set: 0.21520953201533966

Training loss 48887.74609375

Recall on (sampled) validation set: 0.21598744662946112

Training loss 48887.796875

Recall on (sampled) validation set: 0.2197491425358939

Training loss 48887.61328125

Recall on (sampled) validation set: 0.22035238915819677

Training loss 48887.74609375

Recall on (sampled) validation set: 0.2167968336026412

Training loss 48887.63671875

Recall on (sampled) validation set: 0.20943175423756188

Training loss 48887.71484375

Recall on (sampled) validation set: 0.21594741839796286

Training loss 48887.546875

Recall on (sampled) validation set: 0.21606586629408772

Training loss 48887.9609375

Recall on (sampled) validation set: 0.2157654980799264

Training loss 48888.109375

Recall on (sampled) validation set: 0.21245822585024038

Training loss 48887.96875

Recall on (sampled) validation set: 0.21740808155009608

Training loss 48887.62890625

Recall on (sampled) validation set: 0.22232474821676274

Training loss 48888.06640625

Recall on (sampled) validation set: 0.21879575135155893

Training loss 48887.4765625

Recall on (sampled) validation set: 0.21693464024044787

Training loss 48887.796875

Recall on (sampled) validation set: 0.21542586831062327

Training loss 48887.5234375

Recall on (sampled) validation set: 0.2095531261102949

Training loss 48887.91015625

Recall on (sampled) validation set: 0.21787223042803802

Training loss 48888.05078125

Recall on (sampled) validation set: 0.21500651729462977

Training loss 48888.03125

Recall on (sampled) validation set: 0.21535134488083676

Training loss 48887.40625

Recall on (sampled) validation set: 0.21678903393104842

Training loss 48887.44140625

Recall on (sampled) validation set: 0.21975269307891818

Training loss 48887.3203125

Recall on (sampled) validation set: 0.21467395456596908

Training loss 48887.73828125

Recall on (sampled) validation set: 0.2168209167991382

Training loss 48887.4765625

Recall on (sampled) validation set: 0.21541950378384134

Training loss 48887.65625

Recall on (sampled) validation set: 0.21519345014399457

Training loss 48887.63671875

Recall on (sampled) validation set: 0.2178010035101687

Training loss 48887.67578125

Recall on (sampled) validation set: 0.21131688372795449

Training loss 48887.76171875

Recall on (sampled) validation set: 0.21562912265861447

Training loss 48887.6015625

Recall on (sampled) validation set: 0.21311435873731702

Training loss 48887.375

Recall on (sampled) validation set: 0.2190852970548978

Training loss 48887.4296875

Recall on (sampled) validation set: 0.2154624180182256

Training loss 48888.0390625

Recall on (sampled) validation set: 0.2175499932782147

Training loss 48888.03515625

Recall on (sampled) validation set: 0.21054178309759072

Training loss 48887.71484375

Recall on (sampled) validation set: 0.21382837077891523

Training loss 48887.19140625

Recall on (sampled) validation set: 0.217856357412165

Training loss 48887.82421875

Recall on (sampled) validation set: 0.21726056476963918

Training loss 48887.6640625

Recall on (sampled) validation set: 0.21792273547854307

Training loss 48887.76171875

Recall on (sampled) validation set: 0.21747916442970885

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21822445961647413

Training loss 48887.671875

Recall on (sampled) validation set: 0.21757064312645075

Training loss 48887.67578125

Recall on (sampled) validation set: 0.2166500082058158

Training loss 48887.65625

Recall on (sampled) validation set: 0.21358971379161942

Training loss 48887.25

Recall on (sampled) validation set: 0.2160550437832652

Training loss 48887.6484375

Recall on (sampled) validation set: 0.21312475568056327

Training loss 48887.81640625

Recall on (sampled) validation set: 0.21111471163104556

Training loss 48887.71875

Recall on (sampled) validation set: 0.21101125615327068

Training loss 48887.63671875

Recall on (sampled) validation set: 0.2075384793837607

Training loss 48887.5234375

Recall on (sampled) validation set: 0.2151771142415425

Training loss 48887.5859375

Recall on (sampled) validation set: 0.21178526733063938

Training loss 48887.375

Recall on (sampled) validation set: 0.21146220916275363

Training loss 48887.671875

Recall on (sampled) validation set: 0.21301125615327068

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21201508757089518

Training loss 48887.25

Recall on (sampled) validation set: 0.2111064222293805

Training loss 48887.421875

Recall on (sampled) validation set: 0.2112242887347243

Training loss 48887.2734375

Recall on (sampled) validation set: 0.21593084679654553

Training loss 48887.46875

Recall on (sampled) validation set: 0.21410642222938048

Training loss 48887.5234375

Recall on (sampled) validation set: 0.21722902759336515

Training loss 48887.42578125

Recall on (sampled) validation set: 0.214545542496087

Training loss 48887.63671875

Recall on (sampled) validation set: 0.21689077338941223

Training loss 48888.171875

Recall on (sampled) validation set: 0.2171651374605095

Training loss 48887.546875

Recall on (sampled) validation set: 0.2161844313849758

Training loss 48887.6484375

Recall on (sampled) validation set: 0.21724012377687515

Training loss 48887.76953125

Recall on (sampled) validation set: 0.2169932566089553

Training loss 48887.93359375

Recall on (sampled) validation set: 0.21585510427933297

Training loss 48887.91015625

Recall on (sampled) validation set: 0.21304265649320095

Training loss 48887.51953125

Recall on (sampled) validation set: 0.21090773585828032

Training loss 48887.48046875

Recall on (sampled) validation set: 0.21126905582486344

Training loss 48887.33984375

Recall on (sampled) validation set: 0.2116618409485923

Training loss 48887.421875

Recall on (sampled) validation set: 0.21261011681066125

Training loss 48887.3046875

Recall on (sampled) validation set: 0.21326898380573517

Training loss 48887.39453125

Recall on (sampled) validation set: 0.21393565047240182

Training loss 48887.671875

Recall on (sampled) validation set: 0.21310628539303675

Training loss 48887.578125

Recall on (sampled) validation set: 0.21759545895389815

Training loss 48887.25390625

Recall on (sampled) validation set: 0.21406563059512243

Training loss 48887.4609375

Recall on (sampled) validation set: 0.22008233903288346

Training loss 48887.609375

Recall on (sampled) validation set: 0.22120549174224313

Training loss 48888.0390625

Recall on (sampled) validation set: 0.21807098881826653

Training loss 48887.546875

Recall on (sampled) validation set: 0.21819793889984454

Training loss 48887.7265625

Recall on (sampled) validation set: 0.21493756421705607

Training loss 48887.56640625

Recall on (sampled) validation set: 0.2180982120487565

Training loss 48887.4296875

Recall on (sampled) validation set: 0.21546081439230258

Training loss 48887.34375

Recall on (sampled) validation set: 0.2167849936579519

Training loss 48887.3359375

Recall on (sampled) validation set: 0.21662504441179578

Training loss 48887.515625

Recall on (sampled) validation set: 0.21824308179888946

Training loss 48887.60546875

Recall on (sampled) validation set: 0.21660958190495394

Training loss 48887.578125

Recall on (sampled) validation set: 0.2181010980516425

Training loss 48887.44140625

Recall on (sampled) validation set: 0.2127320504325949

Training loss 48887.76171875

Recall on (sampled) validation set: 0.2177042726548171

Training loss 48887.96875

Recall on (sampled) validation set: 0.212084279621031

Training loss 48887.265625

Recall on (sampled) validation set: 0.21143839963894412

Training loss 48887.63671875

Recall on (sampled) validation set: 0.21466019694830948

Training loss 48887.68359375

Recall on (sampled) validation set: 0.21210896254045075

Training loss 48887.546875

Recall on (sampled) validation set: 0.21492266345941477

Training loss 48887.6640625

Recall on (sampled) validation set: 0.21092649487703932

Training loss 48887.50390625

Recall on (sampled) validation set: 0.2103393301260815

Training loss 48887.4296875

Recall on (sampled) validation set: 0.21627549237077365

Training loss 48887.5546875

Recall on (sampled) validation set: 0.2161362529887938

Training loss 48887.90625

Recall on (sampled) validation set: 0.21436327648623477

Training loss 48887.75390625

Recall on (sampled) validation set: 0.21361724474020302

Training loss 48887.60546875

Recall on (sampled) validation set: 0.21642541262595708

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21779637791797501

Training loss 48887.33984375

Recall on (sampled) validation set: 0.21139105426401253

Training loss 48887.18359375

Recall on (sampled) validation set: 0.21389871709926156

Training loss 48887.875

Recall on (sampled) validation set: 0.2140968417211611

Training loss 48887.6015625

Recall on (sampled) validation set: 0.21402586490608266

Training loss 48887.640625

Recall on (sampled) validation set: 0.21405493379041474

Training loss 48887.34375

Recall on (sampled) validation set: 0.2095525335892849

Training loss 48887.46484375

Recall on (sampled) validation set: 0.21389871709926156

Training loss 48887.26171875

Recall on (sampled) validation set: 0.21709194245628002

Training loss 48887.44140625

Recall on (sampled) validation set: 0.21449095919876318

Training loss 48887.24609375

Recall on (sampled) validation set: 0.21098205043259488

Training loss 48887.8046875

Recall on (sampled) validation set: 0.21923205043259486

Training loss 48887.61328125

Recall on (sampled) validation set: 0.21473457568512014

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21267663171338305

Training loss 48887.25

Recall on (sampled) validation set: 0.21117510163426678

Training loss 48887.91015625

Recall on (sampled) validation set: 0.2108505363024419

Training loss 48887.44921875

Recall on (sampled) validation set: 0.21234705777854598

Training loss 48887.375

Recall on (sampled) validation set: 0.21036710790385926

Training loss 48887.65625

Recall on (sampled) validation set: 0.21546550567467085

Training loss 48887.89453125

Recall on (sampled) validation set: 0.21479143740577494

Training loss 48887.36328125

Recall on (sampled) validation set: 0.2187547777053222

Training loss 48887.51171875

Recall on (sampled) validation set: 0.2134821872689386

Training loss 48887.3984375

Recall on (sampled) validation set: 0.21358933012608147

Training loss 48887.2734375

Recall on (sampled) validation set: 0.21369922214976658

Training loss 48887.44921875

Recall on (sampled) validation set: 0.2137356009756191

Training loss 48887.5546875

Recall on (sampled) validation set: 0.21103255548309996

Training loss 48887.73046875

Recall on (sampled) validation set: 0.21450585995640442

Training loss 48887.640625

Recall on (sampled) validation set: 0.21498594666743487

Training loss 48887.75

Recall on (sampled) validation set: 0.21531538376592826

Training loss 48887.55078125

Recall on (sampled) validation set: 0.2211121673916592

Training loss 48887.33984375

Recall on (sampled) validation set: 0.2157197999788744

Training loss 48887.82421875

Recall on (sampled) validation set: 0.21561230422800293

Training loss 48887.375

Recall on (sampled) validation set: 0.21312093932148377

Training loss 48887.5390625

Recall on (sampled) validation set: 0.21406058009007192

Training loss 48887.4453125

Recall on (sampled) validation set: 0.21637441784537975

Training loss 48887.09375

Recall on (sampled) validation set: 0.2135271972599559

Training loss 48887.5859375

Recall on (sampled) validation set: 0.2134302163018134

Training loss 48887.7890625

Recall on (sampled) validation set: 0.2198356355448007

Training loss 48887.640625

Recall on (sampled) validation set: 0.22065884102453973

Training loss 48887.13671875

Recall on (sampled) validation set: 0.21493380481855978

Training loss 48887.59375

Recall on (sampled) validation set: 0.2132281620543871

Training loss 48887.53515625

Recall on (sampled) validation set: 0.2207018842386356

Training loss 48887.51171875

Recall on (sampled) validation set: 0.21793628489545006

Training loss 48886.9765625

Recall on (sampled) validation set: 0.2162980035861161

Training loss 48887.4765625

Recall on (sampled) validation set: 0.21384221612896748

Training loss 48887.640625

Recall on (sampled) validation set: 0.21797821901497036

Training loss 48887.03515625

Recall on (sampled) validation set: 0.21975561312721026

Training loss 48887.515625

Recall on (sampled) validation set: 0.21739402734457183

Training loss 48887.25390625

Recall on (sampled) validation set: 0.21711985707040152

Training loss 48887.2890625

Recall on (sampled) validation set: 0.21103782990216746

Training loss 48887.80078125

Recall on (sampled) validation set: 0.21167013820688954

Training loss 48887.42578125

Recall on (sampled) validation set: 0.21762635057689503

Training loss 48887.30078125

Recall on (sampled) validation set: 0.2190338884916925

Training loss 48887.64453125

Recall on (sampled) validation set: 0.21583982771278595

Training loss 48887.49609375

Recall on (sampled) validation set: 0.2151659951428554

Training loss 48887.13671875

Recall on (sampled) validation set: 0.21642643791645605

Training loss 48887.44921875

Recall on (sampled) validation set: 0.21864486276645986

Training loss 48887.2734375

Recall on (sampled) validation set: 0.21986057642364357

Training loss 48887.35546875

Recall on (sampled) validation set: 0.2208117762623207

Training loss 48887.453125

Recall on (sampled) validation set: 0.21397307990456815

Training loss 48887.296875

Recall on (sampled) validation set: 0.2145101889607334

Training loss 48887.7890625

Recall on (sampled) validation set: 0.21318527466349607

Training loss 48886.859375

Recall on (sampled) validation set: 0.2183901959269473

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21581971277025722

Training loss 48887.1484375

Recall on (sampled) validation set: 0.21868695663750107

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21834063629118078

Training loss 48887.73828125

Recall on (sampled) validation set: 0.2159065246274865

Training loss 48887.33984375

Recall on (sampled) validation set: 0.21622558769791075

Training loss 48887.62890625

Recall on (sampled) validation set: 0.21696399785601234

Training loss 48887.59375

Recall on (sampled) validation set: 0.21708399088979852

Training loss 48887.63671875

Recall on (sampled) validation set: 0.21903605299385698

Training loss 48887.5859375

Recall on (sampled) validation set: 0.20784474138149275

Training loss 48887.796875

Recall on (sampled) validation set: 0.20844812484013936

Training loss 48887.296875

Recall on (sampled) validation set: 0.21382226093795964

Training loss 48887.53515625

Recall on (sampled) validation set: 0.2122845910055529

Training loss 48887.74609375

Recall on (sampled) validation set: 0.21118094565916706

Training loss 48887.6484375

Recall on (sampled) validation set: 0.2103656269286941

Training loss 48887.55078125

Recall on (sampled) validation set: 0.21189688323036782

Training loss 48887.34375

Recall on (sampled) validation set: 0.21580513086093844

Training loss 48887.0234375

Recall on (sampled) validation set: 0.21393622007823462

Training loss 48887.4296875

Recall on (sampled) validation set: 0.2179241784799861

Training loss 48887.1953125

Recall on (sampled) validation set: 0.2155336226756372

Training loss 48887.515625

Recall on (sampled) validation set: 0.20977651766127267

Training loss 48887.35546875

Recall on (sampled) validation set: 0.21174247421933448

Training loss 48887.19140625

Recall on (sampled) validation set: 0.21342083679243387

Training loss 48887.58984375

Recall on (sampled) validation set: 0.20945080198755334

Training loss 48887.3359375

Recall on (sampled) validation set: 0.21570170942856967

Training loss 48887.0703125

Recall on (sampled) validation set: 0.209098709635461

Training loss 48887.5234375

Recall on (sampled) validation set: 0.21735083223558724

Training loss 48887.71875

Recall on (sampled) validation set: 0.2177130255977806

Training loss 48887.51953125

Recall on (sampled) validation set: 0.2121149014996565

Training loss 48887.80859375

Recall on (sampled) validation set: 0.2156216457636603

Training loss 48887.44140625

Recall on (sampled) validation set: 0.21058213803404366

Training loss 48887.28515625

Recall on (sampled) validation set: 0.20345428051144931

Training loss 48887.48828125

Recall on (sampled) validation set: 0.2051625473907688

Training loss 48887.64453125

Recall on (sampled) validation set: 0.20501639373599448

Training loss 48887.30078125

Recall on (sampled) validation set: 0.20642327103896976

Training loss 48887.40625

Recall on (sampled) validation set: 0.2145050031470177

Training loss 48887.3359375

Recall on (sampled) validation set: 0.2093282417992037

Training loss 48887.14453125

Recall on (sampled) validation set: 0.2152524992819911

Training loss 48887.64453125

Recall on (sampled) validation set: 0.21515931569606703

Training loss 48887.3984375

Recall on (sampled) validation set: 0.21905551452647642

Training loss 48887.33984375

Recall on (sampled) validation set: 0.21404541351637538

Training loss 48888.08984375

Recall on (sampled) validation set: 0.2166763658973278

Training loss 48887.828125

Recall on (sampled) validation set: 0.2112874770084389

Training loss 48887.56640625

Recall on (sampled) validation set: 0.21439794496691045

Training loss 48887.375

Recall on (sampled) validation set: 0.21627399240874742

Training loss 48887.43359375

Recall on (sampled) validation set: 0.2119953071899533

Training loss 48887.453125

Recall on (sampled) validation set: 0.21887962810195116

Training loss 48887.703125

Recall on (sampled) validation set: 0.21738005301480798

Training loss 48887.5546875

Recall on (sampled) validation set: 0.21755648285639212

Training loss 48886.93359375

Recall on (sampled) validation set: 0.2152076071404565

Training loss 48887.609375

Recall on (sampled) validation set: 0.21984726270570193

Training loss 48887.6796875

Recall on (sampled) validation set: 0.21542916482254051

Training loss 48887.1796875

Recall on (sampled) validation set: 0.21737304686306502

Training loss 48886.703125

Recall on (sampled) validation set: 0.21518928874781867

Training loss 48887.5703125

Recall on (sampled) validation set: 0.21351514845979455

Training loss 48887.25390625

Recall on (sampled) validation set: 0.217514203045056

Training loss 48887.44921875

Recall on (sampled) validation set: 0.2120841886150416

Training loss 48887.43359375

Recall on (sampled) validation set: 0.22034293370137292

Training loss 48887.734375

Recall on (sampled) validation set: 0.21865663462033694

Training loss 48887.28125

Recall on (sampled) validation set: 0.21722060921198852

Training loss 48887.375

Recall on (sampled) validation set: 0.22343313307650875

Training loss 48887.53515625

Recall on (sampled) validation set: 0.21132602666540962

Training loss 48887.609375

Recall on (sampled) validation set: 0.21099902861472739

Training loss 48887.15625

Recall on (sampled) validation set: 0.2117879477516501

Training loss 48887.80859375

Recall on (sampled) validation set: 0.2275631131992294

Training loss 48887.2890625

Recall on (sampled) validation set: 0.22041917380528994

Training loss 48887.17578125

Recall on (sampled) validation set: 0.2235818074007729

Training loss 48887.4453125

Recall on (sampled) validation set: 0.21651434708331257

Training loss 48887.48828125

Recall on (sampled) validation set: 0.21785227523703024

Training loss 48887.6796875

Recall on (sampled) validation set: 0.21724297420667657

Training loss 48887.37109375

Recall on (sampled) validation set: 0.21413510351985848

Training loss 48887.09375

Recall on (sampled) validation set: 0.21945548061201417

Training loss 48887.921875

Recall on (sampled) validation set: 0.21700633855624782

Training loss 48887.484375

Recall on (sampled) validation set: 0.21734057933059744

Training loss 48887.3203125

Recall on (sampled) validation set: 0.2181847731484755

Training loss 48887.36328125

Recall on (sampled) validation set: 0.21674993605574372

Training loss 48887.32421875

Recall on (sampled) validation set: 0.21616540655016153

Training loss 48887.30859375

Recall on (sampled) validation set: 0.21873744270114504

Training loss 48887.30078125

Recall on (sampled) validation set: 0.2172385517957206

Training loss 48887.1796875

Recall on (sampled) validation set: 0.22226668246722692

Training loss 48887.359375

Recall on (sampled) validation set: 0.21757954796430293

Training loss 48887.49609375

Recall on (sampled) validation set: 0.21508365305461496

Training loss 48887.50390625

Recall on (sampled) validation set: 0.21781018922262116

Training loss 48887.39453125

Recall on (sampled) validation set: 0.21390915987286224

Training loss 48887.69140625

Recall on (sampled) validation set: 0.2233799659371347

Training loss 48887.26171875

Recall on (sampled) validation set: 0.2219734873582424

Training loss 48887.84375

Recall on (sampled) validation set: 0.2133708483154944

Training loss 48887.6484375

Recall on (sampled) validation set: 0.2087929982567006

Training loss 48887.5703125

Recall on (sampled) validation set: 0.20884966290683168

Training loss 48887.53515625

Recall on (sampled) validation set: 0.21144546275127035

Training loss 48887.234375

Recall on (sampled) validation set: 0.21431052312948864

Training loss 48887.6640625

Recall on (sampled) validation set: 0.21857488112479037

Training loss 48887.37109375

Recall on (sampled) validation set: 0.2180239924087474

Training loss 48887.4453125

Recall on (sampled) validation set: 0.22410493732589917

Training loss 48887.30078125

Recall on (sampled) validation set: 0.21562502542493467

Training loss 48887.65625

Recall on (sampled) validation set: 0.21732702271177773

Training loss 48887.2734375

Recall on (sampled) validation set: 0.2165027081374631

Training loss 48887.48828125

Recall on (sampled) validation set: 0.22155088173236995

Training loss 48887.2734375

Recall on (sampled) validation set: 0.22758967188958115

Training loss 48887.53515625

Recall on (sampled) validation set: 0.22341558921685964

Training loss 48887.109375

Recall on (sampled) validation set: 0.21696752941217548

Training loss 48887.35546875

Recall on (sampled) validation set: 0.21585107906478143

Training loss 48887.35546875

Recall on (sampled) validation set: 0.21793191398908277

Training loss 48887.30078125

Recall on (sampled) validation set: 0.2196869644941333

Training loss 48886.9609375

Recall on (sampled) validation set: 0.22224910063385564

Training loss 48887.51953125

Recall on (sampled) validation set: 0.22104804876175113

Training loss 48887.55859375

Recall on (sampled) validation set: 0.21907585338302216

Training loss 48887.40625

Recall on (sampled) validation set: 0.21203624286246792

Training loss 48887.35546875

Recall on (sampled) validation set: 0.2185352254286011

Training loss 48887.0859375

Recall on (sampled) validation set: 0.2161022752370302

Training loss 48887.265625

Recall on (sampled) validation set: 0.2173561564133252

Training loss 48887.16015625

Recall on (sampled) validation set: 0.21967788091789903

Training loss 48887.51171875

Recall on (sampled) validation set: 0.21819715258190756

Training loss 48887.67578125

Recall on (sampled) validation set: 0.2058561564133252

Training loss 48887.18359375

Recall on (sampled) validation set: 0.21779938177034366